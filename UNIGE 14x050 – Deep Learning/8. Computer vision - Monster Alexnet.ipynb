{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPI1sYsPtwCH2pHOTbgs0Dc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"aafa5228824249a6a2661a3c851ca2c9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1c79e199f02041d188460390c9bf5361","IPY_MODEL_5187a5e676104de38a596274eea92374","IPY_MODEL_6b6a39e62eb543e2bdadae1626f8f32f"],"layout":"IPY_MODEL_b990379b34f94d17a7ccb6e01203030c"}},"1c79e199f02041d188460390c9bf5361":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0862f490bc1f4c88a59fb60874d2b1b4","placeholder":"​","style":"IPY_MODEL_4b1bee656a974d488debd51921c43c7f","value":"100%"}},"5187a5e676104de38a596274eea92374":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3da5bebf0f614544bdf56fe0beb9c800","max":170498071,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b9ff9c8ff46487a8310d51526a60fb3","value":170498071}},"6b6a39e62eb543e2bdadae1626f8f32f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b32b8a13971407eb9bd0bdf781fd555","placeholder":"​","style":"IPY_MODEL_85dc2acc262d41e8acb4200d973d95bf","value":" 170498071/170498071 [00:13&lt;00:00, 8657727.65it/s]"}},"b990379b34f94d17a7ccb6e01203030c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0862f490bc1f4c88a59fb60874d2b1b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b1bee656a974d488debd51921c43c7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3da5bebf0f614544bdf56fe0beb9c800":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b9ff9c8ff46487a8310d51526a60fb3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8b32b8a13971407eb9bd0bdf781fd555":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85dc2acc262d41e8acb4200d973d95bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158,"referenced_widgets":["aafa5228824249a6a2661a3c851ca2c9","1c79e199f02041d188460390c9bf5361","5187a5e676104de38a596274eea92374","6b6a39e62eb543e2bdadae1626f8f32f","b990379b34f94d17a7ccb6e01203030c","0862f490bc1f4c88a59fb60874d2b1b4","4b1bee656a974d488debd51921c43c7f","3da5bebf0f614544bdf56fe0beb9c800","2b9ff9c8ff46487a8310d51526a60fb3","8b32b8a13971407eb9bd0bdf781fd555","85dc2acc262d41e8acb4200d973d95bf"]},"id":"jgz0oy5sNVPT","executionInfo":{"status":"ok","timestamp":1672530000442,"user_tz":480,"elapsed":24601,"user":{"displayName":"sillybierba","userId":"07761949595544066685"}},"outputId":"30cf6350-7a5a-4ffc-8534-d0cfeaab8cdc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar10/cifar-10-python.tar.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aafa5228824249a6a2661a3c851ca2c9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar10/cifar-10-python.tar.gz to ./data/cifar10/\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n"]}],"source":["import os\n","import torch\n","import torchvision\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","\n","data_dir = os.environ.get('PYTORCH_DATA_DIR') or './data/cifar10/'\n","\n","num_workers = 4\n","batch_size = 64\n","\n","transform = torchvision.transforms.ToTensor()\n","\n","train_set = datasets.CIFAR10(root = data_dir, train = True,\n","                             download = True, transform = transform)\n","\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size,\n","                                    shuffle = True, num_workers = num_workers)\n","\n","test_set = datasets.CIFAR10(root = data_dir, train = False,\n","                            download = True, transform = transform)\n","\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size,\n","                                    shuffle = False, num_workers = num_workers)\n"]},{"cell_type":"code","source":["from torch import nn\n","import torch.nn.functional as F\n","\n","class ResBlock(nn.Module):\n","    def __init__(self, nb_channels, kernel_size):\n","        super().__init__()\n","\n","        self.conv1 = nn.Conv2d(nb_channels, nb_channels, kernel_size,\n","                               padding = (kernel_size-1)//2)\n","        self.bn1 = nn.BatchNorm2d(nb_channels)\n","\n","        self.conv2 = nn.Conv2d(nb_channels, nb_channels, kernel_size,\n","                               padding = (kernel_size-1)//2)\n","        self.bn2 = nn.BatchNorm2d(nb_channels)\n","\n","    def forward(self, x):\n","        y = self.bn1(self.conv1(x))\n","        y = F.relu(y)\n","        y = self.bn1(self.conv1(x))\n","        y += x\n","        y = F.relu(y)\n","        return y"],"metadata":{"id":"jsiycDS-QSN1","executionInfo":{"status":"ok","timestamp":1672530008117,"user_tz":480,"elapsed":349,"user":{"displayName":"sillybierba","userId":"07761949595544066685"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class Monster(nn.Module):\n","    def __init__(self, nb_blocks, nb_channels):\n","        super().__init__()\n","        \n","        alexnet = torchvision.models.alexnet(weights = 'IMAGENET1K_V1')\n","\n","        self.features = nn.Sequential(alexnet.features[0], nn.ReLU(inplace = True))\n","\n","        dummy = self.features(torch.zeros(1, 3, 32, 32)).size()\n","        alexnet_nb_channels = dummy[1]\n","        alexnet_map_size = tuple(dummy[2:4])\n","\n","        self.conv = nn.Conv2d(alexnet_nb_channels, nb_channels, kernel_size = 1)\n","\n","        self.resblocks = nn.Sequential(\n","            *(ResBlock(nb_channels, kernel_size = 3) for _ in range(nb_blocks))\n","        )\n","\n","        self.avg = nn.AvgPool2d(kernel_size = alexnet_map_size)\n","        self.fc = nn.Linear(nb_channels, 10)\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = F.relu(self.conv(x))\n","        x = self.resblocks(x)\n","        x = F.relu(self.avg(x))\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x\n"],"metadata":{"id":"DIs7A7BlRH6f","executionInfo":{"status":"ok","timestamp":1672530019763,"user_tz":480,"elapsed":401,"user":{"displayName":"sillybierba","userId":"07761949595544066685"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["nb_epochs = 50\n","nb_blocks, nb_channels = 8, 64\n","device = 'cuda'\n","\n","model, criterion = Monster(nb_blocks, nb_channels), nn.CrossEntropyLoss()\n","\n","model.to(device)\n","criterion.to(device)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr = 1e-2, momentum = 0.9)\n","\n","for e in range(nb_epochs):\n","    for p in model.features.parameters():\n","        p.requires_grad = e >= nb_epochs // 2\n","\n","    acc_loss = 0.0\n","\n","    print(f'Starting epoch {e}...')\n","    mini_batch = 0\n","    for input, targets in iter(train_loader):\n","        input, targets = input.to(device), targets.to(device)\n","\n","        output = model(input)\n","        preds = torch.argmax(output.data, 1)\n","        diff_count = torch.count_nonzero(preds - targets)\n","        batch_size = targets.size(0)\n","\n","        training_error = float(diff_count) / batch_size\n","\n","        loss = criterion(output, targets)\n","        acc_loss += loss.item()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        mini_batch += 1\n","        print(f'Epoch {e}: finishing mini batch {mini_batch}, training error = {training_error}, loss = {loss.item()}')\n","\n","    print(f'Epoch {e} completed, acc_loss = {acc_loss}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oAB0FMwXS3TR","executionInfo":{"status":"ok","timestamp":1672531759371,"user_tz":480,"elapsed":717904,"user":{"displayName":"sillybierba","userId":"07761949595544066685"}},"outputId":"17b377ff-9b2c-4c06-e6db-141a1920b4b0"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 43: finishing mini batch 488, training error = 0.09375, loss = 0.24551428854465485\n","Epoch 43: finishing mini batch 489, training error = 0.078125, loss = 0.2678520679473877\n","Epoch 43: finishing mini batch 490, training error = 0.015625, loss = 0.052144475281238556\n","Epoch 43: finishing mini batch 491, training error = 0.0625, loss = 0.16373704373836517\n","Epoch 43: finishing mini batch 492, training error = 0.109375, loss = 0.2425498515367508\n","Epoch 43: finishing mini batch 493, training error = 0.078125, loss = 0.2730174660682678\n","Epoch 43: finishing mini batch 494, training error = 0.0625, loss = 0.1500380039215088\n","Epoch 43: finishing mini batch 495, training error = 0.09375, loss = 0.17088575661182404\n","Epoch 43: finishing mini batch 496, training error = 0.03125, loss = 0.0829305648803711\n","Epoch 43: finishing mini batch 497, training error = 0.03125, loss = 0.07369601726531982\n","Epoch 43: finishing mini batch 498, training error = 0.03125, loss = 0.08491259068250656\n","Epoch 43: finishing mini batch 499, training error = 0.046875, loss = 0.15751440823078156\n","Epoch 43: finishing mini batch 500, training error = 0.03125, loss = 0.10270510613918304\n","Epoch 43: finishing mini batch 501, training error = 0.03125, loss = 0.18406417965888977\n","Epoch 43: finishing mini batch 502, training error = 0.0625, loss = 0.1413317769765854\n","Epoch 43: finishing mini batch 503, training error = 0.046875, loss = 0.11139116436243057\n","Epoch 43: finishing mini batch 504, training error = 0.125, loss = 0.4242721199989319\n","Epoch 43: finishing mini batch 505, training error = 0.109375, loss = 0.22055797278881073\n","Epoch 43: finishing mini batch 506, training error = 0.0625, loss = 0.15106666088104248\n","Epoch 43: finishing mini batch 507, training error = 0.078125, loss = 0.2353798896074295\n","Epoch 43: finishing mini batch 508, training error = 0.046875, loss = 0.15671366453170776\n","Epoch 43: finishing mini batch 509, training error = 0.078125, loss = 0.18735668063163757\n","Epoch 43: finishing mini batch 510, training error = 0.078125, loss = 0.13852326571941376\n","Epoch 43: finishing mini batch 511, training error = 0.03125, loss = 0.09154649823904037\n","Epoch 43: finishing mini batch 512, training error = 0.03125, loss = 0.12227718532085419\n","Epoch 43: finishing mini batch 513, training error = 0.0625, loss = 0.15119744837284088\n","Epoch 43: finishing mini batch 514, training error = 0.09375, loss = 0.27254167199134827\n","Epoch 43: finishing mini batch 515, training error = 0.03125, loss = 0.1564246565103531\n","Epoch 43: finishing mini batch 516, training error = 0.0625, loss = 0.1660834401845932\n","Epoch 43: finishing mini batch 517, training error = 0.03125, loss = 0.08835642039775848\n","Epoch 43: finishing mini batch 518, training error = 0.09375, loss = 0.2224363088607788\n","Epoch 43: finishing mini batch 519, training error = 0.078125, loss = 0.24842610955238342\n","Epoch 43: finishing mini batch 520, training error = 0.046875, loss = 0.10050767660140991\n","Epoch 43: finishing mini batch 521, training error = 0.0625, loss = 0.15096966922283173\n","Epoch 43: finishing mini batch 522, training error = 0.046875, loss = 0.09549879282712936\n","Epoch 43: finishing mini batch 523, training error = 0.0625, loss = 0.1900300681591034\n","Epoch 43: finishing mini batch 524, training error = 0.078125, loss = 0.11486497521400452\n","Epoch 43: finishing mini batch 525, training error = 0.09375, loss = 0.17616252601146698\n","Epoch 43: finishing mini batch 526, training error = 0.125, loss = 0.22337606549263\n","Epoch 43: finishing mini batch 527, training error = 0.0625, loss = 0.15799950063228607\n","Epoch 43: finishing mini batch 528, training error = 0.0, loss = 0.03459808975458145\n","Epoch 43: finishing mini batch 529, training error = 0.09375, loss = 0.290196031332016\n","Epoch 43: finishing mini batch 530, training error = 0.078125, loss = 0.27515867352485657\n","Epoch 43: finishing mini batch 531, training error = 0.015625, loss = 0.0489848293364048\n","Epoch 43: finishing mini batch 532, training error = 0.0625, loss = 0.19303245842456818\n","Epoch 43: finishing mini batch 533, training error = 0.015625, loss = 0.053030259907245636\n","Epoch 43: finishing mini batch 534, training error = 0.0625, loss = 0.12862101197242737\n","Epoch 43: finishing mini batch 535, training error = 0.03125, loss = 0.1043347492814064\n","Epoch 43: finishing mini batch 536, training error = 0.0625, loss = 0.1804281622171402\n","Epoch 43: finishing mini batch 537, training error = 0.0, loss = 0.04524968937039375\n","Epoch 43: finishing mini batch 538, training error = 0.078125, loss = 0.16253410279750824\n","Epoch 43: finishing mini batch 539, training error = 0.03125, loss = 0.08194432407617569\n","Epoch 43: finishing mini batch 540, training error = 0.0625, loss = 0.10045789927244186\n","Epoch 43: finishing mini batch 541, training error = 0.0625, loss = 0.15018519759178162\n","Epoch 43: finishing mini batch 542, training error = 0.03125, loss = 0.11302880942821503\n","Epoch 43: finishing mini batch 543, training error = 0.078125, loss = 0.18358781933784485\n","Epoch 43: finishing mini batch 544, training error = 0.078125, loss = 0.21196341514587402\n","Epoch 43: finishing mini batch 545, training error = 0.015625, loss = 0.11437980085611343\n","Epoch 43: finishing mini batch 546, training error = 0.0625, loss = 0.22926326096057892\n","Epoch 43: finishing mini batch 547, training error = 0.03125, loss = 0.12031323462724686\n","Epoch 43: finishing mini batch 548, training error = 0.078125, loss = 0.1418243795633316\n","Epoch 43: finishing mini batch 549, training error = 0.0625, loss = 0.15163177251815796\n","Epoch 43: finishing mini batch 550, training error = 0.046875, loss = 0.1458946168422699\n","Epoch 43: finishing mini batch 551, training error = 0.078125, loss = 0.1681215763092041\n","Epoch 43: finishing mini batch 552, training error = 0.046875, loss = 0.11172279715538025\n","Epoch 43: finishing mini batch 553, training error = 0.09375, loss = 0.2637802064418793\n","Epoch 43: finishing mini batch 554, training error = 0.078125, loss = 0.20053228735923767\n","Epoch 43: finishing mini batch 555, training error = 0.09375, loss = 0.20290125906467438\n","Epoch 43: finishing mini batch 556, training error = 0.0625, loss = 0.2035803496837616\n","Epoch 43: finishing mini batch 557, training error = 0.09375, loss = 0.2927204668521881\n","Epoch 43: finishing mini batch 558, training error = 0.0625, loss = 0.13658933341503143\n","Epoch 43: finishing mini batch 559, training error = 0.09375, loss = 0.22755280137062073\n","Epoch 43: finishing mini batch 560, training error = 0.078125, loss = 0.15242375433444977\n","Epoch 43: finishing mini batch 561, training error = 0.0625, loss = 0.11042167246341705\n","Epoch 43: finishing mini batch 562, training error = 0.0, loss = 0.051757726818323135\n","Epoch 43: finishing mini batch 563, training error = 0.03125, loss = 0.08127898722887039\n","Epoch 43: finishing mini batch 564, training error = 0.0625, loss = 0.22367875277996063\n","Epoch 43: finishing mini batch 565, training error = 0.09375, loss = 0.22718065977096558\n","Epoch 43: finishing mini batch 566, training error = 0.046875, loss = 0.17283819615840912\n","Epoch 43: finishing mini batch 567, training error = 0.046875, loss = 0.10515441000461578\n","Epoch 43: finishing mini batch 568, training error = 0.046875, loss = 0.14554505050182343\n","Epoch 43: finishing mini batch 569, training error = 0.03125, loss = 0.10785041004419327\n","Epoch 43: finishing mini batch 570, training error = 0.109375, loss = 0.2762874364852905\n","Epoch 43: finishing mini batch 571, training error = 0.0, loss = 0.07581314444541931\n","Epoch 43: finishing mini batch 572, training error = 0.125, loss = 0.2874012589454651\n","Epoch 43: finishing mini batch 573, training error = 0.09375, loss = 0.21215276420116425\n","Epoch 43: finishing mini batch 574, training error = 0.015625, loss = 0.08769132941961288\n","Epoch 43: finishing mini batch 575, training error = 0.046875, loss = 0.1479395180940628\n","Epoch 43: finishing mini batch 576, training error = 0.0625, loss = 0.1759510487318039\n","Epoch 43: finishing mini batch 577, training error = 0.09375, loss = 0.20163068175315857\n","Epoch 43: finishing mini batch 578, training error = 0.046875, loss = 0.17517398297786713\n","Epoch 43: finishing mini batch 579, training error = 0.015625, loss = 0.10389982908964157\n","Epoch 43: finishing mini batch 580, training error = 0.015625, loss = 0.0943615660071373\n","Epoch 43: finishing mini batch 581, training error = 0.0625, loss = 0.1610710620880127\n","Epoch 43: finishing mini batch 582, training error = 0.015625, loss = 0.08764240145683289\n","Epoch 43: finishing mini batch 583, training error = 0.125, loss = 0.2752355933189392\n","Epoch 43: finishing mini batch 584, training error = 0.03125, loss = 0.08225418627262115\n","Epoch 43: finishing mini batch 585, training error = 0.03125, loss = 0.11936520040035248\n","Epoch 43: finishing mini batch 586, training error = 0.03125, loss = 0.10597071796655655\n","Epoch 43: finishing mini batch 587, training error = 0.046875, loss = 0.12229806929826736\n","Epoch 43: finishing mini batch 588, training error = 0.03125, loss = 0.08601509034633636\n","Epoch 43: finishing mini batch 589, training error = 0.046875, loss = 0.11693848669528961\n","Epoch 43: finishing mini batch 590, training error = 0.03125, loss = 0.08343912661075592\n","Epoch 43: finishing mini batch 591, training error = 0.015625, loss = 0.0871310606598854\n","Epoch 43: finishing mini batch 592, training error = 0.03125, loss = 0.0847783237695694\n","Epoch 43: finishing mini batch 593, training error = 0.046875, loss = 0.12408668547868729\n","Epoch 43: finishing mini batch 594, training error = 0.046875, loss = 0.1051703616976738\n","Epoch 43: finishing mini batch 595, training error = 0.078125, loss = 0.1495530903339386\n","Epoch 43: finishing mini batch 596, training error = 0.0625, loss = 0.19309520721435547\n","Epoch 43: finishing mini batch 597, training error = 0.046875, loss = 0.09499777853488922\n","Epoch 43: finishing mini batch 598, training error = 0.09375, loss = 0.22463475167751312\n","Epoch 43: finishing mini batch 599, training error = 0.015625, loss = 0.049632519483566284\n","Epoch 43: finishing mini batch 600, training error = 0.046875, loss = 0.11511287838220596\n","Epoch 43: finishing mini batch 601, training error = 0.046875, loss = 0.11195086687803268\n","Epoch 43: finishing mini batch 602, training error = 0.109375, loss = 0.26570552587509155\n","Epoch 43: finishing mini batch 603, training error = 0.03125, loss = 0.12427970767021179\n","Epoch 43: finishing mini batch 604, training error = 0.03125, loss = 0.1333514302968979\n","Epoch 43: finishing mini batch 605, training error = 0.03125, loss = 0.1133439838886261\n","Epoch 43: finishing mini batch 606, training error = 0.078125, loss = 0.15264981985092163\n","Epoch 43: finishing mini batch 607, training error = 0.046875, loss = 0.10269863158464432\n","Epoch 43: finishing mini batch 608, training error = 0.03125, loss = 0.09075403958559036\n","Epoch 43: finishing mini batch 609, training error = 0.046875, loss = 0.20620420575141907\n","Epoch 43: finishing mini batch 610, training error = 0.125, loss = 0.2525077760219574\n","Epoch 43: finishing mini batch 611, training error = 0.03125, loss = 0.07025332003831863\n","Epoch 43: finishing mini batch 612, training error = 0.046875, loss = 0.09525072574615479\n","Epoch 43: finishing mini batch 613, training error = 0.078125, loss = 0.19063973426818848\n","Epoch 43: finishing mini batch 614, training error = 0.078125, loss = 0.22584682703018188\n","Epoch 43: finishing mini batch 615, training error = 0.046875, loss = 0.08694009482860565\n","Epoch 43: finishing mini batch 616, training error = 0.078125, loss = 0.20279042422771454\n","Epoch 43: finishing mini batch 617, training error = 0.078125, loss = 0.1899874210357666\n","Epoch 43: finishing mini batch 618, training error = 0.015625, loss = 0.059812281280756\n","Epoch 43: finishing mini batch 619, training error = 0.09375, loss = 0.2084450125694275\n","Epoch 43: finishing mini batch 620, training error = 0.03125, loss = 0.05866929888725281\n","Epoch 43: finishing mini batch 621, training error = 0.0625, loss = 0.14095845818519592\n","Epoch 43: finishing mini batch 622, training error = 0.078125, loss = 0.176622211933136\n","Epoch 43: finishing mini batch 623, training error = 0.015625, loss = 0.07452696561813354\n","Epoch 43: finishing mini batch 624, training error = 0.03125, loss = 0.15499109029769897\n","Epoch 43: finishing mini batch 625, training error = 0.0625, loss = 0.21487794816493988\n","Epoch 43: finishing mini batch 626, training error = 0.015625, loss = 0.06580764055252075\n","Epoch 43: finishing mini batch 627, training error = 0.078125, loss = 0.17784634232521057\n","Epoch 43: finishing mini batch 628, training error = 0.046875, loss = 0.1453953981399536\n","Epoch 43: finishing mini batch 629, training error = 0.015625, loss = 0.07795342803001404\n","Epoch 43: finishing mini batch 630, training error = 0.03125, loss = 0.09943045675754547\n","Epoch 43: finishing mini batch 631, training error = 0.015625, loss = 0.045659713447093964\n","Epoch 43: finishing mini batch 632, training error = 0.015625, loss = 0.09062715619802475\n","Epoch 43: finishing mini batch 633, training error = 0.078125, loss = 0.20386844873428345\n","Epoch 43: finishing mini batch 634, training error = 0.046875, loss = 0.15926507115364075\n","Epoch 43: finishing mini batch 635, training error = 0.03125, loss = 0.11648030579090118\n","Epoch 43: finishing mini batch 636, training error = 0.015625, loss = 0.06137131527066231\n","Epoch 43: finishing mini batch 637, training error = 0.09375, loss = 0.2225879430770874\n","Epoch 43: finishing mini batch 638, training error = 0.046875, loss = 0.1032257080078125\n","Epoch 43: finishing mini batch 639, training error = 0.0625, loss = 0.17203572392463684\n","Epoch 43: finishing mini batch 640, training error = 0.0625, loss = 0.2071453332901001\n","Epoch 43: finishing mini batch 641, training error = 0.046875, loss = 0.10246174037456512\n","Epoch 43: finishing mini batch 642, training error = 0.078125, loss = 0.1770033985376358\n","Epoch 43: finishing mini batch 643, training error = 0.015625, loss = 0.05763539299368858\n","Epoch 43: finishing mini batch 644, training error = 0.078125, loss = 0.2499127984046936\n","Epoch 43: finishing mini batch 645, training error = 0.078125, loss = 0.22483475506305695\n","Epoch 43: finishing mini batch 646, training error = 0.125, loss = 0.3100900948047638\n","Epoch 43: finishing mini batch 647, training error = 0.0625, loss = 0.14760805666446686\n","Epoch 43: finishing mini batch 648, training error = 0.0, loss = 0.03875020518898964\n","Epoch 43: finishing mini batch 649, training error = 0.03125, loss = 0.0721602737903595\n","Epoch 43: finishing mini batch 650, training error = 0.03125, loss = 0.0759965181350708\n","Epoch 43: finishing mini batch 651, training error = 0.078125, loss = 0.18325601518154144\n","Epoch 43: finishing mini batch 652, training error = 0.09375, loss = 0.17051532864570618\n","Epoch 43: finishing mini batch 653, training error = 0.078125, loss = 0.18340730667114258\n","Epoch 43: finishing mini batch 654, training error = 0.078125, loss = 0.16317887604236603\n","Epoch 43: finishing mini batch 655, training error = 0.140625, loss = 0.3794102668762207\n","Epoch 43: finishing mini batch 656, training error = 0.046875, loss = 0.12029404193162918\n","Epoch 43: finishing mini batch 657, training error = 0.03125, loss = 0.10526873916387558\n","Epoch 43: finishing mini batch 658, training error = 0.03125, loss = 0.19208107888698578\n","Epoch 43: finishing mini batch 659, training error = 0.015625, loss = 0.09218950569629669\n","Epoch 43: finishing mini batch 660, training error = 0.0625, loss = 0.18607521057128906\n","Epoch 43: finishing mini batch 661, training error = 0.015625, loss = 0.1493881493806839\n","Epoch 43: finishing mini batch 662, training error = 0.0625, loss = 0.15219488739967346\n","Epoch 43: finishing mini batch 663, training error = 0.109375, loss = 0.304361492395401\n","Epoch 43: finishing mini batch 664, training error = 0.046875, loss = 0.17507146298885345\n","Epoch 43: finishing mini batch 665, training error = 0.09375, loss = 0.171108216047287\n","Epoch 43: finishing mini batch 666, training error = 0.0625, loss = 0.2315003126859665\n","Epoch 43: finishing mini batch 667, training error = 0.078125, loss = 0.19540855288505554\n","Epoch 43: finishing mini batch 668, training error = 0.046875, loss = 0.1665230542421341\n","Epoch 43: finishing mini batch 669, training error = 0.078125, loss = 0.15246941149234772\n","Epoch 43: finishing mini batch 670, training error = 0.0625, loss = 0.19153717160224915\n","Epoch 43: finishing mini batch 671, training error = 0.015625, loss = 0.060933854430913925\n","Epoch 43: finishing mini batch 672, training error = 0.0625, loss = 0.12437380850315094\n","Epoch 43: finishing mini batch 673, training error = 0.046875, loss = 0.09181046485900879\n","Epoch 43: finishing mini batch 674, training error = 0.046875, loss = 0.10168209671974182\n","Epoch 43: finishing mini batch 675, training error = 0.03125, loss = 0.08376838266849518\n","Epoch 43: finishing mini batch 676, training error = 0.078125, loss = 0.22323507070541382\n","Epoch 43: finishing mini batch 677, training error = 0.125, loss = 0.26091063022613525\n","Epoch 43: finishing mini batch 678, training error = 0.109375, loss = 0.23791256546974182\n","Epoch 43: finishing mini batch 679, training error = 0.078125, loss = 0.18152746558189392\n","Epoch 43: finishing mini batch 680, training error = 0.09375, loss = 0.18167853355407715\n","Epoch 43: finishing mini batch 681, training error = 0.046875, loss = 0.19034287333488464\n","Epoch 43: finishing mini batch 682, training error = 0.09375, loss = 0.20202456414699554\n","Epoch 43: finishing mini batch 683, training error = 0.046875, loss = 0.11862966418266296\n","Epoch 43: finishing mini batch 684, training error = 0.03125, loss = 0.12077847868204117\n","Epoch 43: finishing mini batch 685, training error = 0.03125, loss = 0.12651315331459045\n","Epoch 43: finishing mini batch 686, training error = 0.0625, loss = 0.12122183293104172\n","Epoch 43: finishing mini batch 687, training error = 0.0625, loss = 0.1937505155801773\n","Epoch 43: finishing mini batch 688, training error = 0.0625, loss = 0.18000560998916626\n","Epoch 43: finishing mini batch 689, training error = 0.09375, loss = 0.264029860496521\n","Epoch 43: finishing mini batch 690, training error = 0.078125, loss = 0.21232512593269348\n","Epoch 43: finishing mini batch 691, training error = 0.0, loss = 0.0389275886118412\n","Epoch 43: finishing mini batch 692, training error = 0.109375, loss = 0.2996566891670227\n","Epoch 43: finishing mini batch 693, training error = 0.078125, loss = 0.20381416380405426\n","Epoch 43: finishing mini batch 694, training error = 0.078125, loss = 0.17123103141784668\n","Epoch 43: finishing mini batch 695, training error = 0.0625, loss = 0.14632673561573029\n","Epoch 43: finishing mini batch 696, training error = 0.0, loss = 0.056548867374658585\n","Epoch 43: finishing mini batch 697, training error = 0.09375, loss = 0.23060829937458038\n","Epoch 43: finishing mini batch 698, training error = 0.09375, loss = 0.2674626111984253\n","Epoch 43: finishing mini batch 699, training error = 0.09375, loss = 0.23598702251911163\n","Epoch 43: finishing mini batch 700, training error = 0.09375, loss = 0.20065847039222717\n","Epoch 43: finishing mini batch 701, training error = 0.046875, loss = 0.1242312639951706\n","Epoch 43: finishing mini batch 702, training error = 0.03125, loss = 0.14370222389698029\n","Epoch 43: finishing mini batch 703, training error = 0.109375, loss = 0.2664409279823303\n","Epoch 43: finishing mini batch 704, training error = 0.03125, loss = 0.1072029396891594\n","Epoch 43: finishing mini batch 705, training error = 0.078125, loss = 0.17985323071479797\n","Epoch 43: finishing mini batch 706, training error = 0.09375, loss = 0.3573988378047943\n","Epoch 43: finishing mini batch 707, training error = 0.046875, loss = 0.1304509937763214\n","Epoch 43: finishing mini batch 708, training error = 0.03125, loss = 0.0661339983344078\n","Epoch 43: finishing mini batch 709, training error = 0.078125, loss = 0.18222901225090027\n","Epoch 43: finishing mini batch 710, training error = 0.078125, loss = 0.15955732762813568\n","Epoch 43: finishing mini batch 711, training error = 0.09375, loss = 0.13872668147087097\n","Epoch 43: finishing mini batch 712, training error = 0.046875, loss = 0.15111254155635834\n","Epoch 43: finishing mini batch 713, training error = 0.078125, loss = 0.21104402840137482\n","Epoch 43: finishing mini batch 714, training error = 0.0625, loss = 0.1512296199798584\n","Epoch 43: finishing mini batch 715, training error = 0.015625, loss = 0.08335054665803909\n","Epoch 43: finishing mini batch 716, training error = 0.046875, loss = 0.2110481709241867\n","Epoch 43: finishing mini batch 717, training error = 0.046875, loss = 0.13332206010818481\n","Epoch 43: finishing mini batch 718, training error = 0.03125, loss = 0.1515032798051834\n","Epoch 43: finishing mini batch 719, training error = 0.03125, loss = 0.13194522261619568\n","Epoch 43: finishing mini batch 720, training error = 0.046875, loss = 0.12983140349388123\n","Epoch 43: finishing mini batch 721, training error = 0.0625, loss = 0.21357807517051697\n","Epoch 43: finishing mini batch 722, training error = 0.03125, loss = 0.1511688530445099\n","Epoch 43: finishing mini batch 723, training error = 0.078125, loss = 0.20621538162231445\n","Epoch 43: finishing mini batch 724, training error = 0.0625, loss = 0.17541974782943726\n","Epoch 43: finishing mini batch 725, training error = 0.046875, loss = 0.10170365869998932\n","Epoch 43: finishing mini batch 726, training error = 0.046875, loss = 0.15831302106380463\n","Epoch 43: finishing mini batch 727, training error = 0.046875, loss = 0.2154228687286377\n","Epoch 43: finishing mini batch 728, training error = 0.015625, loss = 0.12268606573343277\n","Epoch 43: finishing mini batch 729, training error = 0.09375, loss = 0.17247554659843445\n","Epoch 43: finishing mini batch 730, training error = 0.046875, loss = 0.20316888391971588\n","Epoch 43: finishing mini batch 731, training error = 0.03125, loss = 0.13097327947616577\n","Epoch 43: finishing mini batch 732, training error = 0.078125, loss = 0.1761796921491623\n","Epoch 43: finishing mini batch 733, training error = 0.046875, loss = 0.18747186660766602\n","Epoch 43: finishing mini batch 734, training error = 0.0625, loss = 0.12259630858898163\n","Epoch 43: finishing mini batch 735, training error = 0.0625, loss = 0.1719018518924713\n","Epoch 43: finishing mini batch 736, training error = 0.03125, loss = 0.13562963902950287\n","Epoch 43: finishing mini batch 737, training error = 0.03125, loss = 0.12321947515010834\n","Epoch 43: finishing mini batch 738, training error = 0.015625, loss = 0.041791755706071854\n","Epoch 43: finishing mini batch 739, training error = 0.0625, loss = 0.15730752050876617\n","Epoch 43: finishing mini batch 740, training error = 0.015625, loss = 0.11340028792619705\n","Epoch 43: finishing mini batch 741, training error = 0.09375, loss = 0.3620953857898712\n","Epoch 43: finishing mini batch 742, training error = 0.046875, loss = 0.1378268003463745\n","Epoch 43: finishing mini batch 743, training error = 0.078125, loss = 0.14633595943450928\n","Epoch 43: finishing mini batch 744, training error = 0.015625, loss = 0.09428420662879944\n","Epoch 43: finishing mini batch 745, training error = 0.015625, loss = 0.0738954171538353\n","Epoch 43: finishing mini batch 746, training error = 0.046875, loss = 0.13576386868953705\n","Epoch 43: finishing mini batch 747, training error = 0.0, loss = 0.03448387235403061\n","Epoch 43: finishing mini batch 748, training error = 0.046875, loss = 0.1612052619457245\n","Epoch 43: finishing mini batch 749, training error = 0.03125, loss = 0.08375243097543716\n","Epoch 43: finishing mini batch 750, training error = 0.109375, loss = 0.2704574763774872\n","Epoch 43: finishing mini batch 751, training error = 0.046875, loss = 0.11670605838298798\n","Epoch 43: finishing mini batch 752, training error = 0.046875, loss = 0.23372794687747955\n","Epoch 43: finishing mini batch 753, training error = 0.0625, loss = 0.30852600932121277\n","Epoch 43: finishing mini batch 754, training error = 0.0625, loss = 0.13014794886112213\n","Epoch 43: finishing mini batch 755, training error = 0.078125, loss = 0.17625878751277924\n","Epoch 43: finishing mini batch 756, training error = 0.03125, loss = 0.07744444161653519\n","Epoch 43: finishing mini batch 757, training error = 0.0625, loss = 0.15037856996059418\n","Epoch 43: finishing mini batch 758, training error = 0.03125, loss = 0.1132802963256836\n","Epoch 43: finishing mini batch 759, training error = 0.046875, loss = 0.1321031004190445\n","Epoch 43: finishing mini batch 760, training error = 0.046875, loss = 0.11335764080286026\n","Epoch 43: finishing mini batch 761, training error = 0.015625, loss = 0.11984794586896896\n","Epoch 43: finishing mini batch 762, training error = 0.046875, loss = 0.1258396953344345\n","Epoch 43: finishing mini batch 763, training error = 0.078125, loss = 0.19271425902843475\n","Epoch 43: finishing mini batch 764, training error = 0.03125, loss = 0.13255098462104797\n","Epoch 43: finishing mini batch 765, training error = 0.109375, loss = 0.1961214542388916\n","Epoch 43: finishing mini batch 766, training error = 0.046875, loss = 0.1128963828086853\n","Epoch 43: finishing mini batch 767, training error = 0.109375, loss = 0.2861088514328003\n","Epoch 43: finishing mini batch 768, training error = 0.015625, loss = 0.08040940761566162\n","Epoch 43: finishing mini batch 769, training error = 0.03125, loss = 0.08928363770246506\n","Epoch 43: finishing mini batch 770, training error = 0.03125, loss = 0.09687845408916473\n","Epoch 43: finishing mini batch 771, training error = 0.015625, loss = 0.08156673610210419\n","Epoch 43: finishing mini batch 772, training error = 0.0625, loss = 0.1890232115983963\n","Epoch 43: finishing mini batch 773, training error = 0.09375, loss = 0.22119136154651642\n","Epoch 43: finishing mini batch 774, training error = 0.03125, loss = 0.0966920331120491\n","Epoch 43: finishing mini batch 775, training error = 0.046875, loss = 0.14871765673160553\n","Epoch 43: finishing mini batch 776, training error = 0.0625, loss = 0.2046482414007187\n","Epoch 43: finishing mini batch 777, training error = 0.046875, loss = 0.15062230825424194\n","Epoch 43: finishing mini batch 778, training error = 0.03125, loss = 0.07700355350971222\n","Epoch 43: finishing mini batch 779, training error = 0.0625, loss = 0.1798011064529419\n","Epoch 43: finishing mini batch 780, training error = 0.03125, loss = 0.10705125331878662\n","Epoch 43: finishing mini batch 781, training error = 0.0625, loss = 0.18939881026744843\n","Epoch 43: finishing mini batch 782, training error = 0.0625, loss = 0.1378479301929474\n","Epoch 43 completed, acc_loss = 115.9532439019531\n","Starting epoch 44...\n","Epoch 44: finishing mini batch 1, training error = 0.03125, loss = 0.08152611553668976\n","Epoch 44: finishing mini batch 2, training error = 0.03125, loss = 0.10775354504585266\n","Epoch 44: finishing mini batch 3, training error = 0.0625, loss = 0.15800468623638153\n","Epoch 44: finishing mini batch 4, training error = 0.046875, loss = 0.09154810011386871\n","Epoch 44: finishing mini batch 5, training error = 0.046875, loss = 0.1746029555797577\n","Epoch 44: finishing mini batch 6, training error = 0.078125, loss = 0.18243490159511566\n","Epoch 44: finishing mini batch 7, training error = 0.09375, loss = 0.20827466249465942\n","Epoch 44: finishing mini batch 8, training error = 0.046875, loss = 0.15948203206062317\n","Epoch 44: finishing mini batch 9, training error = 0.109375, loss = 0.2911500632762909\n","Epoch 44: finishing mini batch 10, training error = 0.0625, loss = 0.11409484595060349\n","Epoch 44: finishing mini batch 11, training error = 0.015625, loss = 0.09606745094060898\n","Epoch 44: finishing mini batch 12, training error = 0.015625, loss = 0.0839017927646637\n","Epoch 44: finishing mini batch 13, training error = 0.0625, loss = 0.10157081484794617\n","Epoch 44: finishing mini batch 14, training error = 0.078125, loss = 0.2252810150384903\n","Epoch 44: finishing mini batch 15, training error = 0.015625, loss = 0.17718099057674408\n","Epoch 44: finishing mini batch 16, training error = 0.03125, loss = 0.0924222469329834\n","Epoch 44: finishing mini batch 17, training error = 0.015625, loss = 0.11107660830020905\n","Epoch 44: finishing mini batch 18, training error = 0.03125, loss = 0.1184808611869812\n","Epoch 44: finishing mini batch 19, training error = 0.109375, loss = 0.3056078255176544\n","Epoch 44: finishing mini batch 20, training error = 0.03125, loss = 0.07995939254760742\n","Epoch 44: finishing mini batch 21, training error = 0.0625, loss = 0.12933504581451416\n","Epoch 44: finishing mini batch 22, training error = 0.015625, loss = 0.10437402129173279\n","Epoch 44: finishing mini batch 23, training error = 0.015625, loss = 0.10017076134681702\n","Epoch 44: finishing mini batch 24, training error = 0.03125, loss = 0.11834080517292023\n","Epoch 44: finishing mini batch 25, training error = 0.015625, loss = 0.06513199210166931\n","Epoch 44: finishing mini batch 26, training error = 0.046875, loss = 0.16270285844802856\n","Epoch 44: finishing mini batch 27, training error = 0.078125, loss = 0.21290047466754913\n","Epoch 44: finishing mini batch 28, training error = 0.046875, loss = 0.20734505355358124\n","Epoch 44: finishing mini batch 29, training error = 0.046875, loss = 0.20832780003547668\n","Epoch 44: finishing mini batch 30, training error = 0.046875, loss = 0.08579514920711517\n","Epoch 44: finishing mini batch 31, training error = 0.03125, loss = 0.14007259905338287\n","Epoch 44: finishing mini batch 32, training error = 0.046875, loss = 0.09283821284770966\n","Epoch 44: finishing mini batch 33, training error = 0.0625, loss = 0.18438510596752167\n","Epoch 44: finishing mini batch 34, training error = 0.03125, loss = 0.0673450231552124\n","Epoch 44: finishing mini batch 35, training error = 0.0625, loss = 0.21165359020233154\n","Epoch 44: finishing mini batch 36, training error = 0.03125, loss = 0.07425431162118912\n","Epoch 44: finishing mini batch 37, training error = 0.046875, loss = 0.1209680438041687\n","Epoch 44: finishing mini batch 38, training error = 0.0625, loss = 0.1248249039053917\n","Epoch 44: finishing mini batch 39, training error = 0.0625, loss = 0.16026830673217773\n","Epoch 44: finishing mini batch 40, training error = 0.0625, loss = 0.18122035264968872\n","Epoch 44: finishing mini batch 41, training error = 0.0625, loss = 0.20664048194885254\n","Epoch 44: finishing mini batch 42, training error = 0.046875, loss = 0.16399775445461273\n","Epoch 44: finishing mini batch 43, training error = 0.046875, loss = 0.11464717984199524\n","Epoch 44: finishing mini batch 44, training error = 0.0, loss = 0.06611590087413788\n","Epoch 44: finishing mini batch 45, training error = 0.03125, loss = 0.11506497859954834\n","Epoch 44: finishing mini batch 46, training error = 0.046875, loss = 0.13741254806518555\n","Epoch 44: finishing mini batch 47, training error = 0.0625, loss = 0.12593860924243927\n","Epoch 44: finishing mini batch 48, training error = 0.03125, loss = 0.06976179778575897\n","Epoch 44: finishing mini batch 49, training error = 0.03125, loss = 0.1189207062125206\n","Epoch 44: finishing mini batch 50, training error = 0.015625, loss = 0.05258207395672798\n","Epoch 44: finishing mini batch 51, training error = 0.046875, loss = 0.2087956666946411\n","Epoch 44: finishing mini batch 52, training error = 0.03125, loss = 0.09984076768159866\n","Epoch 44: finishing mini batch 53, training error = 0.0625, loss = 0.15067192912101746\n","Epoch 44: finishing mini batch 54, training error = 0.03125, loss = 0.08584266155958176\n","Epoch 44: finishing mini batch 55, training error = 0.046875, loss = 0.13562129437923431\n","Epoch 44: finishing mini batch 56, training error = 0.015625, loss = 0.09255938977003098\n","Epoch 44: finishing mini batch 57, training error = 0.046875, loss = 0.12096545845270157\n","Epoch 44: finishing mini batch 58, training error = 0.046875, loss = 0.09411004930734634\n","Epoch 44: finishing mini batch 59, training error = 0.078125, loss = 0.17888571321964264\n","Epoch 44: finishing mini batch 60, training error = 0.109375, loss = 0.22769878804683685\n","Epoch 44: finishing mini batch 61, training error = 0.046875, loss = 0.20840486884117126\n","Epoch 44: finishing mini batch 62, training error = 0.046875, loss = 0.12486244738101959\n","Epoch 44: finishing mini batch 63, training error = 0.03125, loss = 0.08230125159025192\n","Epoch 44: finishing mini batch 64, training error = 0.09375, loss = 0.17389605939388275\n","Epoch 44: finishing mini batch 65, training error = 0.03125, loss = 0.13723377883434296\n","Epoch 44: finishing mini batch 66, training error = 0.015625, loss = 0.05612052604556084\n","Epoch 44: finishing mini batch 67, training error = 0.0625, loss = 0.19920594990253448\n","Epoch 44: finishing mini batch 68, training error = 0.046875, loss = 0.11373826861381531\n","Epoch 44: finishing mini batch 69, training error = 0.078125, loss = 0.18545502424240112\n","Epoch 44: finishing mini batch 70, training error = 0.046875, loss = 0.09867548942565918\n","Epoch 44: finishing mini batch 71, training error = 0.0625, loss = 0.12080388516187668\n","Epoch 44: finishing mini batch 72, training error = 0.078125, loss = 0.13462615013122559\n","Epoch 44: finishing mini batch 73, training error = 0.0625, loss = 0.1711466759443283\n","Epoch 44: finishing mini batch 74, training error = 0.0625, loss = 0.08869288116693497\n","Epoch 44: finishing mini batch 75, training error = 0.0625, loss = 0.12367681413888931\n","Epoch 44: finishing mini batch 76, training error = 0.015625, loss = 0.10966465622186661\n","Epoch 44: finishing mini batch 77, training error = 0.078125, loss = 0.13860517740249634\n","Epoch 44: finishing mini batch 78, training error = 0.0625, loss = 0.15130342543125153\n","Epoch 44: finishing mini batch 79, training error = 0.046875, loss = 0.10987845808267593\n","Epoch 44: finishing mini batch 80, training error = 0.046875, loss = 0.18078774213790894\n","Epoch 44: finishing mini batch 81, training error = 0.078125, loss = 0.1434524804353714\n","Epoch 44: finishing mini batch 82, training error = 0.03125, loss = 0.09807522594928741\n","Epoch 44: finishing mini batch 83, training error = 0.03125, loss = 0.08066342771053314\n","Epoch 44: finishing mini batch 84, training error = 0.0625, loss = 0.16284383833408356\n","Epoch 44: finishing mini batch 85, training error = 0.078125, loss = 0.16479896008968353\n","Epoch 44: finishing mini batch 86, training error = 0.0625, loss = 0.14274634420871735\n","Epoch 44: finishing mini batch 87, training error = 0.015625, loss = 0.061651311814785004\n","Epoch 44: finishing mini batch 88, training error = 0.0, loss = 0.036849670112133026\n","Epoch 44: finishing mini batch 89, training error = 0.03125, loss = 0.07805722951889038\n","Epoch 44: finishing mini batch 90, training error = 0.03125, loss = 0.0780290737748146\n","Epoch 44: finishing mini batch 91, training error = 0.0625, loss = 0.14687539637088776\n","Epoch 44: finishing mini batch 92, training error = 0.015625, loss = 0.061739400029182434\n","Epoch 44: finishing mini batch 93, training error = 0.03125, loss = 0.10728883743286133\n","Epoch 44: finishing mini batch 94, training error = 0.0625, loss = 0.1932527869939804\n","Epoch 44: finishing mini batch 95, training error = 0.09375, loss = 0.2817560136318207\n","Epoch 44: finishing mini batch 96, training error = 0.0625, loss = 0.13099585473537445\n","Epoch 44: finishing mini batch 97, training error = 0.0, loss = 0.023731771856546402\n","Epoch 44: finishing mini batch 98, training error = 0.03125, loss = 0.12374363094568253\n","Epoch 44: finishing mini batch 99, training error = 0.03125, loss = 0.0981581062078476\n","Epoch 44: finishing mini batch 100, training error = 0.03125, loss = 0.10577727854251862\n","Epoch 44: finishing mini batch 101, training error = 0.078125, loss = 0.11105683445930481\n","Epoch 44: finishing mini batch 102, training error = 0.078125, loss = 0.19894886016845703\n","Epoch 44: finishing mini batch 103, training error = 0.015625, loss = 0.106967031955719\n","Epoch 44: finishing mini batch 104, training error = 0.078125, loss = 0.1722441464662552\n","Epoch 44: finishing mini batch 105, training error = 0.0, loss = 0.068144790828228\n","Epoch 44: finishing mini batch 106, training error = 0.109375, loss = 0.2374039739370346\n","Epoch 44: finishing mini batch 107, training error = 0.046875, loss = 0.17250852286815643\n","Epoch 44: finishing mini batch 108, training error = 0.015625, loss = 0.047398678958415985\n","Epoch 44: finishing mini batch 109, training error = 0.09375, loss = 0.12238306552171707\n","Epoch 44: finishing mini batch 110, training error = 0.0625, loss = 0.10991412401199341\n","Epoch 44: finishing mini batch 111, training error = 0.046875, loss = 0.21356424689292908\n","Epoch 44: finishing mini batch 112, training error = 0.0625, loss = 0.13654546439647675\n","Epoch 44: finishing mini batch 113, training error = 0.0625, loss = 0.14094200730323792\n","Epoch 44: finishing mini batch 114, training error = 0.046875, loss = 0.11363588273525238\n","Epoch 44: finishing mini batch 115, training error = 0.09375, loss = 0.17615701258182526\n","Epoch 44: finishing mini batch 116, training error = 0.046875, loss = 0.09116874635219574\n","Epoch 44: finishing mini batch 117, training error = 0.0625, loss = 0.1502269059419632\n","Epoch 44: finishing mini batch 118, training error = 0.0625, loss = 0.10991392284631729\n","Epoch 44: finishing mini batch 119, training error = 0.078125, loss = 0.16178400814533234\n","Epoch 44: finishing mini batch 120, training error = 0.03125, loss = 0.10251542180776596\n","Epoch 44: finishing mini batch 121, training error = 0.046875, loss = 0.11395807564258575\n","Epoch 44: finishing mini batch 122, training error = 0.015625, loss = 0.06879730522632599\n","Epoch 44: finishing mini batch 123, training error = 0.015625, loss = 0.06732642650604248\n","Epoch 44: finishing mini batch 124, training error = 0.03125, loss = 0.07984661310911179\n","Epoch 44: finishing mini batch 125, training error = 0.0625, loss = 0.1286914050579071\n","Epoch 44: finishing mini batch 126, training error = 0.046875, loss = 0.10524483025074005\n","Epoch 44: finishing mini batch 127, training error = 0.0, loss = 0.04066921025514603\n","Epoch 44: finishing mini batch 128, training error = 0.015625, loss = 0.09211930632591248\n","Epoch 44: finishing mini batch 129, training error = 0.03125, loss = 0.14464493095874786\n","Epoch 44: finishing mini batch 130, training error = 0.078125, loss = 0.16370610892772675\n","Epoch 44: finishing mini batch 131, training error = 0.046875, loss = 0.07755327969789505\n","Epoch 44: finishing mini batch 132, training error = 0.046875, loss = 0.12215983122587204\n","Epoch 44: finishing mini batch 133, training error = 0.03125, loss = 0.12990832328796387\n","Epoch 44: finishing mini batch 134, training error = 0.03125, loss = 0.077105313539505\n","Epoch 44: finishing mini batch 135, training error = 0.015625, loss = 0.060260772705078125\n","Epoch 44: finishing mini batch 136, training error = 0.0, loss = 0.03352012112736702\n","Epoch 44: finishing mini batch 137, training error = 0.03125, loss = 0.06161996349692345\n","Epoch 44: finishing mini batch 138, training error = 0.03125, loss = 0.08124212175607681\n","Epoch 44: finishing mini batch 139, training error = 0.015625, loss = 0.0964113399386406\n","Epoch 44: finishing mini batch 140, training error = 0.03125, loss = 0.111021026968956\n","Epoch 44: finishing mini batch 141, training error = 0.046875, loss = 0.1470535844564438\n","Epoch 44: finishing mini batch 142, training error = 0.046875, loss = 0.14230528473854065\n","Epoch 44: finishing mini batch 143, training error = 0.046875, loss = 0.17178961634635925\n","Epoch 44: finishing mini batch 144, training error = 0.03125, loss = 0.1690700352191925\n","Epoch 44: finishing mini batch 145, training error = 0.0625, loss = 0.1532910168170929\n","Epoch 44: finishing mini batch 146, training error = 0.046875, loss = 0.12407231330871582\n","Epoch 44: finishing mini batch 147, training error = 0.015625, loss = 0.07978280633687973\n","Epoch 44: finishing mini batch 148, training error = 0.078125, loss = 0.19387821853160858\n","Epoch 44: finishing mini batch 149, training error = 0.078125, loss = 0.18516722321510315\n","Epoch 44: finishing mini batch 150, training error = 0.046875, loss = 0.1090727150440216\n","Epoch 44: finishing mini batch 151, training error = 0.046875, loss = 0.1219913512468338\n","Epoch 44: finishing mini batch 152, training error = 0.078125, loss = 0.18199922144412994\n","Epoch 44: finishing mini batch 153, training error = 0.046875, loss = 0.1463879644870758\n","Epoch 44: finishing mini batch 154, training error = 0.0625, loss = 0.17960885167121887\n","Epoch 44: finishing mini batch 155, training error = 0.046875, loss = 0.11743618547916412\n","Epoch 44: finishing mini batch 156, training error = 0.109375, loss = 0.2033461034297943\n","Epoch 44: finishing mini batch 157, training error = 0.03125, loss = 0.10230380296707153\n","Epoch 44: finishing mini batch 158, training error = 0.046875, loss = 0.10811515897512436\n","Epoch 44: finishing mini batch 159, training error = 0.03125, loss = 0.0710679367184639\n","Epoch 44: finishing mini batch 160, training error = 0.0625, loss = 0.27925676107406616\n","Epoch 44: finishing mini batch 161, training error = 0.03125, loss = 0.1226041242480278\n","Epoch 44: finishing mini batch 162, training error = 0.078125, loss = 0.23806031048297882\n","Epoch 44: finishing mini batch 163, training error = 0.0, loss = 0.04875209182500839\n","Epoch 44: finishing mini batch 164, training error = 0.09375, loss = 0.2744954228401184\n","Epoch 44: finishing mini batch 165, training error = 0.015625, loss = 0.10185063630342484\n","Epoch 44: finishing mini batch 166, training error = 0.0625, loss = 0.1245570033788681\n","Epoch 44: finishing mini batch 167, training error = 0.03125, loss = 0.07978001981973648\n","Epoch 44: finishing mini batch 168, training error = 0.09375, loss = 0.221982941031456\n","Epoch 44: finishing mini batch 169, training error = 0.03125, loss = 0.13208502531051636\n","Epoch 44: finishing mini batch 170, training error = 0.09375, loss = 0.22387416660785675\n","Epoch 44: finishing mini batch 171, training error = 0.03125, loss = 0.0794549211859703\n","Epoch 44: finishing mini batch 172, training error = 0.03125, loss = 0.08195491135120392\n","Epoch 44: finishing mini batch 173, training error = 0.0625, loss = 0.1529332846403122\n","Epoch 44: finishing mini batch 174, training error = 0.046875, loss = 0.0862138643860817\n","Epoch 44: finishing mini batch 175, training error = 0.046875, loss = 0.09171111136674881\n","Epoch 44: finishing mini batch 176, training error = 0.046875, loss = 0.14791817963123322\n","Epoch 44: finishing mini batch 177, training error = 0.078125, loss = 0.18745563924312592\n","Epoch 44: finishing mini batch 178, training error = 0.0, loss = 0.047359149903059006\n","Epoch 44: finishing mini batch 179, training error = 0.046875, loss = 0.12291602790355682\n","Epoch 44: finishing mini batch 180, training error = 0.09375, loss = 0.27890583872795105\n","Epoch 44: finishing mini batch 181, training error = 0.0625, loss = 0.13817591965198517\n","Epoch 44: finishing mini batch 182, training error = 0.078125, loss = 0.15519331395626068\n","Epoch 44: finishing mini batch 183, training error = 0.015625, loss = 0.06943178921937943\n","Epoch 44: finishing mini batch 184, training error = 0.109375, loss = 0.2237730324268341\n","Epoch 44: finishing mini batch 185, training error = 0.03125, loss = 0.11922520399093628\n","Epoch 44: finishing mini batch 186, training error = 0.046875, loss = 0.09913655370473862\n","Epoch 44: finishing mini batch 187, training error = 0.078125, loss = 0.12446972727775574\n","Epoch 44: finishing mini batch 188, training error = 0.046875, loss = 0.16174286603927612\n","Epoch 44: finishing mini batch 189, training error = 0.078125, loss = 0.20883414149284363\n","Epoch 44: finishing mini batch 190, training error = 0.078125, loss = 0.33093389868736267\n","Epoch 44: finishing mini batch 191, training error = 0.046875, loss = 0.10753010213375092\n","Epoch 44: finishing mini batch 192, training error = 0.0625, loss = 0.1588202863931656\n","Epoch 44: finishing mini batch 193, training error = 0.078125, loss = 0.13302326202392578\n","Epoch 44: finishing mini batch 194, training error = 0.046875, loss = 0.10800915211439133\n","Epoch 44: finishing mini batch 195, training error = 0.078125, loss = 0.1989814192056656\n","Epoch 44: finishing mini batch 196, training error = 0.0625, loss = 0.20946067571640015\n","Epoch 44: finishing mini batch 197, training error = 0.03125, loss = 0.1187504455447197\n","Epoch 44: finishing mini batch 198, training error = 0.015625, loss = 0.08717745542526245\n","Epoch 44: finishing mini batch 199, training error = 0.015625, loss = 0.0682845339179039\n","Epoch 44: finishing mini batch 200, training error = 0.078125, loss = 0.1813017725944519\n","Epoch 44: finishing mini batch 201, training error = 0.0625, loss = 0.15183700621128082\n","Epoch 44: finishing mini batch 202, training error = 0.078125, loss = 0.1432693898677826\n","Epoch 44: finishing mini batch 203, training error = 0.03125, loss = 0.06958776712417603\n","Epoch 44: finishing mini batch 204, training error = 0.015625, loss = 0.061186064034700394\n","Epoch 44: finishing mini batch 205, training error = 0.0625, loss = 0.12017910182476044\n","Epoch 44: finishing mini batch 206, training error = 0.078125, loss = 0.12284474819898605\n","Epoch 44: finishing mini batch 207, training error = 0.09375, loss = 0.24835830926895142\n","Epoch 44: finishing mini batch 208, training error = 0.046875, loss = 0.10923971235752106\n","Epoch 44: finishing mini batch 209, training error = 0.046875, loss = 0.12507617473602295\n","Epoch 44: finishing mini batch 210, training error = 0.03125, loss = 0.13061842322349548\n","Epoch 44: finishing mini batch 211, training error = 0.0, loss = 0.06493570655584335\n","Epoch 44: finishing mini batch 212, training error = 0.078125, loss = 0.20517529547214508\n","Epoch 44: finishing mini batch 213, training error = 0.046875, loss = 0.11806180328130722\n","Epoch 44: finishing mini batch 214, training error = 0.0625, loss = 0.16124720871448517\n","Epoch 44: finishing mini batch 215, training error = 0.046875, loss = 0.1957068294286728\n","Epoch 44: finishing mini batch 216, training error = 0.046875, loss = 0.08628934621810913\n","Epoch 44: finishing mini batch 217, training error = 0.078125, loss = 0.1571350395679474\n","Epoch 44: finishing mini batch 218, training error = 0.03125, loss = 0.07228528708219528\n","Epoch 44: finishing mini batch 219, training error = 0.046875, loss = 0.13862620294094086\n","Epoch 44: finishing mini batch 220, training error = 0.03125, loss = 0.12644056975841522\n","Epoch 44: finishing mini batch 221, training error = 0.09375, loss = 0.13230985403060913\n","Epoch 44: finishing mini batch 222, training error = 0.0625, loss = 0.09940686821937561\n","Epoch 44: finishing mini batch 223, training error = 0.09375, loss = 0.18354400992393494\n","Epoch 44: finishing mini batch 224, training error = 0.015625, loss = 0.07495748996734619\n","Epoch 44: finishing mini batch 225, training error = 0.015625, loss = 0.08524632453918457\n","Epoch 44: finishing mini batch 226, training error = 0.078125, loss = 0.21351879835128784\n","Epoch 44: finishing mini batch 227, training error = 0.03125, loss = 0.10246021300554276\n","Epoch 44: finishing mini batch 228, training error = 0.015625, loss = 0.07248453795909882\n","Epoch 44: finishing mini batch 229, training error = 0.03125, loss = 0.12014476209878922\n","Epoch 44: finishing mini batch 230, training error = 0.046875, loss = 0.17224456369876862\n","Epoch 44: finishing mini batch 231, training error = 0.03125, loss = 0.09990042448043823\n","Epoch 44: finishing mini batch 232, training error = 0.0625, loss = 0.13894686102867126\n","Epoch 44: finishing mini batch 233, training error = 0.03125, loss = 0.08099477738142014\n","Epoch 44: finishing mini batch 234, training error = 0.046875, loss = 0.07856885343790054\n","Epoch 44: finishing mini batch 235, training error = 0.046875, loss = 0.10107601433992386\n","Epoch 44: finishing mini batch 236, training error = 0.015625, loss = 0.1426459699869156\n","Epoch 44: finishing mini batch 237, training error = 0.015625, loss = 0.05644042789936066\n","Epoch 44: finishing mini batch 238, training error = 0.03125, loss = 0.1043568029999733\n","Epoch 44: finishing mini batch 239, training error = 0.03125, loss = 0.13943058252334595\n","Epoch 44: finishing mini batch 240, training error = 0.03125, loss = 0.09884822368621826\n","Epoch 44: finishing mini batch 241, training error = 0.0, loss = 0.04659438505768776\n","Epoch 44: finishing mini batch 242, training error = 0.03125, loss = 0.0681680217385292\n","Epoch 44: finishing mini batch 243, training error = 0.09375, loss = 0.20377589762210846\n","Epoch 44: finishing mini batch 244, training error = 0.078125, loss = 0.21339763700962067\n","Epoch 44: finishing mini batch 245, training error = 0.140625, loss = 0.33615103363990784\n","Epoch 44: finishing mini batch 246, training error = 0.046875, loss = 0.14995568990707397\n","Epoch 44: finishing mini batch 247, training error = 0.0, loss = 0.04595138877630234\n","Epoch 44: finishing mini batch 248, training error = 0.03125, loss = 0.14652249217033386\n","Epoch 44: finishing mini batch 249, training error = 0.09375, loss = 0.21104273200035095\n","Epoch 44: finishing mini batch 250, training error = 0.0625, loss = 0.1706433743238449\n","Epoch 44: finishing mini batch 251, training error = 0.03125, loss = 0.2286715805530548\n","Epoch 44: finishing mini batch 252, training error = 0.03125, loss = 0.10452955216169357\n","Epoch 44: finishing mini batch 253, training error = 0.015625, loss = 0.14514270424842834\n","Epoch 44: finishing mini batch 254, training error = 0.078125, loss = 0.1757867932319641\n","Epoch 44: finishing mini batch 255, training error = 0.078125, loss = 0.17638757824897766\n","Epoch 44: finishing mini batch 256, training error = 0.015625, loss = 0.07392291724681854\n","Epoch 44: finishing mini batch 257, training error = 0.046875, loss = 0.13343654572963715\n","Epoch 44: finishing mini batch 258, training error = 0.046875, loss = 0.12096361070871353\n","Epoch 44: finishing mini batch 259, training error = 0.078125, loss = 0.23184864223003387\n","Epoch 44: finishing mini batch 260, training error = 0.109375, loss = 0.18103362619876862\n","Epoch 44: finishing mini batch 261, training error = 0.03125, loss = 0.06144479289650917\n","Epoch 44: finishing mini batch 262, training error = 0.0625, loss = 0.16119693219661713\n","Epoch 44: finishing mini batch 263, training error = 0.015625, loss = 0.05824103206396103\n","Epoch 44: finishing mini batch 264, training error = 0.046875, loss = 0.08537370711565018\n","Epoch 44: finishing mini batch 265, training error = 0.078125, loss = 0.1494387537240982\n","Epoch 44: finishing mini batch 266, training error = 0.015625, loss = 0.10214091092348099\n","Epoch 44: finishing mini batch 267, training error = 0.03125, loss = 0.08034224808216095\n","Epoch 44: finishing mini batch 268, training error = 0.046875, loss = 0.17527399957180023\n","Epoch 44: finishing mini batch 269, training error = 0.046875, loss = 0.16505487263202667\n","Epoch 44: finishing mini batch 270, training error = 0.0625, loss = 0.13100910186767578\n","Epoch 44: finishing mini batch 271, training error = 0.09375, loss = 0.16080555319786072\n","Epoch 44: finishing mini batch 272, training error = 0.0625, loss = 0.14654657244682312\n","Epoch 44: finishing mini batch 273, training error = 0.0625, loss = 0.21976767480373383\n","Epoch 44: finishing mini batch 274, training error = 0.109375, loss = 0.20747561752796173\n","Epoch 44: finishing mini batch 275, training error = 0.046875, loss = 0.13999895751476288\n","Epoch 44: finishing mini batch 276, training error = 0.03125, loss = 0.08733246475458145\n","Epoch 44: finishing mini batch 277, training error = 0.0625, loss = 0.17671146988868713\n","Epoch 44: finishing mini batch 278, training error = 0.03125, loss = 0.14999131858348846\n","Epoch 44: finishing mini batch 279, training error = 0.046875, loss = 0.09589274227619171\n","Epoch 44: finishing mini batch 280, training error = 0.03125, loss = 0.10129083693027496\n","Epoch 44: finishing mini batch 281, training error = 0.0625, loss = 0.21578606963157654\n","Epoch 44: finishing mini batch 282, training error = 0.078125, loss = 0.2427305430173874\n","Epoch 44: finishing mini batch 283, training error = 0.046875, loss = 0.17773199081420898\n","Epoch 44: finishing mini batch 284, training error = 0.046875, loss = 0.14952315390110016\n","Epoch 44: finishing mini batch 285, training error = 0.03125, loss = 0.0710437223315239\n","Epoch 44: finishing mini batch 286, training error = 0.0625, loss = 0.19032147526741028\n","Epoch 44: finishing mini batch 287, training error = 0.0625, loss = 0.15108124911785126\n","Epoch 44: finishing mini batch 288, training error = 0.015625, loss = 0.06632092595100403\n","Epoch 44: finishing mini batch 289, training error = 0.0625, loss = 0.1776498705148697\n","Epoch 44: finishing mini batch 290, training error = 0.03125, loss = 0.1696675568819046\n","Epoch 44: finishing mini batch 291, training error = 0.015625, loss = 0.10633894801139832\n","Epoch 44: finishing mini batch 292, training error = 0.03125, loss = 0.14604529738426208\n","Epoch 44: finishing mini batch 293, training error = 0.015625, loss = 0.07635858654975891\n","Epoch 44: finishing mini batch 294, training error = 0.0625, loss = 0.2350291758775711\n","Epoch 44: finishing mini batch 295, training error = 0.0625, loss = 0.10011599212884903\n","Epoch 44: finishing mini batch 296, training error = 0.078125, loss = 0.2352631688117981\n","Epoch 44: finishing mini batch 297, training error = 0.03125, loss = 0.1022314727306366\n","Epoch 44: finishing mini batch 298, training error = 0.015625, loss = 0.039897628128528595\n","Epoch 44: finishing mini batch 299, training error = 0.03125, loss = 0.060859229415655136\n","Epoch 44: finishing mini batch 300, training error = 0.0625, loss = 0.2847003936767578\n","Epoch 44: finishing mini batch 301, training error = 0.0625, loss = 0.22730496525764465\n","Epoch 44: finishing mini batch 302, training error = 0.03125, loss = 0.0781468078494072\n","Epoch 44: finishing mini batch 303, training error = 0.0625, loss = 0.12571276724338531\n","Epoch 44: finishing mini batch 304, training error = 0.0625, loss = 0.2031528502702713\n","Epoch 44: finishing mini batch 305, training error = 0.03125, loss = 0.10360203683376312\n","Epoch 44: finishing mini batch 306, training error = 0.03125, loss = 0.1103421077132225\n","Epoch 44: finishing mini batch 307, training error = 0.0625, loss = 0.2524641156196594\n","Epoch 44: finishing mini batch 308, training error = 0.03125, loss = 0.13388052582740784\n","Epoch 44: finishing mini batch 309, training error = 0.046875, loss = 0.12133225053548813\n","Epoch 44: finishing mini batch 310, training error = 0.015625, loss = 0.052700791507959366\n","Epoch 44: finishing mini batch 311, training error = 0.046875, loss = 0.09438686817884445\n","Epoch 44: finishing mini batch 312, training error = 0.015625, loss = 0.07666784524917603\n","Epoch 44: finishing mini batch 313, training error = 0.03125, loss = 0.09016256034374237\n","Epoch 44: finishing mini batch 314, training error = 0.046875, loss = 0.1620103269815445\n","Epoch 44: finishing mini batch 315, training error = 0.0625, loss = 0.18492907285690308\n","Epoch 44: finishing mini batch 316, training error = 0.0625, loss = 0.14234492182731628\n","Epoch 44: finishing mini batch 317, training error = 0.03125, loss = 0.0597415529191494\n","Epoch 44: finishing mini batch 318, training error = 0.0625, loss = 0.21329650282859802\n","Epoch 44: finishing mini batch 319, training error = 0.046875, loss = 0.12543517351150513\n","Epoch 44: finishing mini batch 320, training error = 0.109375, loss = 0.22904331982135773\n","Epoch 44: finishing mini batch 321, training error = 0.046875, loss = 0.08149290829896927\n","Epoch 44: finishing mini batch 322, training error = 0.015625, loss = 0.04637010768055916\n","Epoch 44: finishing mini batch 323, training error = 0.0, loss = 0.033460747450590134\n","Epoch 44: finishing mini batch 324, training error = 0.046875, loss = 0.1604219377040863\n","Epoch 44: finishing mini batch 325, training error = 0.0625, loss = 0.13745123147964478\n","Epoch 44: finishing mini batch 326, training error = 0.03125, loss = 0.1480959951877594\n","Epoch 44: finishing mini batch 327, training error = 0.0625, loss = 0.21452969312667847\n","Epoch 44: finishing mini batch 328, training error = 0.03125, loss = 0.10119585692882538\n","Epoch 44: finishing mini batch 329, training error = 0.046875, loss = 0.17882920801639557\n","Epoch 44: finishing mini batch 330, training error = 0.015625, loss = 0.06579308956861496\n","Epoch 44: finishing mini batch 331, training error = 0.0625, loss = 0.15410682559013367\n","Epoch 44: finishing mini batch 332, training error = 0.0, loss = 0.0521678552031517\n","Epoch 44: finishing mini batch 333, training error = 0.03125, loss = 0.1103820651769638\n","Epoch 44: finishing mini batch 334, training error = 0.09375, loss = 0.24154601991176605\n","Epoch 44: finishing mini batch 335, training error = 0.078125, loss = 0.21377095580101013\n","Epoch 44: finishing mini batch 336, training error = 0.03125, loss = 0.09094882756471634\n","Epoch 44: finishing mini batch 337, training error = 0.046875, loss = 0.1278541088104248\n","Epoch 44: finishing mini batch 338, training error = 0.0625, loss = 0.18301351368427277\n","Epoch 44: finishing mini batch 339, training error = 0.046875, loss = 0.18236392736434937\n","Epoch 44: finishing mini batch 340, training error = 0.03125, loss = 0.11914882063865662\n","Epoch 44: finishing mini batch 341, training error = 0.046875, loss = 0.10476267337799072\n","Epoch 44: finishing mini batch 342, training error = 0.0625, loss = 0.1226491630077362\n","Epoch 44: finishing mini batch 343, training error = 0.078125, loss = 0.21518948674201965\n","Epoch 44: finishing mini batch 344, training error = 0.03125, loss = 0.10687094926834106\n","Epoch 44: finishing mini batch 345, training error = 0.0625, loss = 0.20147410035133362\n","Epoch 44: finishing mini batch 346, training error = 0.03125, loss = 0.09308253228664398\n","Epoch 44: finishing mini batch 347, training error = 0.078125, loss = 0.12349037826061249\n","Epoch 44: finishing mini batch 348, training error = 0.0, loss = 0.07853300124406815\n","Epoch 44: finishing mini batch 349, training error = 0.046875, loss = 0.14210554957389832\n","Epoch 44: finishing mini batch 350, training error = 0.03125, loss = 0.11538780480623245\n","Epoch 44: finishing mini batch 351, training error = 0.015625, loss = 0.09147414565086365\n","Epoch 44: finishing mini batch 352, training error = 0.0625, loss = 0.12788385152816772\n","Epoch 44: finishing mini batch 353, training error = 0.03125, loss = 0.08907508850097656\n","Epoch 44: finishing mini batch 354, training error = 0.0625, loss = 0.22288253903388977\n","Epoch 44: finishing mini batch 355, training error = 0.03125, loss = 0.10036730021238327\n","Epoch 44: finishing mini batch 356, training error = 0.078125, loss = 0.17053020000457764\n","Epoch 44: finishing mini batch 357, training error = 0.046875, loss = 0.09008032828569412\n","Epoch 44: finishing mini batch 358, training error = 0.046875, loss = 0.12263620644807816\n","Epoch 44: finishing mini batch 359, training error = 0.03125, loss = 0.08882223069667816\n","Epoch 44: finishing mini batch 360, training error = 0.0, loss = 0.04474247246980667\n","Epoch 44: finishing mini batch 361, training error = 0.03125, loss = 0.06775893270969391\n","Epoch 44: finishing mini batch 362, training error = 0.015625, loss = 0.08574028313159943\n","Epoch 44: finishing mini batch 363, training error = 0.0625, loss = 0.11589398235082626\n","Epoch 44: finishing mini batch 364, training error = 0.03125, loss = 0.058677371591329575\n","Epoch 44: finishing mini batch 365, training error = 0.03125, loss = 0.07298830896615982\n","Epoch 44: finishing mini batch 366, training error = 0.046875, loss = 0.13569381833076477\n","Epoch 44: finishing mini batch 367, training error = 0.0625, loss = 0.15101361274719238\n","Epoch 44: finishing mini batch 368, training error = 0.03125, loss = 0.1815052628517151\n","Epoch 44: finishing mini batch 369, training error = 0.03125, loss = 0.11418648809194565\n","Epoch 44: finishing mini batch 370, training error = 0.046875, loss = 0.09764761477708817\n","Epoch 44: finishing mini batch 371, training error = 0.0, loss = 0.047157540917396545\n","Epoch 44: finishing mini batch 372, training error = 0.0625, loss = 0.12970447540283203\n","Epoch 44: finishing mini batch 373, training error = 0.078125, loss = 0.19875694811344147\n","Epoch 44: finishing mini batch 374, training error = 0.015625, loss = 0.07912079989910126\n","Epoch 44: finishing mini batch 375, training error = 0.0, loss = 0.04569512605667114\n","Epoch 44: finishing mini batch 376, training error = 0.0625, loss = 0.170395627617836\n","Epoch 44: finishing mini batch 377, training error = 0.046875, loss = 0.12037859112024307\n","Epoch 44: finishing mini batch 378, training error = 0.09375, loss = 0.3069336712360382\n","Epoch 44: finishing mini batch 379, training error = 0.015625, loss = 0.07442489266395569\n","Epoch 44: finishing mini batch 380, training error = 0.015625, loss = 0.04692703112959862\n","Epoch 44: finishing mini batch 381, training error = 0.046875, loss = 0.13182760775089264\n","Epoch 44: finishing mini batch 382, training error = 0.078125, loss = 0.15587621927261353\n","Epoch 44: finishing mini batch 383, training error = 0.046875, loss = 0.10928994417190552\n","Epoch 44: finishing mini batch 384, training error = 0.0625, loss = 0.12883147597312927\n","Epoch 44: finishing mini batch 385, training error = 0.015625, loss = 0.0504995621740818\n","Epoch 44: finishing mini batch 386, training error = 0.0625, loss = 0.16306926310062408\n","Epoch 44: finishing mini batch 387, training error = 0.03125, loss = 0.07002626359462738\n","Epoch 44: finishing mini batch 388, training error = 0.015625, loss = 0.07680058479309082\n","Epoch 44: finishing mini batch 389, training error = 0.03125, loss = 0.08409419655799866\n","Epoch 44: finishing mini batch 390, training error = 0.0, loss = 0.05406985804438591\n","Epoch 44: finishing mini batch 391, training error = 0.03125, loss = 0.1404680758714676\n","Epoch 44: finishing mini batch 392, training error = 0.046875, loss = 0.11278092861175537\n","Epoch 44: finishing mini batch 393, training error = 0.03125, loss = 0.06275352835655212\n","Epoch 44: finishing mini batch 394, training error = 0.0625, loss = 0.15159736573696136\n","Epoch 44: finishing mini batch 395, training error = 0.09375, loss = 0.23492836952209473\n","Epoch 44: finishing mini batch 396, training error = 0.046875, loss = 0.1069846972823143\n","Epoch 44: finishing mini batch 397, training error = 0.09375, loss = 0.24729248881340027\n","Epoch 44: finishing mini batch 398, training error = 0.015625, loss = 0.12000207602977753\n","Epoch 44: finishing mini batch 399, training error = 0.0, loss = 0.04850206524133682\n","Epoch 44: finishing mini batch 400, training error = 0.015625, loss = 0.060178402811288834\n","Epoch 44: finishing mini batch 401, training error = 0.03125, loss = 0.12425622344017029\n","Epoch 44: finishing mini batch 402, training error = 0.0625, loss = 0.12509948015213013\n","Epoch 44: finishing mini batch 403, training error = 0.03125, loss = 0.10897891968488693\n","Epoch 44: finishing mini batch 404, training error = 0.0, loss = 0.03296227753162384\n","Epoch 44: finishing mini batch 405, training error = 0.078125, loss = 0.17148813605308533\n","Epoch 44: finishing mini batch 406, training error = 0.078125, loss = 0.16309021413326263\n","Epoch 44: finishing mini batch 407, training error = 0.0, loss = 0.05758165195584297\n","Epoch 44: finishing mini batch 408, training error = 0.046875, loss = 0.20541925728321075\n","Epoch 44: finishing mini batch 409, training error = 0.046875, loss = 0.14761501550674438\n","Epoch 44: finishing mini batch 410, training error = 0.046875, loss = 0.10666915774345398\n","Epoch 44: finishing mini batch 411, training error = 0.046875, loss = 0.09302564710378647\n","Epoch 44: finishing mini batch 412, training error = 0.046875, loss = 0.13995683193206787\n","Epoch 44: finishing mini batch 413, training error = 0.03125, loss = 0.11844471842050552\n","Epoch 44: finishing mini batch 414, training error = 0.015625, loss = 0.07145826518535614\n","Epoch 44: finishing mini batch 415, training error = 0.015625, loss = 0.09909714013338089\n","Epoch 44: finishing mini batch 416, training error = 0.015625, loss = 0.10028547793626785\n","Epoch 44: finishing mini batch 417, training error = 0.0, loss = 0.05885203555226326\n","Epoch 44: finishing mini batch 418, training error = 0.03125, loss = 0.111955426633358\n","Epoch 44: finishing mini batch 419, training error = 0.0625, loss = 0.10297268629074097\n","Epoch 44: finishing mini batch 420, training error = 0.0, loss = 0.017360202968120575\n","Epoch 44: finishing mini batch 421, training error = 0.03125, loss = 0.051208432763814926\n","Epoch 44: finishing mini batch 422, training error = 0.015625, loss = 0.02875140868127346\n","Epoch 44: finishing mini batch 423, training error = 0.046875, loss = 0.10823574662208557\n","Epoch 44: finishing mini batch 424, training error = 0.046875, loss = 0.11446332931518555\n","Epoch 44: finishing mini batch 425, training error = 0.03125, loss = 0.09684135019779205\n","Epoch 44: finishing mini batch 426, training error = 0.046875, loss = 0.1125306785106659\n","Epoch 44: finishing mini batch 427, training error = 0.03125, loss = 0.07297630608081818\n","Epoch 44: finishing mini batch 428, training error = 0.0, loss = 0.03240235522389412\n","Epoch 44: finishing mini batch 429, training error = 0.015625, loss = 0.07612813264131546\n","Epoch 44: finishing mini batch 430, training error = 0.015625, loss = 0.0660523846745491\n","Epoch 44: finishing mini batch 431, training error = 0.015625, loss = 0.06385301053524017\n","Epoch 44: finishing mini batch 432, training error = 0.046875, loss = 0.2008868157863617\n","Epoch 44: finishing mini batch 433, training error = 0.0, loss = 0.024172091856598854\n","Epoch 44: finishing mini batch 434, training error = 0.046875, loss = 0.09180061519145966\n","Epoch 44: finishing mini batch 435, training error = 0.015625, loss = 0.0702168345451355\n","Epoch 44: finishing mini batch 436, training error = 0.046875, loss = 0.1817406862974167\n","Epoch 44: finishing mini batch 437, training error = 0.078125, loss = 0.13626855611801147\n","Epoch 44: finishing mini batch 438, training error = 0.0, loss = 0.0379008986055851\n","Epoch 44: finishing mini batch 439, training error = 0.046875, loss = 0.12876662611961365\n","Epoch 44: finishing mini batch 440, training error = 0.03125, loss = 0.08302050828933716\n","Epoch 44: finishing mini batch 441, training error = 0.03125, loss = 0.09039115905761719\n","Epoch 44: finishing mini batch 442, training error = 0.046875, loss = 0.08408814668655396\n","Epoch 44: finishing mini batch 443, training error = 0.015625, loss = 0.056722041219472885\n","Epoch 44: finishing mini batch 444, training error = 0.046875, loss = 0.15354831516742706\n","Epoch 44: finishing mini batch 445, training error = 0.015625, loss = 0.07553582638502121\n","Epoch 44: finishing mini batch 446, training error = 0.046875, loss = 0.11207470297813416\n","Epoch 44: finishing mini batch 447, training error = 0.03125, loss = 0.07310673594474792\n","Epoch 44: finishing mini batch 448, training error = 0.03125, loss = 0.07564803957939148\n","Epoch 44: finishing mini batch 449, training error = 0.046875, loss = 0.07823208719491959\n","Epoch 44: finishing mini batch 450, training error = 0.03125, loss = 0.09380672872066498\n","Epoch 44: finishing mini batch 451, training error = 0.015625, loss = 0.09246981143951416\n","Epoch 44: finishing mini batch 452, training error = 0.015625, loss = 0.09668240696191788\n","Epoch 44: finishing mini batch 453, training error = 0.015625, loss = 0.06284470856189728\n","Epoch 44: finishing mini batch 454, training error = 0.0625, loss = 0.10581286996603012\n","Epoch 44: finishing mini batch 455, training error = 0.046875, loss = 0.10777866840362549\n","Epoch 44: finishing mini batch 456, training error = 0.0, loss = 0.03492717072367668\n","Epoch 44: finishing mini batch 457, training error = 0.0, loss = 0.06824591010808945\n","Epoch 44: finishing mini batch 458, training error = 0.0625, loss = 0.14549796283245087\n","Epoch 44: finishing mini batch 459, training error = 0.09375, loss = 0.19139572978019714\n","Epoch 44: finishing mini batch 460, training error = 0.0625, loss = 0.08973079919815063\n","Epoch 44: finishing mini batch 461, training error = 0.0, loss = 0.02921823039650917\n","Epoch 44: finishing mini batch 462, training error = 0.078125, loss = 0.22381369769573212\n","Epoch 44: finishing mini batch 463, training error = 0.046875, loss = 0.09616893529891968\n","Epoch 44: finishing mini batch 464, training error = 0.015625, loss = 0.07579848915338516\n","Epoch 44: finishing mini batch 465, training error = 0.078125, loss = 0.19420820474624634\n","Epoch 44: finishing mini batch 466, training error = 0.046875, loss = 0.11921592056751251\n","Epoch 44: finishing mini batch 467, training error = 0.0625, loss = 0.2047264277935028\n","Epoch 44: finishing mini batch 468, training error = 0.046875, loss = 0.11704999208450317\n","Epoch 44: finishing mini batch 469, training error = 0.0625, loss = 0.15035389363765717\n","Epoch 44: finishing mini batch 470, training error = 0.015625, loss = 0.13351047039031982\n","Epoch 44: finishing mini batch 471, training error = 0.09375, loss = 0.1878392994403839\n","Epoch 44: finishing mini batch 472, training error = 0.078125, loss = 0.2179085910320282\n","Epoch 44: finishing mini batch 473, training error = 0.0625, loss = 0.15577374398708344\n","Epoch 44: finishing mini batch 474, training error = 0.09375, loss = 0.23978467285633087\n","Epoch 44: finishing mini batch 475, training error = 0.046875, loss = 0.14456389844417572\n","Epoch 44: finishing mini batch 476, training error = 0.0625, loss = 0.27813416719436646\n","Epoch 44: finishing mini batch 477, training error = 0.046875, loss = 0.09658949077129364\n","Epoch 44: finishing mini batch 478, training error = 0.0625, loss = 0.27231693267822266\n","Epoch 44: finishing mini batch 479, training error = 0.0625, loss = 0.19539834558963776\n","Epoch 44: finishing mini batch 480, training error = 0.046875, loss = 0.09401050955057144\n","Epoch 44: finishing mini batch 481, training error = 0.0625, loss = 0.1873294562101364\n","Epoch 44: finishing mini batch 482, training error = 0.0625, loss = 0.11231959611177444\n","Epoch 44: finishing mini batch 483, training error = 0.03125, loss = 0.08946648985147476\n","Epoch 44: finishing mini batch 484, training error = 0.015625, loss = 0.07665371149778366\n","Epoch 44: finishing mini batch 485, training error = 0.03125, loss = 0.08178091049194336\n","Epoch 44: finishing mini batch 486, training error = 0.015625, loss = 0.11160919815301895\n","Epoch 44: finishing mini batch 487, training error = 0.0625, loss = 0.136709064245224\n","Epoch 44: finishing mini batch 488, training error = 0.046875, loss = 0.1543443351984024\n","Epoch 44: finishing mini batch 489, training error = 0.078125, loss = 0.31240758299827576\n","Epoch 44: finishing mini batch 490, training error = 0.046875, loss = 0.10755957663059235\n","Epoch 44: finishing mini batch 491, training error = 0.03125, loss = 0.09595437347888947\n","Epoch 44: finishing mini batch 492, training error = 0.0625, loss = 0.183233380317688\n","Epoch 44: finishing mini batch 493, training error = 0.046875, loss = 0.1370265781879425\n","Epoch 44: finishing mini batch 494, training error = 0.015625, loss = 0.08989112824201584\n","Epoch 44: finishing mini batch 495, training error = 0.03125, loss = 0.05446522310376167\n","Epoch 44: finishing mini batch 496, training error = 0.0625, loss = 0.18174070119857788\n","Epoch 44: finishing mini batch 497, training error = 0.046875, loss = 0.12426532059907913\n","Epoch 44: finishing mini batch 498, training error = 0.0625, loss = 0.10512840747833252\n","Epoch 44: finishing mini batch 499, training error = 0.015625, loss = 0.10260128229856491\n","Epoch 44: finishing mini batch 500, training error = 0.09375, loss = 0.43580326437950134\n","Epoch 44: finishing mini batch 501, training error = 0.09375, loss = 0.19739916920661926\n","Epoch 44: finishing mini batch 502, training error = 0.046875, loss = 0.09459856897592545\n","Epoch 44: finishing mini batch 503, training error = 0.046875, loss = 0.14869366586208344\n","Epoch 44: finishing mini batch 504, training error = 0.046875, loss = 0.15970058739185333\n","Epoch 44: finishing mini batch 505, training error = 0.078125, loss = 0.15613627433776855\n","Epoch 44: finishing mini batch 506, training error = 0.125, loss = 0.30731001496315\n","Epoch 44: finishing mini batch 507, training error = 0.046875, loss = 0.19605675339698792\n","Epoch 44: finishing mini batch 508, training error = 0.015625, loss = 0.07682052254676819\n","Epoch 44: finishing mini batch 509, training error = 0.015625, loss = 0.1124708279967308\n","Epoch 44: finishing mini batch 510, training error = 0.03125, loss = 0.08670026063919067\n","Epoch 44: finishing mini batch 511, training error = 0.09375, loss = 0.24381579458713531\n","Epoch 44: finishing mini batch 512, training error = 0.0625, loss = 0.18633872270584106\n","Epoch 44: finishing mini batch 513, training error = 0.046875, loss = 0.08638271689414978\n","Epoch 44: finishing mini batch 514, training error = 0.0625, loss = 0.19478599727153778\n","Epoch 44: finishing mini batch 515, training error = 0.03125, loss = 0.11368457227945328\n","Epoch 44: finishing mini batch 516, training error = 0.03125, loss = 0.06416062265634537\n","Epoch 44: finishing mini batch 517, training error = 0.078125, loss = 0.23843488097190857\n","Epoch 44: finishing mini batch 518, training error = 0.09375, loss = 0.14268268644809723\n","Epoch 44: finishing mini batch 519, training error = 0.078125, loss = 0.29639190435409546\n","Epoch 44: finishing mini batch 520, training error = 0.046875, loss = 0.15732789039611816\n","Epoch 44: finishing mini batch 521, training error = 0.078125, loss = 0.13651329278945923\n","Epoch 44: finishing mini batch 522, training error = 0.015625, loss = 0.07390285283327103\n","Epoch 44: finishing mini batch 523, training error = 0.0625, loss = 0.17884591221809387\n","Epoch 44: finishing mini batch 524, training error = 0.046875, loss = 0.1633974015712738\n","Epoch 44: finishing mini batch 525, training error = 0.015625, loss = 0.11352783441543579\n","Epoch 44: finishing mini batch 526, training error = 0.0625, loss = 0.14738717675209045\n","Epoch 44: finishing mini batch 527, training error = 0.015625, loss = 0.056497812271118164\n","Epoch 44: finishing mini batch 528, training error = 0.078125, loss = 0.18713286519050598\n","Epoch 44: finishing mini batch 529, training error = 0.03125, loss = 0.12039529532194138\n","Epoch 44: finishing mini batch 530, training error = 0.046875, loss = 0.1515970230102539\n","Epoch 44: finishing mini batch 531, training error = 0.0625, loss = 0.15499848127365112\n","Epoch 44: finishing mini batch 532, training error = 0.0625, loss = 0.19389185309410095\n","Epoch 44: finishing mini batch 533, training error = 0.046875, loss = 0.13922221958637238\n","Epoch 44: finishing mini batch 534, training error = 0.0625, loss = 0.12049968540668488\n","Epoch 44: finishing mini batch 535, training error = 0.046875, loss = 0.1152188703417778\n","Epoch 44: finishing mini batch 536, training error = 0.03125, loss = 0.10272742062807083\n","Epoch 44: finishing mini batch 537, training error = 0.03125, loss = 0.09372212737798691\n","Epoch 44: finishing mini batch 538, training error = 0.0625, loss = 0.19499602913856506\n","Epoch 44: finishing mini batch 539, training error = 0.0625, loss = 0.10938233882188797\n","Epoch 44: finishing mini batch 540, training error = 0.109375, loss = 0.2863151431083679\n","Epoch 44: finishing mini batch 541, training error = 0.015625, loss = 0.09246006608009338\n","Epoch 44: finishing mini batch 542, training error = 0.0625, loss = 0.1466236412525177\n","Epoch 44: finishing mini batch 543, training error = 0.046875, loss = 0.11352783441543579\n","Epoch 44: finishing mini batch 544, training error = 0.046875, loss = 0.09473993629217148\n","Epoch 44: finishing mini batch 545, training error = 0.0625, loss = 0.15146978199481964\n","Epoch 44: finishing mini batch 546, training error = 0.0625, loss = 0.1361972689628601\n","Epoch 44: finishing mini batch 547, training error = 0.015625, loss = 0.10887414216995239\n","Epoch 44: finishing mini batch 548, training error = 0.03125, loss = 0.06813923269510269\n","Epoch 44: finishing mini batch 549, training error = 0.015625, loss = 0.10409912467002869\n","Epoch 44: finishing mini batch 550, training error = 0.015625, loss = 0.06844715029001236\n","Epoch 44: finishing mini batch 551, training error = 0.09375, loss = 0.39481523633003235\n","Epoch 44: finishing mini batch 552, training error = 0.046875, loss = 0.12517164647579193\n","Epoch 44: finishing mini batch 553, training error = 0.0625, loss = 0.1331002116203308\n","Epoch 44: finishing mini batch 554, training error = 0.078125, loss = 0.1683715134859085\n","Epoch 44: finishing mini batch 555, training error = 0.015625, loss = 0.05929671227931976\n","Epoch 44: finishing mini batch 556, training error = 0.078125, loss = 0.20443792641162872\n","Epoch 44: finishing mini batch 557, training error = 0.046875, loss = 0.0922561064362526\n","Epoch 44: finishing mini batch 558, training error = 0.0, loss = 0.0540303997695446\n","Epoch 44: finishing mini batch 559, training error = 0.046875, loss = 0.10889151692390442\n","Epoch 44: finishing mini batch 560, training error = 0.0625, loss = 0.15523751080036163\n","Epoch 44: finishing mini batch 561, training error = 0.0625, loss = 0.13057325780391693\n","Epoch 44: finishing mini batch 562, training error = 0.0625, loss = 0.11775203794240952\n","Epoch 44: finishing mini batch 563, training error = 0.0625, loss = 0.1452607810497284\n","Epoch 44: finishing mini batch 564, training error = 0.03125, loss = 0.08216048032045364\n","Epoch 44: finishing mini batch 565, training error = 0.0625, loss = 0.18621544539928436\n","Epoch 44: finishing mini batch 566, training error = 0.0625, loss = 0.11205722391605377\n","Epoch 44: finishing mini batch 567, training error = 0.078125, loss = 0.19945348799228668\n","Epoch 44: finishing mini batch 568, training error = 0.015625, loss = 0.0517534539103508\n","Epoch 44: finishing mini batch 569, training error = 0.0, loss = 0.05277477204799652\n","Epoch 44: finishing mini batch 570, training error = 0.03125, loss = 0.09239933639764786\n","Epoch 44: finishing mini batch 571, training error = 0.046875, loss = 0.14072160422801971\n","Epoch 44: finishing mini batch 572, training error = 0.09375, loss = 0.2026907503604889\n","Epoch 44: finishing mini batch 573, training error = 0.03125, loss = 0.13174840807914734\n","Epoch 44: finishing mini batch 574, training error = 0.09375, loss = 0.15279990434646606\n","Epoch 44: finishing mini batch 575, training error = 0.03125, loss = 0.08374364674091339\n","Epoch 44: finishing mini batch 576, training error = 0.09375, loss = 0.19452306628227234\n","Epoch 44: finishing mini batch 577, training error = 0.0625, loss = 0.2567436099052429\n","Epoch 44: finishing mini batch 578, training error = 0.046875, loss = 0.2375427782535553\n","Epoch 44: finishing mini batch 579, training error = 0.0625, loss = 0.13389500975608826\n","Epoch 44: finishing mini batch 580, training error = 0.046875, loss = 0.11919531971216202\n","Epoch 44: finishing mini batch 581, training error = 0.0625, loss = 0.17304150760173798\n","Epoch 44: finishing mini batch 582, training error = 0.03125, loss = 0.15421073138713837\n","Epoch 44: finishing mini batch 583, training error = 0.015625, loss = 0.08763232082128525\n","Epoch 44: finishing mini batch 584, training error = 0.046875, loss = 0.12019616365432739\n","Epoch 44: finishing mini batch 585, training error = 0.078125, loss = 0.29710930585861206\n","Epoch 44: finishing mini batch 586, training error = 0.0625, loss = 0.09552120417356491\n","Epoch 44: finishing mini batch 587, training error = 0.03125, loss = 0.06429179757833481\n","Epoch 44: finishing mini batch 588, training error = 0.046875, loss = 0.13114145398139954\n","Epoch 44: finishing mini batch 589, training error = 0.09375, loss = 0.2592405378818512\n","Epoch 44: finishing mini batch 590, training error = 0.0625, loss = 0.18327204883098602\n","Epoch 44: finishing mini batch 591, training error = 0.078125, loss = 0.17414841055870056\n","Epoch 44: finishing mini batch 592, training error = 0.03125, loss = 0.09074579179286957\n","Epoch 44: finishing mini batch 593, training error = 0.03125, loss = 0.10510816425085068\n","Epoch 44: finishing mini batch 594, training error = 0.015625, loss = 0.08928047120571136\n","Epoch 44: finishing mini batch 595, training error = 0.0625, loss = 0.19980275630950928\n","Epoch 44: finishing mini batch 596, training error = 0.0, loss = 0.03877994790673256\n","Epoch 44: finishing mini batch 597, training error = 0.046875, loss = 0.12677688896656036\n","Epoch 44: finishing mini batch 598, training error = 0.03125, loss = 0.09606990218162537\n","Epoch 44: finishing mini batch 599, training error = 0.015625, loss = 0.06364914774894714\n","Epoch 44: finishing mini batch 600, training error = 0.03125, loss = 0.11187785863876343\n","Epoch 44: finishing mini batch 601, training error = 0.0625, loss = 0.12225954979658127\n","Epoch 44: finishing mini batch 602, training error = 0.078125, loss = 0.15527833998203278\n","Epoch 44: finishing mini batch 603, training error = 0.078125, loss = 0.20315049588680267\n","Epoch 44: finishing mini batch 604, training error = 0.015625, loss = 0.10206477344036102\n","Epoch 44: finishing mini batch 605, training error = 0.03125, loss = 0.09101688861846924\n","Epoch 44: finishing mini batch 606, training error = 0.046875, loss = 0.12915341556072235\n","Epoch 44: finishing mini batch 607, training error = 0.046875, loss = 0.1467403620481491\n","Epoch 44: finishing mini batch 608, training error = 0.078125, loss = 0.26396051049232483\n","Epoch 44: finishing mini batch 609, training error = 0.03125, loss = 0.13079559803009033\n","Epoch 44: finishing mini batch 610, training error = 0.0625, loss = 0.202377051115036\n","Epoch 44: finishing mini batch 611, training error = 0.046875, loss = 0.12157886475324631\n","Epoch 44: finishing mini batch 612, training error = 0.015625, loss = 0.0963454395532608\n","Epoch 44: finishing mini batch 613, training error = 0.03125, loss = 0.12382105737924576\n","Epoch 44: finishing mini batch 614, training error = 0.046875, loss = 0.1174115315079689\n","Epoch 44: finishing mini batch 615, training error = 0.0625, loss = 0.17870961129665375\n","Epoch 44: finishing mini batch 616, training error = 0.046875, loss = 0.09109344333410263\n","Epoch 44: finishing mini batch 617, training error = 0.015625, loss = 0.061145201325416565\n","Epoch 44: finishing mini batch 618, training error = 0.140625, loss = 0.3296459913253784\n","Epoch 44: finishing mini batch 619, training error = 0.03125, loss = 0.1455274224281311\n","Epoch 44: finishing mini batch 620, training error = 0.078125, loss = 0.1842999905347824\n","Epoch 44: finishing mini batch 621, training error = 0.0, loss = 0.054617490619421005\n","Epoch 44: finishing mini batch 622, training error = 0.046875, loss = 0.12593518197536469\n","Epoch 44: finishing mini batch 623, training error = 0.0625, loss = 0.1558968722820282\n","Epoch 44: finishing mini batch 624, training error = 0.046875, loss = 0.09501072019338608\n","Epoch 44: finishing mini batch 625, training error = 0.015625, loss = 0.07399116456508636\n","Epoch 44: finishing mini batch 626, training error = 0.0625, loss = 0.1216597929596901\n","Epoch 44: finishing mini batch 627, training error = 0.03125, loss = 0.06685731559991837\n","Epoch 44: finishing mini batch 628, training error = 0.03125, loss = 0.06411802023649216\n","Epoch 44: finishing mini batch 629, training error = 0.109375, loss = 0.3237784504890442\n","Epoch 44: finishing mini batch 630, training error = 0.03125, loss = 0.09894254058599472\n","Epoch 44: finishing mini batch 631, training error = 0.125, loss = 0.19989217817783356\n","Epoch 44: finishing mini batch 632, training error = 0.046875, loss = 0.16754792630672455\n","Epoch 44: finishing mini batch 633, training error = 0.0625, loss = 0.21169431507587433\n","Epoch 44: finishing mini batch 634, training error = 0.125, loss = 0.3685651421546936\n","Epoch 44: finishing mini batch 635, training error = 0.09375, loss = 0.2743106782436371\n","Epoch 44: finishing mini batch 636, training error = 0.046875, loss = 0.13228923082351685\n","Epoch 44: finishing mini batch 637, training error = 0.0625, loss = 0.1863982081413269\n","Epoch 44: finishing mini batch 638, training error = 0.046875, loss = 0.12173675745725632\n","Epoch 44: finishing mini batch 639, training error = 0.0625, loss = 0.1673993319272995\n","Epoch 44: finishing mini batch 640, training error = 0.046875, loss = 0.12384872138500214\n","Epoch 44: finishing mini batch 641, training error = 0.09375, loss = 0.21658362448215485\n","Epoch 44: finishing mini batch 642, training error = 0.0625, loss = 0.1617119163274765\n","Epoch 44: finishing mini batch 643, training error = 0.078125, loss = 0.17657431960105896\n","Epoch 44: finishing mini batch 644, training error = 0.03125, loss = 0.15008459985256195\n","Epoch 44: finishing mini batch 645, training error = 0.046875, loss = 0.1225985735654831\n","Epoch 44: finishing mini batch 646, training error = 0.125, loss = 0.3485879898071289\n","Epoch 44: finishing mini batch 647, training error = 0.0625, loss = 0.0894632637500763\n","Epoch 44: finishing mini batch 648, training error = 0.03125, loss = 0.08294477313756943\n","Epoch 44: finishing mini batch 649, training error = 0.046875, loss = 0.1157812774181366\n","Epoch 44: finishing mini batch 650, training error = 0.078125, loss = 0.16564060747623444\n","Epoch 44: finishing mini batch 651, training error = 0.015625, loss = 0.07874592393636703\n","Epoch 44: finishing mini batch 652, training error = 0.09375, loss = 0.22770929336547852\n","Epoch 44: finishing mini batch 653, training error = 0.015625, loss = 0.062243737280368805\n","Epoch 44: finishing mini batch 654, training error = 0.03125, loss = 0.07408694922924042\n","Epoch 44: finishing mini batch 655, training error = 0.046875, loss = 0.10378164052963257\n","Epoch 44: finishing mini batch 656, training error = 0.046875, loss = 0.1035849004983902\n","Epoch 44: finishing mini batch 657, training error = 0.109375, loss = 0.21458373963832855\n","Epoch 44: finishing mini batch 658, training error = 0.078125, loss = 0.15814617276191711\n","Epoch 44: finishing mini batch 659, training error = 0.03125, loss = 0.0978318527340889\n","Epoch 44: finishing mini batch 660, training error = 0.03125, loss = 0.08808446675539017\n","Epoch 44: finishing mini batch 661, training error = 0.046875, loss = 0.1022903099656105\n","Epoch 44: finishing mini batch 662, training error = 0.03125, loss = 0.12376316636800766\n","Epoch 44: finishing mini batch 663, training error = 0.109375, loss = 0.24282725155353546\n","Epoch 44: finishing mini batch 664, training error = 0.0625, loss = 0.12603023648262024\n","Epoch 44: finishing mini batch 665, training error = 0.0625, loss = 0.1159091666340828\n","Epoch 44: finishing mini batch 666, training error = 0.09375, loss = 0.1865418255329132\n","Epoch 44: finishing mini batch 667, training error = 0.09375, loss = 0.16708125174045563\n","Epoch 44: finishing mini batch 668, training error = 0.03125, loss = 0.1388334184885025\n","Epoch 44: finishing mini batch 669, training error = 0.046875, loss = 0.13282065093517303\n","Epoch 44: finishing mini batch 670, training error = 0.078125, loss = 0.13482388854026794\n","Epoch 44: finishing mini batch 671, training error = 0.046875, loss = 0.1946478635072708\n","Epoch 44: finishing mini batch 672, training error = 0.09375, loss = 0.20354841649532318\n","Epoch 44: finishing mini batch 673, training error = 0.015625, loss = 0.07328217476606369\n","Epoch 44: finishing mini batch 674, training error = 0.0625, loss = 0.14655418694019318\n","Epoch 44: finishing mini batch 675, training error = 0.015625, loss = 0.08525428175926208\n","Epoch 44: finishing mini batch 676, training error = 0.046875, loss = 0.10228823870420456\n","Epoch 44: finishing mini batch 677, training error = 0.046875, loss = 0.08914882689714432\n","Epoch 44: finishing mini batch 678, training error = 0.078125, loss = 0.2242342084646225\n","Epoch 44: finishing mini batch 679, training error = 0.09375, loss = 0.18415753543376923\n","Epoch 44: finishing mini batch 680, training error = 0.03125, loss = 0.11411699652671814\n","Epoch 44: finishing mini batch 681, training error = 0.0625, loss = 0.2789592444896698\n","Epoch 44: finishing mini batch 682, training error = 0.0625, loss = 0.16717179119586945\n","Epoch 44: finishing mini batch 683, training error = 0.0, loss = 0.04020120948553085\n","Epoch 44: finishing mini batch 684, training error = 0.0625, loss = 0.13376294076442719\n","Epoch 44: finishing mini batch 685, training error = 0.03125, loss = 0.09055089950561523\n","Epoch 44: finishing mini batch 686, training error = 0.046875, loss = 0.11520975828170776\n","Epoch 44: finishing mini batch 687, training error = 0.078125, loss = 0.25032365322113037\n","Epoch 44: finishing mini batch 688, training error = 0.046875, loss = 0.12516602873802185\n","Epoch 44: finishing mini batch 689, training error = 0.09375, loss = 0.1719823032617569\n","Epoch 44: finishing mini batch 690, training error = 0.078125, loss = 0.20410607755184174\n","Epoch 44: finishing mini batch 691, training error = 0.0, loss = 0.04439222440123558\n","Epoch 44: finishing mini batch 692, training error = 0.09375, loss = 0.23679177463054657\n","Epoch 44: finishing mini batch 693, training error = 0.046875, loss = 0.10725042968988419\n","Epoch 44: finishing mini batch 694, training error = 0.09375, loss = 0.22586597502231598\n","Epoch 44: finishing mini batch 695, training error = 0.09375, loss = 0.18810079991817474\n","Epoch 44: finishing mini batch 696, training error = 0.046875, loss = 0.10225394368171692\n","Epoch 44: finishing mini batch 697, training error = 0.09375, loss = 0.2316301316022873\n","Epoch 44: finishing mini batch 698, training error = 0.03125, loss = 0.11278180778026581\n","Epoch 44: finishing mini batch 699, training error = 0.078125, loss = 0.1638086885213852\n","Epoch 44: finishing mini batch 700, training error = 0.046875, loss = 0.09568479657173157\n","Epoch 44: finishing mini batch 701, training error = 0.015625, loss = 0.07031436264514923\n","Epoch 44: finishing mini batch 702, training error = 0.09375, loss = 0.2702796459197998\n","Epoch 44: finishing mini batch 703, training error = 0.078125, loss = 0.167582169175148\n","Epoch 44: finishing mini batch 704, training error = 0.0625, loss = 0.13806231319904327\n","Epoch 44: finishing mini batch 705, training error = 0.046875, loss = 0.10043098777532578\n","Epoch 44: finishing mini batch 706, training error = 0.09375, loss = 0.24424491822719574\n","Epoch 44: finishing mini batch 707, training error = 0.078125, loss = 0.316926509141922\n","Epoch 44: finishing mini batch 708, training error = 0.078125, loss = 0.1519121378660202\n","Epoch 44: finishing mini batch 709, training error = 0.078125, loss = 0.150828018784523\n","Epoch 44: finishing mini batch 710, training error = 0.015625, loss = 0.06407542526721954\n","Epoch 44: finishing mini batch 711, training error = 0.046875, loss = 0.11850151419639587\n","Epoch 44: finishing mini batch 712, training error = 0.09375, loss = 0.3802316188812256\n","Epoch 44: finishing mini batch 713, training error = 0.109375, loss = 0.26900193095207214\n","Epoch 44: finishing mini batch 714, training error = 0.046875, loss = 0.25610652565956116\n","Epoch 44: finishing mini batch 715, training error = 0.0625, loss = 0.16960032284259796\n","Epoch 44: finishing mini batch 716, training error = 0.078125, loss = 0.1537591516971588\n","Epoch 44: finishing mini batch 717, training error = 0.015625, loss = 0.0994597002863884\n","Epoch 44: finishing mini batch 718, training error = 0.078125, loss = 0.19987215101718903\n","Epoch 44: finishing mini batch 719, training error = 0.046875, loss = 0.14483234286308289\n","Epoch 44: finishing mini batch 720, training error = 0.015625, loss = 0.1063302531838417\n","Epoch 44: finishing mini batch 721, training error = 0.140625, loss = 0.3043789863586426\n","Epoch 44: finishing mini batch 722, training error = 0.0625, loss = 0.15821905434131622\n","Epoch 44: finishing mini batch 723, training error = 0.046875, loss = 0.15791252255439758\n","Epoch 44: finishing mini batch 724, training error = 0.03125, loss = 0.12580160796642303\n","Epoch 44: finishing mini batch 725, training error = 0.015625, loss = 0.0943584069609642\n","Epoch 44: finishing mini batch 726, training error = 0.015625, loss = 0.0709368884563446\n","Epoch 44: finishing mini batch 727, training error = 0.0625, loss = 0.12196547538042068\n","Epoch 44: finishing mini batch 728, training error = 0.0625, loss = 0.17165324091911316\n","Epoch 44: finishing mini batch 729, training error = 0.03125, loss = 0.0901871770620346\n","Epoch 44: finishing mini batch 730, training error = 0.0, loss = 0.07405544072389603\n","Epoch 44: finishing mini batch 731, training error = 0.03125, loss = 0.10448700189590454\n","Epoch 44: finishing mini batch 732, training error = 0.03125, loss = 0.1112709492444992\n","Epoch 44: finishing mini batch 733, training error = 0.0625, loss = 0.14906643331050873\n","Epoch 44: finishing mini batch 734, training error = 0.046875, loss = 0.13518507778644562\n","Epoch 44: finishing mini batch 735, training error = 0.03125, loss = 0.1229216456413269\n","Epoch 44: finishing mini batch 736, training error = 0.0625, loss = 0.1274903565645218\n","Epoch 44: finishing mini batch 737, training error = 0.046875, loss = 0.12938174605369568\n","Epoch 44: finishing mini batch 738, training error = 0.09375, loss = 0.2338055521249771\n","Epoch 44: finishing mini batch 739, training error = 0.0625, loss = 0.16074636578559875\n","Epoch 44: finishing mini batch 740, training error = 0.0625, loss = 0.134009450674057\n","Epoch 44: finishing mini batch 741, training error = 0.03125, loss = 0.08999607712030411\n","Epoch 44: finishing mini batch 742, training error = 0.078125, loss = 0.2511274814605713\n","Epoch 44: finishing mini batch 743, training error = 0.015625, loss = 0.04192538931965828\n","Epoch 44: finishing mini batch 744, training error = 0.03125, loss = 0.12025702744722366\n","Epoch 44: finishing mini batch 745, training error = 0.0625, loss = 0.1546027511358261\n","Epoch 44: finishing mini batch 746, training error = 0.0625, loss = 0.20746731758117676\n","Epoch 44: finishing mini batch 747, training error = 0.046875, loss = 0.15221351385116577\n","Epoch 44: finishing mini batch 748, training error = 0.0625, loss = 0.14756859838962555\n","Epoch 44: finishing mini batch 749, training error = 0.03125, loss = 0.06027355045080185\n","Epoch 44: finishing mini batch 750, training error = 0.078125, loss = 0.2100551724433899\n","Epoch 44: finishing mini batch 751, training error = 0.046875, loss = 0.1894274204969406\n","Epoch 44: finishing mini batch 752, training error = 0.03125, loss = 0.077894426882267\n","Epoch 44: finishing mini batch 753, training error = 0.03125, loss = 0.10363636165857315\n","Epoch 44: finishing mini batch 754, training error = 0.046875, loss = 0.15748615562915802\n","Epoch 44: finishing mini batch 755, training error = 0.03125, loss = 0.05688402056694031\n","Epoch 44: finishing mini batch 756, training error = 0.09375, loss = 0.16807511448860168\n","Epoch 44: finishing mini batch 757, training error = 0.046875, loss = 0.07318497449159622\n","Epoch 44: finishing mini batch 758, training error = 0.09375, loss = 0.2626064121723175\n","Epoch 44: finishing mini batch 759, training error = 0.09375, loss = 0.23380401730537415\n","Epoch 44: finishing mini batch 760, training error = 0.015625, loss = 0.0636925920844078\n","Epoch 44: finishing mini batch 761, training error = 0.0625, loss = 0.1480507105588913\n","Epoch 44: finishing mini batch 762, training error = 0.03125, loss = 0.10980072617530823\n","Epoch 44: finishing mini batch 763, training error = 0.0625, loss = 0.1601843386888504\n","Epoch 44: finishing mini batch 764, training error = 0.0625, loss = 0.16656914353370667\n","Epoch 44: finishing mini batch 765, training error = 0.078125, loss = 0.16240155696868896\n","Epoch 44: finishing mini batch 766, training error = 0.015625, loss = 0.0769093930721283\n","Epoch 44: finishing mini batch 767, training error = 0.046875, loss = 0.16442255675792694\n","Epoch 44: finishing mini batch 768, training error = 0.046875, loss = 0.11426536738872528\n","Epoch 44: finishing mini batch 769, training error = 0.0625, loss = 0.15810489654541016\n","Epoch 44: finishing mini batch 770, training error = 0.015625, loss = 0.0801888257265091\n","Epoch 44: finishing mini batch 771, training error = 0.03125, loss = 0.12369648367166519\n","Epoch 44: finishing mini batch 772, training error = 0.0625, loss = 0.19659414887428284\n","Epoch 44: finishing mini batch 773, training error = 0.046875, loss = 0.12822701036930084\n","Epoch 44: finishing mini batch 774, training error = 0.0, loss = 0.03624865785241127\n","Epoch 44: finishing mini batch 775, training error = 0.03125, loss = 0.07231369614601135\n","Epoch 44: finishing mini batch 776, training error = 0.0625, loss = 0.1283992975950241\n","Epoch 44: finishing mini batch 777, training error = 0.046875, loss = 0.11334904283285141\n","Epoch 44: finishing mini batch 778, training error = 0.125, loss = 0.2523745894432068\n","Epoch 44: finishing mini batch 779, training error = 0.03125, loss = 0.09321251511573792\n","Epoch 44: finishing mini batch 780, training error = 0.0625, loss = 0.23282861709594727\n","Epoch 44: finishing mini batch 781, training error = 0.0, loss = 0.03922121971845627\n","Epoch 44: finishing mini batch 782, training error = 0.0, loss = 0.02907145582139492\n","Epoch 44 completed, acc_loss = 105.95608677528799\n","Starting epoch 45...\n","Epoch 45: finishing mini batch 1, training error = 0.03125, loss = 0.0799294263124466\n","Epoch 45: finishing mini batch 2, training error = 0.015625, loss = 0.06497545540332794\n","Epoch 45: finishing mini batch 3, training error = 0.046875, loss = 0.19201403856277466\n","Epoch 45: finishing mini batch 4, training error = 0.046875, loss = 0.18767781555652618\n","Epoch 45: finishing mini batch 5, training error = 0.046875, loss = 0.1320883333683014\n","Epoch 45: finishing mini batch 6, training error = 0.09375, loss = 0.16781944036483765\n","Epoch 45: finishing mini batch 7, training error = 0.046875, loss = 0.1029052734375\n","Epoch 45: finishing mini batch 8, training error = 0.0625, loss = 0.07481317967176437\n","Epoch 45: finishing mini batch 9, training error = 0.0625, loss = 0.2010643184185028\n","Epoch 45: finishing mini batch 10, training error = 0.015625, loss = 0.06526380777359009\n","Epoch 45: finishing mini batch 11, training error = 0.046875, loss = 0.08009009808301926\n","Epoch 45: finishing mini batch 12, training error = 0.046875, loss = 0.08931285887956619\n","Epoch 45: finishing mini batch 13, training error = 0.0625, loss = 0.13807913661003113\n","Epoch 45: finishing mini batch 14, training error = 0.0, loss = 0.054421715438365936\n","Epoch 45: finishing mini batch 15, training error = 0.0, loss = 0.05877489224076271\n","Epoch 45: finishing mini batch 16, training error = 0.09375, loss = 0.17741520702838898\n","Epoch 45: finishing mini batch 17, training error = 0.0625, loss = 0.20179182291030884\n","Epoch 45: finishing mini batch 18, training error = 0.0625, loss = 0.20518729090690613\n","Epoch 45: finishing mini batch 19, training error = 0.015625, loss = 0.053202684968709946\n","Epoch 45: finishing mini batch 20, training error = 0.0625, loss = 0.13005414605140686\n","Epoch 45: finishing mini batch 21, training error = 0.09375, loss = 0.2069038450717926\n","Epoch 45: finishing mini batch 22, training error = 0.03125, loss = 0.09674616903066635\n","Epoch 45: finishing mini batch 23, training error = 0.0, loss = 0.07004870474338531\n","Epoch 45: finishing mini batch 24, training error = 0.078125, loss = 0.1754053831100464\n","Epoch 45: finishing mini batch 25, training error = 0.0625, loss = 0.2380022406578064\n","Epoch 45: finishing mini batch 26, training error = 0.0, loss = 0.050706878304481506\n","Epoch 45: finishing mini batch 27, training error = 0.015625, loss = 0.03761730715632439\n","Epoch 45: finishing mini batch 28, training error = 0.015625, loss = 0.033512745052576065\n","Epoch 45: finishing mini batch 29, training error = 0.0, loss = 0.033167582005262375\n","Epoch 45: finishing mini batch 30, training error = 0.015625, loss = 0.06421034038066864\n","Epoch 45: finishing mini batch 31, training error = 0.078125, loss = 0.1995757818222046\n","Epoch 45: finishing mini batch 32, training error = 0.0, loss = 0.034682199358940125\n","Epoch 45: finishing mini batch 33, training error = 0.0, loss = 0.028758849948644638\n","Epoch 45: finishing mini batch 34, training error = 0.03125, loss = 0.13762927055358887\n","Epoch 45: finishing mini batch 35, training error = 0.0, loss = 0.03191034495830536\n","Epoch 45: finishing mini batch 36, training error = 0.015625, loss = 0.05613204836845398\n","Epoch 45: finishing mini batch 37, training error = 0.03125, loss = 0.10622207820415497\n","Epoch 45: finishing mini batch 38, training error = 0.046875, loss = 0.13521835207939148\n","Epoch 45: finishing mini batch 39, training error = 0.046875, loss = 0.11969329416751862\n","Epoch 45: finishing mini batch 40, training error = 0.0625, loss = 0.1254543960094452\n","Epoch 45: finishing mini batch 41, training error = 0.046875, loss = 0.07906477898359299\n","Epoch 45: finishing mini batch 42, training error = 0.03125, loss = 0.086646169424057\n","Epoch 45: finishing mini batch 43, training error = 0.0, loss = 0.02853573113679886\n","Epoch 45: finishing mini batch 44, training error = 0.03125, loss = 0.07752770185470581\n","Epoch 45: finishing mini batch 45, training error = 0.046875, loss = 0.10586287081241608\n","Epoch 45: finishing mini batch 46, training error = 0.0625, loss = 0.13107864558696747\n","Epoch 45: finishing mini batch 47, training error = 0.046875, loss = 0.15329399704933167\n","Epoch 45: finishing mini batch 48, training error = 0.109375, loss = 0.28142049908638\n","Epoch 45: finishing mini batch 49, training error = 0.03125, loss = 0.13181041181087494\n","Epoch 45: finishing mini batch 50, training error = 0.046875, loss = 0.1580554097890854\n","Epoch 45: finishing mini batch 51, training error = 0.046875, loss = 0.14124299585819244\n","Epoch 45: finishing mini batch 52, training error = 0.046875, loss = 0.07603920996189117\n","Epoch 45: finishing mini batch 53, training error = 0.0, loss = 0.04126232489943504\n","Epoch 45: finishing mini batch 54, training error = 0.03125, loss = 0.08607058227062225\n","Epoch 45: finishing mini batch 55, training error = 0.0625, loss = 0.1942782998085022\n","Epoch 45: finishing mini batch 56, training error = 0.015625, loss = 0.09103476256132126\n","Epoch 45: finishing mini batch 57, training error = 0.015625, loss = 0.0834646075963974\n","Epoch 45: finishing mini batch 58, training error = 0.046875, loss = 0.10146277397871017\n","Epoch 45: finishing mini batch 59, training error = 0.078125, loss = 0.18826459348201752\n","Epoch 45: finishing mini batch 60, training error = 0.03125, loss = 0.10183718055486679\n","Epoch 45: finishing mini batch 61, training error = 0.0625, loss = 0.17165765166282654\n","Epoch 45: finishing mini batch 62, training error = 0.0625, loss = 0.16805821657180786\n","Epoch 45: finishing mini batch 63, training error = 0.0625, loss = 0.2016587108373642\n","Epoch 45: finishing mini batch 64, training error = 0.015625, loss = 0.058224741369485855\n","Epoch 45: finishing mini batch 65, training error = 0.046875, loss = 0.21430060267448425\n","Epoch 45: finishing mini batch 66, training error = 0.03125, loss = 0.11189600080251694\n","Epoch 45: finishing mini batch 67, training error = 0.015625, loss = 0.04925253987312317\n","Epoch 45: finishing mini batch 68, training error = 0.046875, loss = 0.1703326404094696\n","Epoch 45: finishing mini batch 69, training error = 0.03125, loss = 0.13661116361618042\n","Epoch 45: finishing mini batch 70, training error = 0.078125, loss = 0.20988300442695618\n","Epoch 45: finishing mini batch 71, training error = 0.0625, loss = 0.12236806005239487\n","Epoch 45: finishing mini batch 72, training error = 0.0625, loss = 0.11986350268125534\n","Epoch 45: finishing mini batch 73, training error = 0.046875, loss = 0.09479551017284393\n","Epoch 45: finishing mini batch 74, training error = 0.078125, loss = 0.12851719558238983\n","Epoch 45: finishing mini batch 75, training error = 0.03125, loss = 0.10138578712940216\n","Epoch 45: finishing mini batch 76, training error = 0.015625, loss = 0.07267168909311295\n","Epoch 45: finishing mini batch 77, training error = 0.078125, loss = 0.15239331126213074\n","Epoch 45: finishing mini batch 78, training error = 0.03125, loss = 0.13251718878746033\n","Epoch 45: finishing mini batch 79, training error = 0.015625, loss = 0.0650942474603653\n","Epoch 45: finishing mini batch 80, training error = 0.015625, loss = 0.0525474026799202\n","Epoch 45: finishing mini batch 81, training error = 0.046875, loss = 0.0890524834394455\n","Epoch 45: finishing mini batch 82, training error = 0.03125, loss = 0.08398221433162689\n","Epoch 45: finishing mini batch 83, training error = 0.046875, loss = 0.14056557416915894\n","Epoch 45: finishing mini batch 84, training error = 0.078125, loss = 0.21152938902378082\n","Epoch 45: finishing mini batch 85, training error = 0.015625, loss = 0.07738372683525085\n","Epoch 45: finishing mini batch 86, training error = 0.046875, loss = 0.0959726870059967\n","Epoch 45: finishing mini batch 87, training error = 0.03125, loss = 0.07062680274248123\n","Epoch 45: finishing mini batch 88, training error = 0.015625, loss = 0.04616015404462814\n","Epoch 45: finishing mini batch 89, training error = 0.0, loss = 0.03517308458685875\n","Epoch 45: finishing mini batch 90, training error = 0.03125, loss = 0.1865658462047577\n","Epoch 45: finishing mini batch 91, training error = 0.03125, loss = 0.09885381162166595\n","Epoch 45: finishing mini batch 92, training error = 0.09375, loss = 0.2252417802810669\n","Epoch 45: finishing mini batch 93, training error = 0.125, loss = 0.308788537979126\n","Epoch 45: finishing mini batch 94, training error = 0.03125, loss = 0.12317705154418945\n","Epoch 45: finishing mini batch 95, training error = 0.03125, loss = 0.10949020087718964\n","Epoch 45: finishing mini batch 96, training error = 0.03125, loss = 0.09837677329778671\n","Epoch 45: finishing mini batch 97, training error = 0.015625, loss = 0.08792062848806381\n","Epoch 45: finishing mini batch 98, training error = 0.03125, loss = 0.10552367568016052\n","Epoch 45: finishing mini batch 99, training error = 0.015625, loss = 0.037955403327941895\n","Epoch 45: finishing mini batch 100, training error = 0.015625, loss = 0.07115516811609268\n","Epoch 45: finishing mini batch 101, training error = 0.046875, loss = 0.1117066964507103\n","Epoch 45: finishing mini batch 102, training error = 0.0625, loss = 0.3358064293861389\n","Epoch 45: finishing mini batch 103, training error = 0.03125, loss = 0.09032856673002243\n","Epoch 45: finishing mini batch 104, training error = 0.03125, loss = 0.07989196479320526\n","Epoch 45: finishing mini batch 105, training error = 0.03125, loss = 0.13374163210391998\n","Epoch 45: finishing mini batch 106, training error = 0.03125, loss = 0.08261676877737045\n","Epoch 45: finishing mini batch 107, training error = 0.046875, loss = 0.15156903862953186\n","Epoch 45: finishing mini batch 108, training error = 0.03125, loss = 0.09961437433958054\n","Epoch 45: finishing mini batch 109, training error = 0.03125, loss = 0.09692072123289108\n","Epoch 45: finishing mini batch 110, training error = 0.015625, loss = 0.042901359498500824\n","Epoch 45: finishing mini batch 111, training error = 0.046875, loss = 0.1735137701034546\n","Epoch 45: finishing mini batch 112, training error = 0.046875, loss = 0.1044974997639656\n","Epoch 45: finishing mini batch 113, training error = 0.0625, loss = 0.14409375190734863\n","Epoch 45: finishing mini batch 114, training error = 0.015625, loss = 0.06484648585319519\n","Epoch 45: finishing mini batch 115, training error = 0.0625, loss = 0.10943849384784698\n","Epoch 45: finishing mini batch 116, training error = 0.03125, loss = 0.09817135334014893\n","Epoch 45: finishing mini batch 117, training error = 0.03125, loss = 0.0894734337925911\n","Epoch 45: finishing mini batch 118, training error = 0.046875, loss = 0.15534986555576324\n","Epoch 45: finishing mini batch 119, training error = 0.03125, loss = 0.11628929525613785\n","Epoch 45: finishing mini batch 120, training error = 0.0625, loss = 0.19861675798892975\n","Epoch 45: finishing mini batch 121, training error = 0.015625, loss = 0.06922576576471329\n","Epoch 45: finishing mini batch 122, training error = 0.0625, loss = 0.21933646500110626\n","Epoch 45: finishing mini batch 123, training error = 0.078125, loss = 0.20623505115509033\n","Epoch 45: finishing mini batch 124, training error = 0.03125, loss = 0.06644444167613983\n","Epoch 45: finishing mini batch 125, training error = 0.046875, loss = 0.11513929069042206\n","Epoch 45: finishing mini batch 126, training error = 0.0, loss = 0.024912498891353607\n","Epoch 45: finishing mini batch 127, training error = 0.03125, loss = 0.1654084473848343\n","Epoch 45: finishing mini batch 128, training error = 0.015625, loss = 0.05308062583208084\n","Epoch 45: finishing mini batch 129, training error = 0.0, loss = 0.04795721545815468\n","Epoch 45: finishing mini batch 130, training error = 0.09375, loss = 0.260933518409729\n","Epoch 45: finishing mini batch 131, training error = 0.03125, loss = 0.08248429000377655\n","Epoch 45: finishing mini batch 132, training error = 0.015625, loss = 0.062000226229429245\n","Epoch 45: finishing mini batch 133, training error = 0.046875, loss = 0.13610105216503143\n","Epoch 45: finishing mini batch 134, training error = 0.046875, loss = 0.10521512478590012\n","Epoch 45: finishing mini batch 135, training error = 0.03125, loss = 0.06772106885910034\n","Epoch 45: finishing mini batch 136, training error = 0.015625, loss = 0.036987289786338806\n","Epoch 45: finishing mini batch 137, training error = 0.0625, loss = 0.164180725812912\n","Epoch 45: finishing mini batch 138, training error = 0.03125, loss = 0.08384781330823898\n","Epoch 45: finishing mini batch 139, training error = 0.03125, loss = 0.10427302122116089\n","Epoch 45: finishing mini batch 140, training error = 0.015625, loss = 0.09276141226291656\n","Epoch 45: finishing mini batch 141, training error = 0.03125, loss = 0.04976135492324829\n","Epoch 45: finishing mini batch 142, training error = 0.0625, loss = 0.23225897550582886\n","Epoch 45: finishing mini batch 143, training error = 0.09375, loss = 0.2136612832546234\n","Epoch 45: finishing mini batch 144, training error = 0.03125, loss = 0.08222583681344986\n","Epoch 45: finishing mini batch 145, training error = 0.015625, loss = 0.06630030274391174\n","Epoch 45: finishing mini batch 146, training error = 0.0625, loss = 0.2073543816804886\n","Epoch 45: finishing mini batch 147, training error = 0.0625, loss = 0.16567720472812653\n","Epoch 45: finishing mini batch 148, training error = 0.0625, loss = 0.19793766736984253\n","Epoch 45: finishing mini batch 149, training error = 0.03125, loss = 0.05689729005098343\n","Epoch 45: finishing mini batch 150, training error = 0.125, loss = 0.29170146584510803\n","Epoch 45: finishing mini batch 151, training error = 0.078125, loss = 0.13867983222007751\n","Epoch 45: finishing mini batch 152, training error = 0.078125, loss = 0.22288745641708374\n","Epoch 45: finishing mini batch 153, training error = 0.046875, loss = 0.12347697466611862\n","Epoch 45: finishing mini batch 154, training error = 0.09375, loss = 0.21732637286186218\n","Epoch 45: finishing mini batch 155, training error = 0.09375, loss = 0.18317821621894836\n","Epoch 45: finishing mini batch 156, training error = 0.046875, loss = 0.12221002578735352\n","Epoch 45: finishing mini batch 157, training error = 0.0625, loss = 0.23554064333438873\n","Epoch 45: finishing mini batch 158, training error = 0.125, loss = 0.23859208822250366\n","Epoch 45: finishing mini batch 159, training error = 0.046875, loss = 0.1334664523601532\n","Epoch 45: finishing mini batch 160, training error = 0.046875, loss = 0.12316624075174332\n","Epoch 45: finishing mini batch 161, training error = 0.03125, loss = 0.0972144827246666\n","Epoch 45: finishing mini batch 162, training error = 0.03125, loss = 0.11458095908164978\n","Epoch 45: finishing mini batch 163, training error = 0.046875, loss = 0.18386997282505035\n","Epoch 45: finishing mini batch 164, training error = 0.03125, loss = 0.07526329904794693\n","Epoch 45: finishing mini batch 165, training error = 0.109375, loss = 0.24903163313865662\n","Epoch 45: finishing mini batch 166, training error = 0.03125, loss = 0.08851425349712372\n","Epoch 45: finishing mini batch 167, training error = 0.046875, loss = 0.10450789332389832\n","Epoch 45: finishing mini batch 168, training error = 0.03125, loss = 0.07802539318799973\n","Epoch 45: finishing mini batch 169, training error = 0.015625, loss = 0.09891557693481445\n","Epoch 45: finishing mini batch 170, training error = 0.046875, loss = 0.12238627672195435\n","Epoch 45: finishing mini batch 171, training error = 0.046875, loss = 0.1359032392501831\n","Epoch 45: finishing mini batch 172, training error = 0.09375, loss = 0.24199116230010986\n","Epoch 45: finishing mini batch 173, training error = 0.03125, loss = 0.13887877762317657\n","Epoch 45: finishing mini batch 174, training error = 0.015625, loss = 0.07756879925727844\n","Epoch 45: finishing mini batch 175, training error = 0.03125, loss = 0.09144564718008041\n","Epoch 45: finishing mini batch 176, training error = 0.015625, loss = 0.08772315084934235\n","Epoch 45: finishing mini batch 177, training error = 0.03125, loss = 0.08491861820220947\n","Epoch 45: finishing mini batch 178, training error = 0.078125, loss = 0.14148350059986115\n","Epoch 45: finishing mini batch 179, training error = 0.046875, loss = 0.16392569243907928\n","Epoch 45: finishing mini batch 180, training error = 0.03125, loss = 0.09930948168039322\n","Epoch 45: finishing mini batch 181, training error = 0.0625, loss = 0.2355019450187683\n","Epoch 45: finishing mini batch 182, training error = 0.078125, loss = 0.12288478016853333\n","Epoch 45: finishing mini batch 183, training error = 0.078125, loss = 0.19370172917842865\n","Epoch 45: finishing mini batch 184, training error = 0.046875, loss = 0.12617896497249603\n","Epoch 45: finishing mini batch 185, training error = 0.046875, loss = 0.20820802450180054\n","Epoch 45: finishing mini batch 186, training error = 0.0, loss = 0.04845273494720459\n","Epoch 45: finishing mini batch 187, training error = 0.078125, loss = 0.17048922181129456\n","Epoch 45: finishing mini batch 188, training error = 0.0625, loss = 0.16815917193889618\n","Epoch 45: finishing mini batch 189, training error = 0.109375, loss = 0.3289239704608917\n","Epoch 45: finishing mini batch 190, training error = 0.015625, loss = 0.05135496333241463\n","Epoch 45: finishing mini batch 191, training error = 0.046875, loss = 0.1296899914741516\n","Epoch 45: finishing mini batch 192, training error = 0.09375, loss = 0.23381449282169342\n","Epoch 45: finishing mini batch 193, training error = 0.109375, loss = 0.23833033442497253\n","Epoch 45: finishing mini batch 194, training error = 0.03125, loss = 0.08523964881896973\n","Epoch 45: finishing mini batch 195, training error = 0.109375, loss = 0.31857773661613464\n","Epoch 45: finishing mini batch 196, training error = 0.015625, loss = 0.06453964114189148\n","Epoch 45: finishing mini batch 197, training error = 0.0625, loss = 0.19479680061340332\n","Epoch 45: finishing mini batch 198, training error = 0.03125, loss = 0.11303309351205826\n","Epoch 45: finishing mini batch 199, training error = 0.046875, loss = 0.12586332857608795\n","Epoch 45: finishing mini batch 200, training error = 0.03125, loss = 0.15050488710403442\n","Epoch 45: finishing mini batch 201, training error = 0.078125, loss = 0.2713853120803833\n","Epoch 45: finishing mini batch 202, training error = 0.078125, loss = 0.19088159501552582\n","Epoch 45: finishing mini batch 203, training error = 0.03125, loss = 0.1005379781126976\n","Epoch 45: finishing mini batch 204, training error = 0.0625, loss = 0.17285394668579102\n","Epoch 45: finishing mini batch 205, training error = 0.0, loss = 0.04681115224957466\n","Epoch 45: finishing mini batch 206, training error = 0.046875, loss = 0.13460785150527954\n","Epoch 45: finishing mini batch 207, training error = 0.078125, loss = 0.19890792667865753\n","Epoch 45: finishing mini batch 208, training error = 0.015625, loss = 0.07258448004722595\n","Epoch 45: finishing mini batch 209, training error = 0.078125, loss = 0.23090527951717377\n","Epoch 45: finishing mini batch 210, training error = 0.03125, loss = 0.0936022624373436\n","Epoch 45: finishing mini batch 211, training error = 0.046875, loss = 0.09486605226993561\n","Epoch 45: finishing mini batch 212, training error = 0.015625, loss = 0.042737849056720734\n","Epoch 45: finishing mini batch 213, training error = 0.0625, loss = 0.14968976378440857\n","Epoch 45: finishing mini batch 214, training error = 0.09375, loss = 0.2543773055076599\n","Epoch 45: finishing mini batch 215, training error = 0.09375, loss = 0.24885496497154236\n","Epoch 45: finishing mini batch 216, training error = 0.015625, loss = 0.08032436668872833\n","Epoch 45: finishing mini batch 217, training error = 0.109375, loss = 0.1780528575181961\n","Epoch 45: finishing mini batch 218, training error = 0.046875, loss = 0.09441234916448593\n","Epoch 45: finishing mini batch 219, training error = 0.03125, loss = 0.10526856780052185\n","Epoch 45: finishing mini batch 220, training error = 0.03125, loss = 0.08737152069807053\n","Epoch 45: finishing mini batch 221, training error = 0.0625, loss = 0.09890219569206238\n","Epoch 45: finishing mini batch 222, training error = 0.03125, loss = 0.09367214143276215\n","Epoch 45: finishing mini batch 223, training error = 0.03125, loss = 0.1082601398229599\n","Epoch 45: finishing mini batch 224, training error = 0.046875, loss = 0.09006013721227646\n","Epoch 45: finishing mini batch 225, training error = 0.015625, loss = 0.07627229392528534\n","Epoch 45: finishing mini batch 226, training error = 0.03125, loss = 0.13863539695739746\n","Epoch 45: finishing mini batch 227, training error = 0.125, loss = 0.2919192314147949\n","Epoch 45: finishing mini batch 228, training error = 0.015625, loss = 0.06244039535522461\n","Epoch 45: finishing mini batch 229, training error = 0.078125, loss = 0.23948583006858826\n","Epoch 45: finishing mini batch 230, training error = 0.03125, loss = 0.12763440608978271\n","Epoch 45: finishing mini batch 231, training error = 0.078125, loss = 0.14532648026943207\n","Epoch 45: finishing mini batch 232, training error = 0.0, loss = 0.02588607743382454\n","Epoch 45: finishing mini batch 233, training error = 0.0, loss = 0.054437704384326935\n","Epoch 45: finishing mini batch 234, training error = 0.0625, loss = 0.10015186667442322\n","Epoch 45: finishing mini batch 235, training error = 0.015625, loss = 0.069562166929245\n","Epoch 45: finishing mini batch 236, training error = 0.015625, loss = 0.09828446805477142\n","Epoch 45: finishing mini batch 237, training error = 0.03125, loss = 0.09014388173818588\n","Epoch 45: finishing mini batch 238, training error = 0.109375, loss = 0.2401392012834549\n","Epoch 45: finishing mini batch 239, training error = 0.015625, loss = 0.050776951014995575\n","Epoch 45: finishing mini batch 240, training error = 0.078125, loss = 0.25408703088760376\n","Epoch 45: finishing mini batch 241, training error = 0.03125, loss = 0.10576405376195908\n","Epoch 45: finishing mini batch 242, training error = 0.109375, loss = 0.22036151587963104\n","Epoch 45: finishing mini batch 243, training error = 0.046875, loss = 0.13417452573776245\n","Epoch 45: finishing mini batch 244, training error = 0.03125, loss = 0.1227761059999466\n","Epoch 45: finishing mini batch 245, training error = 0.03125, loss = 0.10262680798768997\n","Epoch 45: finishing mini batch 246, training error = 0.046875, loss = 0.11760241538286209\n","Epoch 45: finishing mini batch 247, training error = 0.0625, loss = 0.12866052985191345\n","Epoch 45: finishing mini batch 248, training error = 0.046875, loss = 0.14669565856456757\n","Epoch 45: finishing mini batch 249, training error = 0.09375, loss = 0.14909721910953522\n","Epoch 45: finishing mini batch 250, training error = 0.0, loss = 0.03924117609858513\n","Epoch 45: finishing mini batch 251, training error = 0.09375, loss = 0.25536131858825684\n","Epoch 45: finishing mini batch 252, training error = 0.078125, loss = 0.21829847991466522\n","Epoch 45: finishing mini batch 253, training error = 0.03125, loss = 0.07590317726135254\n","Epoch 45: finishing mini batch 254, training error = 0.046875, loss = 0.12318948656320572\n","Epoch 45: finishing mini batch 255, training error = 0.015625, loss = 0.05509063974022865\n","Epoch 45: finishing mini batch 256, training error = 0.03125, loss = 0.1228489801287651\n","Epoch 45: finishing mini batch 257, training error = 0.046875, loss = 0.1742868423461914\n","Epoch 45: finishing mini batch 258, training error = 0.0625, loss = 0.17554043233394623\n","Epoch 45: finishing mini batch 259, training error = 0.09375, loss = 0.1606959104537964\n","Epoch 45: finishing mini batch 260, training error = 0.046875, loss = 0.15015962719917297\n","Epoch 45: finishing mini batch 261, training error = 0.015625, loss = 0.07105309516191483\n","Epoch 45: finishing mini batch 262, training error = 0.015625, loss = 0.06860113143920898\n","Epoch 45: finishing mini batch 263, training error = 0.109375, loss = 0.30260780453681946\n","Epoch 45: finishing mini batch 264, training error = 0.0625, loss = 0.10040007531642914\n","Epoch 45: finishing mini batch 265, training error = 0.015625, loss = 0.08418901264667511\n","Epoch 45: finishing mini batch 266, training error = 0.078125, loss = 0.1780993640422821\n","Epoch 45: finishing mini batch 267, training error = 0.046875, loss = 0.0893993005156517\n","Epoch 45: finishing mini batch 268, training error = 0.0625, loss = 0.15146459639072418\n","Epoch 45: finishing mini batch 269, training error = 0.046875, loss = 0.1642875224351883\n","Epoch 45: finishing mini batch 270, training error = 0.0, loss = 0.04540697857737541\n","Epoch 45: finishing mini batch 271, training error = 0.046875, loss = 0.10286784172058105\n","Epoch 45: finishing mini batch 272, training error = 0.015625, loss = 0.04141797125339508\n","Epoch 45: finishing mini batch 273, training error = 0.046875, loss = 0.18783047795295715\n","Epoch 45: finishing mini batch 274, training error = 0.015625, loss = 0.08902283757925034\n","Epoch 45: finishing mini batch 275, training error = 0.03125, loss = 0.08006782829761505\n","Epoch 45: finishing mini batch 276, training error = 0.0, loss = 0.04482933506369591\n","Epoch 45: finishing mini batch 277, training error = 0.03125, loss = 0.09160730242729187\n","Epoch 45: finishing mini batch 278, training error = 0.125, loss = 0.2511696219444275\n","Epoch 45: finishing mini batch 279, training error = 0.046875, loss = 0.19446350634098053\n","Epoch 45: finishing mini batch 280, training error = 0.015625, loss = 0.06420112401247025\n","Epoch 45: finishing mini batch 281, training error = 0.078125, loss = 0.15926413238048553\n","Epoch 45: finishing mini batch 282, training error = 0.03125, loss = 0.12032230198383331\n","Epoch 45: finishing mini batch 283, training error = 0.046875, loss = 0.14416687190532684\n","Epoch 45: finishing mini batch 284, training error = 0.0, loss = 0.025831295177340508\n","Epoch 45: finishing mini batch 285, training error = 0.03125, loss = 0.09396720677614212\n","Epoch 45: finishing mini batch 286, training error = 0.078125, loss = 0.10147365927696228\n","Epoch 45: finishing mini batch 287, training error = 0.078125, loss = 0.2866864502429962\n","Epoch 45: finishing mini batch 288, training error = 0.015625, loss = 0.08671749383211136\n","Epoch 45: finishing mini batch 289, training error = 0.03125, loss = 0.15286831557750702\n","Epoch 45: finishing mini batch 290, training error = 0.046875, loss = 0.13427506387233734\n","Epoch 45: finishing mini batch 291, training error = 0.0, loss = 0.038754455745220184\n","Epoch 45: finishing mini batch 292, training error = 0.046875, loss = 0.11598341166973114\n","Epoch 45: finishing mini batch 293, training error = 0.046875, loss = 0.115052230656147\n","Epoch 45: finishing mini batch 294, training error = 0.109375, loss = 0.2718593180179596\n","Epoch 45: finishing mini batch 295, training error = 0.0625, loss = 0.27198919653892517\n","Epoch 45: finishing mini batch 296, training error = 0.015625, loss = 0.09717078506946564\n","Epoch 45: finishing mini batch 297, training error = 0.078125, loss = 0.19209598004817963\n","Epoch 45: finishing mini batch 298, training error = 0.03125, loss = 0.10162175446748734\n","Epoch 45: finishing mini batch 299, training error = 0.0625, loss = 0.1095951721072197\n","Epoch 45: finishing mini batch 300, training error = 0.09375, loss = 0.2268572598695755\n","Epoch 45: finishing mini batch 301, training error = 0.046875, loss = 0.13107432425022125\n","Epoch 45: finishing mini batch 302, training error = 0.0625, loss = 0.17316316068172455\n","Epoch 45: finishing mini batch 303, training error = 0.03125, loss = 0.1634647399187088\n","Epoch 45: finishing mini batch 304, training error = 0.03125, loss = 0.08874122053384781\n","Epoch 45: finishing mini batch 305, training error = 0.03125, loss = 0.12130960822105408\n","Epoch 45: finishing mini batch 306, training error = 0.046875, loss = 0.11984290182590485\n","Epoch 45: finishing mini batch 307, training error = 0.0625, loss = 0.20247989892959595\n","Epoch 45: finishing mini batch 308, training error = 0.03125, loss = 0.10051146894693375\n","Epoch 45: finishing mini batch 309, training error = 0.015625, loss = 0.05866044759750366\n","Epoch 45: finishing mini batch 310, training error = 0.046875, loss = 0.08621075749397278\n","Epoch 45: finishing mini batch 311, training error = 0.03125, loss = 0.1535658836364746\n","Epoch 45: finishing mini batch 312, training error = 0.03125, loss = 0.11809709668159485\n","Epoch 45: finishing mini batch 313, training error = 0.09375, loss = 0.25789496302604675\n","Epoch 45: finishing mini batch 314, training error = 0.046875, loss = 0.0905691459774971\n","Epoch 45: finishing mini batch 315, training error = 0.046875, loss = 0.12099765986204147\n","Epoch 45: finishing mini batch 316, training error = 0.0625, loss = 0.15638145804405212\n","Epoch 45: finishing mini batch 317, training error = 0.03125, loss = 0.14853787422180176\n","Epoch 45: finishing mini batch 318, training error = 0.046875, loss = 0.11260396987199783\n","Epoch 45: finishing mini batch 319, training error = 0.015625, loss = 0.08840357512235641\n","Epoch 45: finishing mini batch 320, training error = 0.015625, loss = 0.09996598958969116\n","Epoch 45: finishing mini batch 321, training error = 0.046875, loss = 0.12934434413909912\n","Epoch 45: finishing mini batch 322, training error = 0.046875, loss = 0.11628398299217224\n","Epoch 45: finishing mini batch 323, training error = 0.0625, loss = 0.1400594562292099\n","Epoch 45: finishing mini batch 324, training error = 0.015625, loss = 0.06165671721100807\n","Epoch 45: finishing mini batch 325, training error = 0.0625, loss = 0.16157998144626617\n","Epoch 45: finishing mini batch 326, training error = 0.046875, loss = 0.1716626137495041\n","Epoch 45: finishing mini batch 327, training error = 0.03125, loss = 0.10423897951841354\n","Epoch 45: finishing mini batch 328, training error = 0.03125, loss = 0.08012562245130539\n","Epoch 45: finishing mini batch 329, training error = 0.078125, loss = 0.15810096263885498\n","Epoch 45: finishing mini batch 330, training error = 0.046875, loss = 0.08916216343641281\n","Epoch 45: finishing mini batch 331, training error = 0.078125, loss = 0.20682957768440247\n","Epoch 45: finishing mini batch 332, training error = 0.03125, loss = 0.08108915388584137\n","Epoch 45: finishing mini batch 333, training error = 0.0625, loss = 0.11588114500045776\n","Epoch 45: finishing mini batch 334, training error = 0.03125, loss = 0.07621156424283981\n","Epoch 45: finishing mini batch 335, training error = 0.0625, loss = 0.145280122756958\n","Epoch 45: finishing mini batch 336, training error = 0.046875, loss = 0.12190544605255127\n","Epoch 45: finishing mini batch 337, training error = 0.03125, loss = 0.08488401770591736\n","Epoch 45: finishing mini batch 338, training error = 0.046875, loss = 0.09888442605733871\n","Epoch 45: finishing mini batch 339, training error = 0.046875, loss = 0.14442986249923706\n","Epoch 45: finishing mini batch 340, training error = 0.03125, loss = 0.10517406463623047\n","Epoch 45: finishing mini batch 341, training error = 0.046875, loss = 0.10275103896856308\n","Epoch 45: finishing mini batch 342, training error = 0.03125, loss = 0.09114334732294083\n","Epoch 45: finishing mini batch 343, training error = 0.046875, loss = 0.11045479774475098\n","Epoch 45: finishing mini batch 344, training error = 0.03125, loss = 0.10743138194084167\n","Epoch 45: finishing mini batch 345, training error = 0.046875, loss = 0.08056696504354477\n","Epoch 45: finishing mini batch 346, training error = 0.03125, loss = 0.10950174182653427\n","Epoch 45: finishing mini batch 347, training error = 0.03125, loss = 0.0899842157959938\n","Epoch 45: finishing mini batch 348, training error = 0.03125, loss = 0.09036768972873688\n","Epoch 45: finishing mini batch 349, training error = 0.03125, loss = 0.058602526783943176\n","Epoch 45: finishing mini batch 350, training error = 0.09375, loss = 0.2585471272468567\n","Epoch 45: finishing mini batch 351, training error = 0.046875, loss = 0.12117617577314377\n","Epoch 45: finishing mini batch 352, training error = 0.03125, loss = 0.08123744279146194\n","Epoch 45: finishing mini batch 353, training error = 0.0, loss = 0.03553250432014465\n","Epoch 45: finishing mini batch 354, training error = 0.0625, loss = 0.17515809834003448\n","Epoch 45: finishing mini batch 355, training error = 0.09375, loss = 0.30637863278388977\n","Epoch 45: finishing mini batch 356, training error = 0.015625, loss = 0.05664552375674248\n","Epoch 45: finishing mini batch 357, training error = 0.015625, loss = 0.06170429289340973\n","Epoch 45: finishing mini batch 358, training error = 0.03125, loss = 0.07946940511465073\n","Epoch 45: finishing mini batch 359, training error = 0.015625, loss = 0.07047911733388901\n","Epoch 45: finishing mini batch 360, training error = 0.046875, loss = 0.13279350101947784\n","Epoch 45: finishing mini batch 361, training error = 0.015625, loss = 0.05948299169540405\n","Epoch 45: finishing mini batch 362, training error = 0.09375, loss = 0.27076631784439087\n","Epoch 45: finishing mini batch 363, training error = 0.046875, loss = 0.21312333643436432\n","Epoch 45: finishing mini batch 364, training error = 0.0625, loss = 0.10496438294649124\n","Epoch 45: finishing mini batch 365, training error = 0.0625, loss = 0.19579285383224487\n","Epoch 45: finishing mini batch 366, training error = 0.03125, loss = 0.08644433319568634\n","Epoch 45: finishing mini batch 367, training error = 0.0, loss = 0.035684678703546524\n","Epoch 45: finishing mini batch 368, training error = 0.046875, loss = 0.170037642121315\n","Epoch 45: finishing mini batch 369, training error = 0.0625, loss = 0.1634165644645691\n","Epoch 45: finishing mini batch 370, training error = 0.0625, loss = 0.15787498652935028\n","Epoch 45: finishing mini batch 371, training error = 0.078125, loss = 0.26940375566482544\n","Epoch 45: finishing mini batch 372, training error = 0.046875, loss = 0.1035902127623558\n","Epoch 45: finishing mini batch 373, training error = 0.0625, loss = 0.14450588822364807\n","Epoch 45: finishing mini batch 374, training error = 0.015625, loss = 0.06606145203113556\n","Epoch 45: finishing mini batch 375, training error = 0.046875, loss = 0.09107303619384766\n","Epoch 45: finishing mini batch 376, training error = 0.03125, loss = 0.11770171672105789\n","Epoch 45: finishing mini batch 377, training error = 0.03125, loss = 0.0897490382194519\n","Epoch 45: finishing mini batch 378, training error = 0.03125, loss = 0.07367254048585892\n","Epoch 45: finishing mini batch 379, training error = 0.046875, loss = 0.0827639102935791\n","Epoch 45: finishing mini batch 380, training error = 0.046875, loss = 0.12698465585708618\n","Epoch 45: finishing mini batch 381, training error = 0.0625, loss = 0.24111254513263702\n","Epoch 45: finishing mini batch 382, training error = 0.046875, loss = 0.12816935777664185\n","Epoch 45: finishing mini batch 383, training error = 0.03125, loss = 0.1103920042514801\n","Epoch 45: finishing mini batch 384, training error = 0.046875, loss = 0.1312846541404724\n","Epoch 45: finishing mini batch 385, training error = 0.015625, loss = 0.03694988042116165\n","Epoch 45: finishing mini batch 386, training error = 0.09375, loss = 0.15713520348072052\n","Epoch 45: finishing mini batch 387, training error = 0.0625, loss = 0.17660076916217804\n","Epoch 45: finishing mini batch 388, training error = 0.046875, loss = 0.11804182827472687\n","Epoch 45: finishing mini batch 389, training error = 0.046875, loss = 0.10145542025566101\n","Epoch 45: finishing mini batch 390, training error = 0.09375, loss = 0.2547076642513275\n","Epoch 45: finishing mini batch 391, training error = 0.0625, loss = 0.13819074630737305\n","Epoch 45: finishing mini batch 392, training error = 0.046875, loss = 0.10547835379838943\n","Epoch 45: finishing mini batch 393, training error = 0.0625, loss = 0.15883678197860718\n","Epoch 45: finishing mini batch 394, training error = 0.03125, loss = 0.0862206518650055\n","Epoch 45: finishing mini batch 395, training error = 0.03125, loss = 0.09265349805355072\n","Epoch 45: finishing mini batch 396, training error = 0.078125, loss = 0.15631616115570068\n","Epoch 45: finishing mini batch 397, training error = 0.015625, loss = 0.08093338459730148\n","Epoch 45: finishing mini batch 398, training error = 0.015625, loss = 0.06184253841638565\n","Epoch 45: finishing mini batch 399, training error = 0.03125, loss = 0.07936754077672958\n","Epoch 45: finishing mini batch 400, training error = 0.078125, loss = 0.17534607648849487\n","Epoch 45: finishing mini batch 401, training error = 0.015625, loss = 0.10166676342487335\n","Epoch 45: finishing mini batch 402, training error = 0.046875, loss = 0.09648530930280685\n","Epoch 45: finishing mini batch 403, training error = 0.0625, loss = 0.1592739373445511\n","Epoch 45: finishing mini batch 404, training error = 0.03125, loss = 0.06949260830879211\n","Epoch 45: finishing mini batch 405, training error = 0.046875, loss = 0.15732555091381073\n","Epoch 45: finishing mini batch 406, training error = 0.046875, loss = 0.13770370185375214\n","Epoch 45: finishing mini batch 407, training error = 0.078125, loss = 0.14978699386119843\n","Epoch 45: finishing mini batch 408, training error = 0.0625, loss = 0.13517317175865173\n","Epoch 45: finishing mini batch 409, training error = 0.0625, loss = 0.18656210601329803\n","Epoch 45: finishing mini batch 410, training error = 0.0625, loss = 0.13832102715969086\n","Epoch 45: finishing mini batch 411, training error = 0.0625, loss = 0.13407914340496063\n","Epoch 45: finishing mini batch 412, training error = 0.109375, loss = 0.21337226033210754\n","Epoch 45: finishing mini batch 413, training error = 0.046875, loss = 0.06702668964862823\n","Epoch 45: finishing mini batch 414, training error = 0.03125, loss = 0.12076237052679062\n","Epoch 45: finishing mini batch 415, training error = 0.015625, loss = 0.05589368939399719\n","Epoch 45: finishing mini batch 416, training error = 0.015625, loss = 0.08818602561950684\n","Epoch 45: finishing mini batch 417, training error = 0.046875, loss = 0.14844666421413422\n","Epoch 45: finishing mini batch 418, training error = 0.0625, loss = 0.10764022171497345\n","Epoch 45: finishing mini batch 419, training error = 0.03125, loss = 0.09145677834749222\n","Epoch 45: finishing mini batch 420, training error = 0.09375, loss = 0.25385114550590515\n","Epoch 45: finishing mini batch 421, training error = 0.015625, loss = 0.07560382783412933\n","Epoch 45: finishing mini batch 422, training error = 0.015625, loss = 0.04379309341311455\n","Epoch 45: finishing mini batch 423, training error = 0.078125, loss = 0.1929681897163391\n","Epoch 45: finishing mini batch 424, training error = 0.0, loss = 0.0400923453271389\n","Epoch 45: finishing mini batch 425, training error = 0.078125, loss = 0.18104103207588196\n","Epoch 45: finishing mini batch 426, training error = 0.09375, loss = 0.2727833688259125\n","Epoch 45: finishing mini batch 427, training error = 0.03125, loss = 0.09541714936494827\n","Epoch 45: finishing mini batch 428, training error = 0.046875, loss = 0.08767232298851013\n","Epoch 45: finishing mini batch 429, training error = 0.046875, loss = 0.1440928727388382\n","Epoch 45: finishing mini batch 430, training error = 0.03125, loss = 0.13267654180526733\n","Epoch 45: finishing mini batch 431, training error = 0.03125, loss = 0.057918500155210495\n","Epoch 45: finishing mini batch 432, training error = 0.046875, loss = 0.14456109702587128\n","Epoch 45: finishing mini batch 433, training error = 0.03125, loss = 0.06862250715494156\n","Epoch 45: finishing mini batch 434, training error = 0.046875, loss = 0.18787913024425507\n","Epoch 45: finishing mini batch 435, training error = 0.03125, loss = 0.0916164442896843\n","Epoch 45: finishing mini batch 436, training error = 0.046875, loss = 0.1403300017118454\n","Epoch 45: finishing mini batch 437, training error = 0.0, loss = 0.027805602177977562\n","Epoch 45: finishing mini batch 438, training error = 0.015625, loss = 0.07295141369104385\n","Epoch 45: finishing mini batch 439, training error = 0.0625, loss = 0.1530895233154297\n","Epoch 45: finishing mini batch 440, training error = 0.046875, loss = 0.19839738309383392\n","Epoch 45: finishing mini batch 441, training error = 0.046875, loss = 0.10760680586099625\n","Epoch 45: finishing mini batch 442, training error = 0.0625, loss = 0.19205017387866974\n","Epoch 45: finishing mini batch 443, training error = 0.0625, loss = 0.1586216539144516\n","Epoch 45: finishing mini batch 444, training error = 0.0625, loss = 0.10165563970804214\n","Epoch 45: finishing mini batch 445, training error = 0.03125, loss = 0.07115583121776581\n","Epoch 45: finishing mini batch 446, training error = 0.078125, loss = 0.1528232842683792\n","Epoch 45: finishing mini batch 447, training error = 0.015625, loss = 0.09780827909708023\n","Epoch 45: finishing mini batch 448, training error = 0.015625, loss = 0.09709572792053223\n","Epoch 45: finishing mini batch 449, training error = 0.046875, loss = 0.14781971275806427\n","Epoch 45: finishing mini batch 450, training error = 0.046875, loss = 0.0829319879412651\n","Epoch 45: finishing mini batch 451, training error = 0.015625, loss = 0.06819070875644684\n","Epoch 45: finishing mini batch 452, training error = 0.03125, loss = 0.15121832489967346\n","Epoch 45: finishing mini batch 453, training error = 0.078125, loss = 0.11506195366382599\n","Epoch 45: finishing mini batch 454, training error = 0.015625, loss = 0.05014559626579285\n","Epoch 45: finishing mini batch 455, training error = 0.03125, loss = 0.07935275137424469\n","Epoch 45: finishing mini batch 456, training error = 0.109375, loss = 0.220656156539917\n","Epoch 45: finishing mini batch 457, training error = 0.078125, loss = 0.1648782640695572\n","Epoch 45: finishing mini batch 458, training error = 0.046875, loss = 0.10551192611455917\n","Epoch 45: finishing mini batch 459, training error = 0.03125, loss = 0.0882067009806633\n","Epoch 45: finishing mini batch 460, training error = 0.0625, loss = 0.2051522135734558\n","Epoch 45: finishing mini batch 461, training error = 0.046875, loss = 0.15374064445495605\n","Epoch 45: finishing mini batch 462, training error = 0.078125, loss = 0.16598354279994965\n","Epoch 45: finishing mini batch 463, training error = 0.0625, loss = 0.15944461524486542\n","Epoch 45: finishing mini batch 464, training error = 0.0, loss = 0.025794617831707\n","Epoch 45: finishing mini batch 465, training error = 0.046875, loss = 0.1499023288488388\n","Epoch 45: finishing mini batch 466, training error = 0.03125, loss = 0.13821999728679657\n","Epoch 45: finishing mini batch 467, training error = 0.03125, loss = 0.15564434230327606\n","Epoch 45: finishing mini batch 468, training error = 0.0625, loss = 0.16502146422863007\n","Epoch 45: finishing mini batch 469, training error = 0.0625, loss = 0.07896587997674942\n","Epoch 45: finishing mini batch 470, training error = 0.0625, loss = 0.10571251064538956\n","Epoch 45: finishing mini batch 471, training error = 0.03125, loss = 0.1388605237007141\n","Epoch 45: finishing mini batch 472, training error = 0.0, loss = 0.04550255462527275\n","Epoch 45: finishing mini batch 473, training error = 0.0625, loss = 0.1620967984199524\n","Epoch 45: finishing mini batch 474, training error = 0.015625, loss = 0.06398311257362366\n","Epoch 45: finishing mini batch 475, training error = 0.03125, loss = 0.07427406311035156\n","Epoch 45: finishing mini batch 476, training error = 0.0625, loss = 0.13630224764347076\n","Epoch 45: finishing mini batch 477, training error = 0.03125, loss = 0.10267744213342667\n","Epoch 45: finishing mini batch 478, training error = 0.0625, loss = 0.14970849454402924\n","Epoch 45: finishing mini batch 479, training error = 0.03125, loss = 0.07583390921354294\n","Epoch 45: finishing mini batch 480, training error = 0.03125, loss = 0.07672605663537979\n","Epoch 45: finishing mini batch 481, training error = 0.078125, loss = 0.18593883514404297\n","Epoch 45: finishing mini batch 482, training error = 0.0625, loss = 0.14442682266235352\n","Epoch 45: finishing mini batch 483, training error = 0.03125, loss = 0.10464414209127426\n","Epoch 45: finishing mini batch 484, training error = 0.078125, loss = 0.09855819493532181\n","Epoch 45: finishing mini batch 485, training error = 0.09375, loss = 0.1664307415485382\n","Epoch 45: finishing mini batch 486, training error = 0.0, loss = 0.05333293601870537\n","Epoch 45: finishing mini batch 487, training error = 0.046875, loss = 0.13857828080654144\n","Epoch 45: finishing mini batch 488, training error = 0.046875, loss = 0.10639236122369766\n","Epoch 45: finishing mini batch 489, training error = 0.03125, loss = 0.0814160481095314\n","Epoch 45: finishing mini batch 490, training error = 0.03125, loss = 0.08086241036653519\n","Epoch 45: finishing mini batch 491, training error = 0.046875, loss = 0.13896355032920837\n","Epoch 45: finishing mini batch 492, training error = 0.0625, loss = 0.15380921959877014\n","Epoch 45: finishing mini batch 493, training error = 0.015625, loss = 0.08016791939735413\n","Epoch 45: finishing mini batch 494, training error = 0.0625, loss = 0.2113994061946869\n","Epoch 45: finishing mini batch 495, training error = 0.015625, loss = 0.10689682513475418\n","Epoch 45: finishing mini batch 496, training error = 0.046875, loss = 0.1289691925048828\n","Epoch 45: finishing mini batch 497, training error = 0.046875, loss = 0.10442706942558289\n","Epoch 45: finishing mini batch 498, training error = 0.046875, loss = 0.13538667559623718\n","Epoch 45: finishing mini batch 499, training error = 0.078125, loss = 0.20212821662425995\n","Epoch 45: finishing mini batch 500, training error = 0.015625, loss = 0.06516491621732712\n","Epoch 45: finishing mini batch 501, training error = 0.015625, loss = 0.05332857742905617\n","Epoch 45: finishing mini batch 502, training error = 0.078125, loss = 0.1119195818901062\n","Epoch 45: finishing mini batch 503, training error = 0.03125, loss = 0.0642649233341217\n","Epoch 45: finishing mini batch 504, training error = 0.078125, loss = 0.18503575026988983\n","Epoch 45: finishing mini batch 505, training error = 0.015625, loss = 0.076278917491436\n","Epoch 45: finishing mini batch 506, training error = 0.0625, loss = 0.10737622529268265\n","Epoch 45: finishing mini batch 507, training error = 0.109375, loss = 0.22599384188652039\n","Epoch 45: finishing mini batch 508, training error = 0.03125, loss = 0.07013876736164093\n","Epoch 45: finishing mini batch 509, training error = 0.03125, loss = 0.08082341402769089\n","Epoch 45: finishing mini batch 510, training error = 0.0625, loss = 0.24259018898010254\n","Epoch 45: finishing mini batch 511, training error = 0.046875, loss = 0.14432744681835175\n","Epoch 45: finishing mini batch 512, training error = 0.0625, loss = 0.11985170096158981\n","Epoch 45: finishing mini batch 513, training error = 0.078125, loss = 0.16511330008506775\n","Epoch 45: finishing mini batch 514, training error = 0.0625, loss = 0.20207753777503967\n","Epoch 45: finishing mini batch 515, training error = 0.046875, loss = 0.13137833774089813\n","Epoch 45: finishing mini batch 516, training error = 0.09375, loss = 0.35683107376098633\n","Epoch 45: finishing mini batch 517, training error = 0.03125, loss = 0.1025712862610817\n","Epoch 45: finishing mini batch 518, training error = 0.078125, loss = 0.1409555822610855\n","Epoch 45: finishing mini batch 519, training error = 0.09375, loss = 0.20165088772773743\n","Epoch 45: finishing mini batch 520, training error = 0.0625, loss = 0.12401668727397919\n","Epoch 45: finishing mini batch 521, training error = 0.0625, loss = 0.16448400914669037\n","Epoch 45: finishing mini batch 522, training error = 0.125, loss = 0.30299273133277893\n","Epoch 45: finishing mini batch 523, training error = 0.03125, loss = 0.1007445678114891\n","Epoch 45: finishing mini batch 524, training error = 0.015625, loss = 0.061269376426935196\n","Epoch 45: finishing mini batch 525, training error = 0.0625, loss = 0.16244059801101685\n","Epoch 45: finishing mini batch 526, training error = 0.015625, loss = 0.16311068832874298\n","Epoch 45: finishing mini batch 527, training error = 0.046875, loss = 0.14932720363140106\n","Epoch 45: finishing mini batch 528, training error = 0.078125, loss = 0.1634475439786911\n","Epoch 45: finishing mini batch 529, training error = 0.03125, loss = 0.08285395056009293\n","Epoch 45: finishing mini batch 530, training error = 0.03125, loss = 0.06338702887296677\n","Epoch 45: finishing mini batch 531, training error = 0.0625, loss = 0.18068809807300568\n","Epoch 45: finishing mini batch 532, training error = 0.109375, loss = 0.25966736674308777\n","Epoch 45: finishing mini batch 533, training error = 0.09375, loss = 0.1919749677181244\n","Epoch 45: finishing mini batch 534, training error = 0.03125, loss = 0.1287662386894226\n","Epoch 45: finishing mini batch 535, training error = 0.015625, loss = 0.07844986766576767\n","Epoch 45: finishing mini batch 536, training error = 0.0625, loss = 0.13279274106025696\n","Epoch 45: finishing mini batch 537, training error = 0.046875, loss = 0.12559755146503448\n","Epoch 45: finishing mini batch 538, training error = 0.078125, loss = 0.15701602399349213\n","Epoch 45: finishing mini batch 539, training error = 0.09375, loss = 0.2637442946434021\n","Epoch 45: finishing mini batch 540, training error = 0.046875, loss = 0.13606922328472137\n","Epoch 45: finishing mini batch 541, training error = 0.109375, loss = 0.2408183217048645\n","Epoch 45: finishing mini batch 542, training error = 0.046875, loss = 0.10464166849851608\n","Epoch 45: finishing mini batch 543, training error = 0.0625, loss = 0.1296284943819046\n","Epoch 45: finishing mini batch 544, training error = 0.0625, loss = 0.1448192447423935\n","Epoch 45: finishing mini batch 545, training error = 0.046875, loss = 0.15930140018463135\n","Epoch 45: finishing mini batch 546, training error = 0.078125, loss = 0.17817363142967224\n","Epoch 45: finishing mini batch 547, training error = 0.0625, loss = 0.16410350799560547\n","Epoch 45: finishing mini batch 548, training error = 0.0625, loss = 0.14634986221790314\n","Epoch 45: finishing mini batch 549, training error = 0.0625, loss = 0.1702936887741089\n","Epoch 45: finishing mini batch 550, training error = 0.0625, loss = 0.20618517696857452\n","Epoch 45: finishing mini batch 551, training error = 0.03125, loss = 0.08714986592531204\n","Epoch 45: finishing mini batch 552, training error = 0.0625, loss = 0.14104250073432922\n","Epoch 45: finishing mini batch 553, training error = 0.015625, loss = 0.09235398471355438\n","Epoch 45: finishing mini batch 554, training error = 0.046875, loss = 0.22332367300987244\n","Epoch 45: finishing mini batch 555, training error = 0.078125, loss = 0.1633908897638321\n","Epoch 45: finishing mini batch 556, training error = 0.0625, loss = 0.10824697464704514\n","Epoch 45: finishing mini batch 557, training error = 0.0625, loss = 0.19382673501968384\n","Epoch 45: finishing mini batch 558, training error = 0.078125, loss = 0.16510042548179626\n","Epoch 45: finishing mini batch 559, training error = 0.0625, loss = 0.1685182899236679\n","Epoch 45: finishing mini batch 560, training error = 0.078125, loss = 0.1874079555273056\n","Epoch 45: finishing mini batch 561, training error = 0.0625, loss = 0.21669334173202515\n","Epoch 45: finishing mini batch 562, training error = 0.046875, loss = 0.14285045862197876\n","Epoch 45: finishing mini batch 563, training error = 0.046875, loss = 0.1591411679983139\n","Epoch 45: finishing mini batch 564, training error = 0.078125, loss = 0.22615133225917816\n","Epoch 45: finishing mini batch 565, training error = 0.046875, loss = 0.1196388378739357\n","Epoch 45: finishing mini batch 566, training error = 0.09375, loss = 0.23529650270938873\n","Epoch 45: finishing mini batch 567, training error = 0.09375, loss = 0.2026282101869583\n","Epoch 45: finishing mini batch 568, training error = 0.078125, loss = 0.12170692533254623\n","Epoch 45: finishing mini batch 569, training error = 0.0625, loss = 0.17660516500473022\n","Epoch 45: finishing mini batch 570, training error = 0.046875, loss = 0.07932370156049728\n","Epoch 45: finishing mini batch 571, training error = 0.03125, loss = 0.11055557429790497\n","Epoch 45: finishing mini batch 572, training error = 0.0625, loss = 0.14270740747451782\n","Epoch 45: finishing mini batch 573, training error = 0.0, loss = 0.03517698869109154\n","Epoch 45: finishing mini batch 574, training error = 0.046875, loss = 0.11774136871099472\n","Epoch 45: finishing mini batch 575, training error = 0.0625, loss = 0.13882781565189362\n","Epoch 45: finishing mini batch 576, training error = 0.03125, loss = 0.08699675649404526\n","Epoch 45: finishing mini batch 577, training error = 0.03125, loss = 0.08225973695516586\n","Epoch 45: finishing mini batch 578, training error = 0.09375, loss = 0.28902360796928406\n","Epoch 45: finishing mini batch 579, training error = 0.0625, loss = 0.1380464732646942\n","Epoch 45: finishing mini batch 580, training error = 0.078125, loss = 0.1353948563337326\n","Epoch 45: finishing mini batch 581, training error = 0.046875, loss = 0.08927083760499954\n","Epoch 45: finishing mini batch 582, training error = 0.015625, loss = 0.055659711360931396\n","Epoch 45: finishing mini batch 583, training error = 0.0, loss = 0.07434490323066711\n","Epoch 45: finishing mini batch 584, training error = 0.015625, loss = 0.06647396087646484\n","Epoch 45: finishing mini batch 585, training error = 0.046875, loss = 0.12486617267131805\n","Epoch 45: finishing mini batch 586, training error = 0.109375, loss = 0.2532995939254761\n","Epoch 45: finishing mini batch 587, training error = 0.046875, loss = 0.14835694432258606\n","Epoch 45: finishing mini batch 588, training error = 0.125, loss = 0.4724418818950653\n","Epoch 45: finishing mini batch 589, training error = 0.046875, loss = 0.11322036385536194\n","Epoch 45: finishing mini batch 590, training error = 0.046875, loss = 0.16483300924301147\n","Epoch 45: finishing mini batch 591, training error = 0.125, loss = 0.23338109254837036\n","Epoch 45: finishing mini batch 592, training error = 0.046875, loss = 0.18206945061683655\n","Epoch 45: finishing mini batch 593, training error = 0.03125, loss = 0.12371578067541122\n","Epoch 45: finishing mini batch 594, training error = 0.0625, loss = 0.09100731462240219\n","Epoch 45: finishing mini batch 595, training error = 0.0625, loss = 0.1531696915626526\n","Epoch 45: finishing mini batch 596, training error = 0.015625, loss = 0.08290445804595947\n","Epoch 45: finishing mini batch 597, training error = 0.078125, loss = 0.1647476702928543\n","Epoch 45: finishing mini batch 598, training error = 0.109375, loss = 0.2780410051345825\n","Epoch 45: finishing mini batch 599, training error = 0.078125, loss = 0.13768494129180908\n","Epoch 45: finishing mini batch 600, training error = 0.0625, loss = 0.14565862715244293\n","Epoch 45: finishing mini batch 601, training error = 0.078125, loss = 0.2480459213256836\n","Epoch 45: finishing mini batch 602, training error = 0.046875, loss = 0.1161506325006485\n","Epoch 45: finishing mini batch 603, training error = 0.109375, loss = 0.18349969387054443\n","Epoch 45: finishing mini batch 604, training error = 0.109375, loss = 0.3288467228412628\n","Epoch 45: finishing mini batch 605, training error = 0.046875, loss = 0.14695461094379425\n","Epoch 45: finishing mini batch 606, training error = 0.046875, loss = 0.18005238473415375\n","Epoch 45: finishing mini batch 607, training error = 0.125, loss = 0.32136270403862\n","Epoch 45: finishing mini batch 608, training error = 0.0625, loss = 0.15236759185791016\n","Epoch 45: finishing mini batch 609, training error = 0.078125, loss = 0.13845941424369812\n","Epoch 45: finishing mini batch 610, training error = 0.03125, loss = 0.15568313002586365\n","Epoch 45: finishing mini batch 611, training error = 0.09375, loss = 0.1881343126296997\n","Epoch 45: finishing mini batch 612, training error = 0.109375, loss = 0.3554224371910095\n","Epoch 45: finishing mini batch 613, training error = 0.015625, loss = 0.11809848248958588\n","Epoch 45: finishing mini batch 614, training error = 0.015625, loss = 0.09250697493553162\n","Epoch 45: finishing mini batch 615, training error = 0.015625, loss = 0.058401916176080704\n","Epoch 45: finishing mini batch 616, training error = 0.078125, loss = 0.20508690178394318\n","Epoch 45: finishing mini batch 617, training error = 0.125, loss = 0.4452352225780487\n","Epoch 45: finishing mini batch 618, training error = 0.078125, loss = 0.14000651240348816\n","Epoch 45: finishing mini batch 619, training error = 0.078125, loss = 0.25264662504196167\n","Epoch 45: finishing mini batch 620, training error = 0.0625, loss = 0.1362549513578415\n","Epoch 45: finishing mini batch 621, training error = 0.09375, loss = 0.29168248176574707\n","Epoch 45: finishing mini batch 622, training error = 0.015625, loss = 0.07706225663423538\n","Epoch 45: finishing mini batch 623, training error = 0.078125, loss = 0.18879009783267975\n","Epoch 45: finishing mini batch 624, training error = 0.0625, loss = 0.23813018202781677\n","Epoch 45: finishing mini batch 625, training error = 0.0625, loss = 0.18888938426971436\n","Epoch 45: finishing mini batch 626, training error = 0.09375, loss = 0.1957552134990692\n","Epoch 45: finishing mini batch 627, training error = 0.09375, loss = 0.2758174240589142\n","Epoch 45: finishing mini batch 628, training error = 0.078125, loss = 0.16419841349124908\n","Epoch 45: finishing mini batch 629, training error = 0.078125, loss = 0.21051056683063507\n","Epoch 45: finishing mini batch 630, training error = 0.0625, loss = 0.16243873536586761\n","Epoch 45: finishing mini batch 631, training error = 0.09375, loss = 0.26769423484802246\n","Epoch 45: finishing mini batch 632, training error = 0.09375, loss = 0.23009173572063446\n","Epoch 45: finishing mini batch 633, training error = 0.171875, loss = 0.49282050132751465\n","Epoch 45: finishing mini batch 634, training error = 0.0625, loss = 0.15510085225105286\n","Epoch 45: finishing mini batch 635, training error = 0.046875, loss = 0.12995706498622894\n","Epoch 45: finishing mini batch 636, training error = 0.09375, loss = 0.2101554125547409\n","Epoch 45: finishing mini batch 637, training error = 0.03125, loss = 0.11129658669233322\n","Epoch 45: finishing mini batch 638, training error = 0.03125, loss = 0.09210476279258728\n","Epoch 45: finishing mini batch 639, training error = 0.078125, loss = 0.24070820212364197\n","Epoch 45: finishing mini batch 640, training error = 0.015625, loss = 0.07837463915348053\n","Epoch 45: finishing mini batch 641, training error = 0.046875, loss = 0.11680594086647034\n","Epoch 45: finishing mini batch 642, training error = 0.03125, loss = 0.09232987463474274\n","Epoch 45: finishing mini batch 643, training error = 0.0625, loss = 0.20963548123836517\n","Epoch 45: finishing mini batch 644, training error = 0.046875, loss = 0.11014815419912338\n","Epoch 45: finishing mini batch 645, training error = 0.09375, loss = 0.18454329669475555\n","Epoch 45: finishing mini batch 646, training error = 0.171875, loss = 0.3433937728404999\n","Epoch 45: finishing mini batch 647, training error = 0.078125, loss = 0.16390293836593628\n","Epoch 45: finishing mini batch 648, training error = 0.109375, loss = 0.2414611279964447\n","Epoch 45: finishing mini batch 649, training error = 0.046875, loss = 0.11389313638210297\n","Epoch 45: finishing mini batch 650, training error = 0.109375, loss = 0.37086477875709534\n","Epoch 45: finishing mini batch 651, training error = 0.0, loss = 0.07375382632017136\n","Epoch 45: finishing mini batch 652, training error = 0.09375, loss = 0.2906860113143921\n","Epoch 45: finishing mini batch 653, training error = 0.046875, loss = 0.12609046697616577\n","Epoch 45: finishing mini batch 654, training error = 0.09375, loss = 0.27636730670928955\n","Epoch 45: finishing mini batch 655, training error = 0.09375, loss = 0.1897820085287094\n","Epoch 45: finishing mini batch 656, training error = 0.015625, loss = 0.05639982968568802\n","Epoch 45: finishing mini batch 657, training error = 0.046875, loss = 0.10022968053817749\n","Epoch 45: finishing mini batch 658, training error = 0.09375, loss = 0.2857968509197235\n","Epoch 45: finishing mini batch 659, training error = 0.046875, loss = 0.12934860587120056\n","Epoch 45: finishing mini batch 660, training error = 0.09375, loss = 0.13043950498104095\n","Epoch 45: finishing mini batch 661, training error = 0.140625, loss = 0.4447013735771179\n","Epoch 45: finishing mini batch 662, training error = 0.078125, loss = 0.2234094738960266\n","Epoch 45: finishing mini batch 663, training error = 0.078125, loss = 0.1747669279575348\n","Epoch 45: finishing mini batch 664, training error = 0.109375, loss = 0.21990886330604553\n","Epoch 45: finishing mini batch 665, training error = 0.03125, loss = 0.09260353446006775\n","Epoch 45: finishing mini batch 666, training error = 0.09375, loss = 0.1963324248790741\n","Epoch 45: finishing mini batch 667, training error = 0.0625, loss = 0.19356173276901245\n","Epoch 45: finishing mini batch 668, training error = 0.09375, loss = 0.27846822142601013\n","Epoch 45: finishing mini batch 669, training error = 0.046875, loss = 0.10057927668094635\n","Epoch 45: finishing mini batch 670, training error = 0.015625, loss = 0.05908171460032463\n","Epoch 45: finishing mini batch 671, training error = 0.078125, loss = 0.12450136244297028\n","Epoch 45: finishing mini batch 672, training error = 0.0625, loss = 0.1700463891029358\n","Epoch 45: finishing mini batch 673, training error = 0.0625, loss = 0.16063252091407776\n","Epoch 45: finishing mini batch 674, training error = 0.0625, loss = 0.20933179557323456\n","Epoch 45: finishing mini batch 675, training error = 0.078125, loss = 0.2030370682477951\n","Epoch 45: finishing mini batch 676, training error = 0.03125, loss = 0.07223454117774963\n","Epoch 45: finishing mini batch 677, training error = 0.046875, loss = 0.15417605638504028\n","Epoch 45: finishing mini batch 678, training error = 0.078125, loss = 0.2770731449127197\n","Epoch 45: finishing mini batch 679, training error = 0.078125, loss = 0.246995747089386\n","Epoch 45: finishing mini batch 680, training error = 0.125, loss = 0.27725133299827576\n","Epoch 45: finishing mini batch 681, training error = 0.046875, loss = 0.1272604763507843\n","Epoch 45: finishing mini batch 682, training error = 0.078125, loss = 0.15368618071079254\n","Epoch 45: finishing mini batch 683, training error = 0.078125, loss = 0.21535076200962067\n","Epoch 45: finishing mini batch 684, training error = 0.078125, loss = 0.2217789888381958\n","Epoch 45: finishing mini batch 685, training error = 0.046875, loss = 0.1509149670600891\n","Epoch 45: finishing mini batch 686, training error = 0.03125, loss = 0.14606553316116333\n","Epoch 45: finishing mini batch 687, training error = 0.109375, loss = 0.26118940114974976\n","Epoch 45: finishing mini batch 688, training error = 0.140625, loss = 0.32681021094322205\n","Epoch 45: finishing mini batch 689, training error = 0.03125, loss = 0.1049894466996193\n","Epoch 45: finishing mini batch 690, training error = 0.03125, loss = 0.07917900383472443\n","Epoch 45: finishing mini batch 691, training error = 0.09375, loss = 0.14400607347488403\n","Epoch 45: finishing mini batch 692, training error = 0.015625, loss = 0.07836300879716873\n","Epoch 45: finishing mini batch 693, training error = 0.046875, loss = 0.1292317658662796\n","Epoch 45: finishing mini batch 694, training error = 0.09375, loss = 0.2992325723171234\n","Epoch 45: finishing mini batch 695, training error = 0.046875, loss = 0.15549342334270477\n","Epoch 45: finishing mini batch 696, training error = 0.03125, loss = 0.09522851556539536\n","Epoch 45: finishing mini batch 697, training error = 0.015625, loss = 0.10039297491312027\n","Epoch 45: finishing mini batch 698, training error = 0.125, loss = 0.27905401587486267\n","Epoch 45: finishing mini batch 699, training error = 0.0625, loss = 0.15860356390476227\n","Epoch 45: finishing mini batch 700, training error = 0.046875, loss = 0.12061627209186554\n","Epoch 45: finishing mini batch 701, training error = 0.015625, loss = 0.07887222617864609\n","Epoch 45: finishing mini batch 702, training error = 0.09375, loss = 0.19852060079574585\n","Epoch 45: finishing mini batch 703, training error = 0.171875, loss = 0.4341466724872589\n","Epoch 45: finishing mini batch 704, training error = 0.078125, loss = 0.19820943474769592\n","Epoch 45: finishing mini batch 705, training error = 0.03125, loss = 0.1660478413105011\n","Epoch 45: finishing mini batch 706, training error = 0.0625, loss = 0.22468432784080505\n","Epoch 45: finishing mini batch 707, training error = 0.03125, loss = 0.12422565370798111\n","Epoch 45: finishing mini batch 708, training error = 0.03125, loss = 0.05807757377624512\n","Epoch 45: finishing mini batch 709, training error = 0.046875, loss = 0.15046997368335724\n","Epoch 45: finishing mini batch 710, training error = 0.078125, loss = 0.18163636326789856\n","Epoch 45: finishing mini batch 711, training error = 0.09375, loss = 0.28738000988960266\n","Epoch 45: finishing mini batch 712, training error = 0.09375, loss = 0.24288734793663025\n","Epoch 45: finishing mini batch 713, training error = 0.015625, loss = 0.09036717563867569\n","Epoch 45: finishing mini batch 714, training error = 0.078125, loss = 0.1416027843952179\n","Epoch 45: finishing mini batch 715, training error = 0.03125, loss = 0.10339613258838654\n","Epoch 45: finishing mini batch 716, training error = 0.046875, loss = 0.21956926584243774\n","Epoch 45: finishing mini batch 717, training error = 0.015625, loss = 0.07396126538515091\n","Epoch 45: finishing mini batch 718, training error = 0.03125, loss = 0.1366720050573349\n","Epoch 45: finishing mini batch 719, training error = 0.015625, loss = 0.10120987147092819\n","Epoch 45: finishing mini batch 720, training error = 0.046875, loss = 0.11572775989770889\n","Epoch 45: finishing mini batch 721, training error = 0.046875, loss = 0.08950287848711014\n","Epoch 45: finishing mini batch 722, training error = 0.0625, loss = 0.2087354212999344\n","Epoch 45: finishing mini batch 723, training error = 0.046875, loss = 0.14142264425754547\n","Epoch 45: finishing mini batch 724, training error = 0.03125, loss = 0.06172700598835945\n","Epoch 45: finishing mini batch 725, training error = 0.03125, loss = 0.09343301504850388\n","Epoch 45: finishing mini batch 726, training error = 0.03125, loss = 0.09903478622436523\n","Epoch 45: finishing mini batch 727, training error = 0.03125, loss = 0.12142875790596008\n","Epoch 45: finishing mini batch 728, training error = 0.109375, loss = 0.16473068296909332\n","Epoch 45: finishing mini batch 729, training error = 0.046875, loss = 0.13755378127098083\n","Epoch 45: finishing mini batch 730, training error = 0.03125, loss = 0.12089960277080536\n","Epoch 45: finishing mini batch 731, training error = 0.078125, loss = 0.18904583156108856\n","Epoch 45: finishing mini batch 732, training error = 0.046875, loss = 0.12011951208114624\n","Epoch 45: finishing mini batch 733, training error = 0.015625, loss = 0.07058771699666977\n","Epoch 45: finishing mini batch 734, training error = 0.0625, loss = 0.17983631789684296\n","Epoch 45: finishing mini batch 735, training error = 0.015625, loss = 0.13334067165851593\n","Epoch 45: finishing mini batch 736, training error = 0.09375, loss = 0.2214801013469696\n","Epoch 45: finishing mini batch 737, training error = 0.0625, loss = 0.13969871401786804\n","Epoch 45: finishing mini batch 738, training error = 0.015625, loss = 0.07781866937875748\n","Epoch 45: finishing mini batch 739, training error = 0.09375, loss = 0.17544996738433838\n","Epoch 45: finishing mini batch 740, training error = 0.03125, loss = 0.1019245907664299\n","Epoch 45: finishing mini batch 741, training error = 0.09375, loss = 0.28594550490379333\n","Epoch 45: finishing mini batch 742, training error = 0.0625, loss = 0.1119706854224205\n","Epoch 45: finishing mini batch 743, training error = 0.03125, loss = 0.0958818718791008\n","Epoch 45: finishing mini batch 744, training error = 0.015625, loss = 0.10956213623285294\n","Epoch 45: finishing mini batch 745, training error = 0.0625, loss = 0.12558776140213013\n","Epoch 45: finishing mini batch 746, training error = 0.0625, loss = 0.13357694447040558\n","Epoch 45: finishing mini batch 747, training error = 0.046875, loss = 0.09255575388669968\n","Epoch 45: finishing mini batch 748, training error = 0.0625, loss = 0.17249324917793274\n","Epoch 45: finishing mini batch 749, training error = 0.09375, loss = 0.17779576778411865\n","Epoch 45: finishing mini batch 750, training error = 0.078125, loss = 0.1787915825843811\n","Epoch 45: finishing mini batch 751, training error = 0.0625, loss = 0.1789969652891159\n","Epoch 45: finishing mini batch 752, training error = 0.03125, loss = 0.08004288375377655\n","Epoch 45: finishing mini batch 753, training error = 0.0625, loss = 0.1546216905117035\n","Epoch 45: finishing mini batch 754, training error = 0.0, loss = 0.03804921731352806\n","Epoch 45: finishing mini batch 755, training error = 0.03125, loss = 0.0816420167684555\n","Epoch 45: finishing mini batch 756, training error = 0.046875, loss = 0.1072598546743393\n","Epoch 45: finishing mini batch 757, training error = 0.078125, loss = 0.19469720125198364\n","Epoch 45: finishing mini batch 758, training error = 0.015625, loss = 0.07142364978790283\n","Epoch 45: finishing mini batch 759, training error = 0.03125, loss = 0.08926374465227127\n","Epoch 45: finishing mini batch 760, training error = 0.046875, loss = 0.19162815809249878\n","Epoch 45: finishing mini batch 761, training error = 0.046875, loss = 0.14899109303951263\n","Epoch 45: finishing mini batch 762, training error = 0.09375, loss = 0.22316952049732208\n","Epoch 45: finishing mini batch 763, training error = 0.03125, loss = 0.10571514815092087\n","Epoch 45: finishing mini batch 764, training error = 0.03125, loss = 0.1092730313539505\n","Epoch 45: finishing mini batch 765, training error = 0.09375, loss = 0.3212316632270813\n","Epoch 45: finishing mini batch 766, training error = 0.0625, loss = 0.09949147701263428\n","Epoch 45: finishing mini batch 767, training error = 0.0625, loss = 0.14511030912399292\n","Epoch 45: finishing mini batch 768, training error = 0.109375, loss = 0.29390949010849\n","Epoch 45: finishing mini batch 769, training error = 0.09375, loss = 0.3466069996356964\n","Epoch 45: finishing mini batch 770, training error = 0.0, loss = 0.0441480427980423\n","Epoch 45: finishing mini batch 771, training error = 0.03125, loss = 0.07286940515041351\n","Epoch 45: finishing mini batch 772, training error = 0.0, loss = 0.06683909893035889\n","Epoch 45: finishing mini batch 773, training error = 0.125, loss = 0.28478214144706726\n","Epoch 45: finishing mini batch 774, training error = 0.03125, loss = 0.13776999711990356\n","Epoch 45: finishing mini batch 775, training error = 0.015625, loss = 0.062346819788217545\n","Epoch 45: finishing mini batch 776, training error = 0.078125, loss = 0.1806543469429016\n","Epoch 45: finishing mini batch 777, training error = 0.0625, loss = 0.11853177845478058\n","Epoch 45: finishing mini batch 778, training error = 0.078125, loss = 0.25159111618995667\n","Epoch 45: finishing mini batch 779, training error = 0.046875, loss = 0.12955091893672943\n","Epoch 45: finishing mini batch 780, training error = 0.078125, loss = 0.15610583126544952\n","Epoch 45: finishing mini batch 781, training error = 0.0625, loss = 0.19238784909248352\n","Epoch 45: finishing mini batch 782, training error = 0.0, loss = 0.008127933368086815\n","Epoch 45 completed, acc_loss = 109.59345788694918\n","Starting epoch 46...\n","Epoch 46: finishing mini batch 1, training error = 0.09375, loss = 0.24701882898807526\n","Epoch 46: finishing mini batch 2, training error = 0.046875, loss = 0.12971240282058716\n","Epoch 46: finishing mini batch 3, training error = 0.03125, loss = 0.11655221879482269\n","Epoch 46: finishing mini batch 4, training error = 0.046875, loss = 0.1421966552734375\n","Epoch 46: finishing mini batch 5, training error = 0.015625, loss = 0.06759104877710342\n","Epoch 46: finishing mini batch 6, training error = 0.0, loss = 0.046357933431863785\n","Epoch 46: finishing mini batch 7, training error = 0.03125, loss = 0.13224853575229645\n","Epoch 46: finishing mini batch 8, training error = 0.0625, loss = 0.21873603761196136\n","Epoch 46: finishing mini batch 9, training error = 0.0, loss = 0.053104013204574585\n","Epoch 46: finishing mini batch 10, training error = 0.0625, loss = 0.1661776900291443\n","Epoch 46: finishing mini batch 11, training error = 0.015625, loss = 0.06543578952550888\n","Epoch 46: finishing mini batch 12, training error = 0.0625, loss = 0.18080058693885803\n","Epoch 46: finishing mini batch 13, training error = 0.015625, loss = 0.06184237822890282\n","Epoch 46: finishing mini batch 14, training error = 0.03125, loss = 0.11847829818725586\n","Epoch 46: finishing mini batch 15, training error = 0.046875, loss = 0.17447543144226074\n","Epoch 46: finishing mini batch 16, training error = 0.015625, loss = 0.06150094419717789\n","Epoch 46: finishing mini batch 17, training error = 0.046875, loss = 0.10682034492492676\n","Epoch 46: finishing mini batch 18, training error = 0.015625, loss = 0.04372060298919678\n","Epoch 46: finishing mini batch 19, training error = 0.03125, loss = 0.06963036954402924\n","Epoch 46: finishing mini batch 20, training error = 0.046875, loss = 0.14257796108722687\n","Epoch 46: finishing mini batch 21, training error = 0.015625, loss = 0.06182190030813217\n","Epoch 46: finishing mini batch 22, training error = 0.046875, loss = 0.16108927130699158\n","Epoch 46: finishing mini batch 23, training error = 0.03125, loss = 0.09660756587982178\n","Epoch 46: finishing mini batch 24, training error = 0.046875, loss = 0.1255064457654953\n","Epoch 46: finishing mini batch 25, training error = 0.0625, loss = 0.10455979406833649\n","Epoch 46: finishing mini batch 26, training error = 0.046875, loss = 0.11881589889526367\n","Epoch 46: finishing mini batch 27, training error = 0.078125, loss = 0.18595416843891144\n","Epoch 46: finishing mini batch 28, training error = 0.015625, loss = 0.09253963083028793\n","Epoch 46: finishing mini batch 29, training error = 0.015625, loss = 0.05110197886824608\n","Epoch 46: finishing mini batch 30, training error = 0.046875, loss = 0.08732190728187561\n","Epoch 46: finishing mini batch 31, training error = 0.09375, loss = 0.22269387543201447\n","Epoch 46: finishing mini batch 32, training error = 0.078125, loss = 0.1440814584493637\n","Epoch 46: finishing mini batch 33, training error = 0.046875, loss = 0.12813599407672882\n","Epoch 46: finishing mini batch 34, training error = 0.0, loss = 0.05396993085741997\n","Epoch 46: finishing mini batch 35, training error = 0.015625, loss = 0.05964027717709541\n","Epoch 46: finishing mini batch 36, training error = 0.046875, loss = 0.08971242606639862\n","Epoch 46: finishing mini batch 37, training error = 0.015625, loss = 0.07837120443582535\n","Epoch 46: finishing mini batch 38, training error = 0.0625, loss = 0.28294071555137634\n","Epoch 46: finishing mini batch 39, training error = 0.0625, loss = 0.11351979523897171\n","Epoch 46: finishing mini batch 40, training error = 0.015625, loss = 0.11071648448705673\n","Epoch 46: finishing mini batch 41, training error = 0.03125, loss = 0.12371916323900223\n","Epoch 46: finishing mini batch 42, training error = 0.0, loss = 0.04943053796887398\n","Epoch 46: finishing mini batch 43, training error = 0.015625, loss = 0.045708440244197845\n","Epoch 46: finishing mini batch 44, training error = 0.046875, loss = 0.06585347652435303\n","Epoch 46: finishing mini batch 45, training error = 0.078125, loss = 0.19141051173210144\n","Epoch 46: finishing mini batch 46, training error = 0.03125, loss = 0.07017572224140167\n","Epoch 46: finishing mini batch 47, training error = 0.015625, loss = 0.09634712338447571\n","Epoch 46: finishing mini batch 48, training error = 0.015625, loss = 0.09983500093221664\n","Epoch 46: finishing mini batch 49, training error = 0.078125, loss = 0.1598127782344818\n","Epoch 46: finishing mini batch 50, training error = 0.125, loss = 0.27474209666252136\n","Epoch 46: finishing mini batch 51, training error = 0.03125, loss = 0.09193715453147888\n","Epoch 46: finishing mini batch 52, training error = 0.0, loss = 0.03275994211435318\n","Epoch 46: finishing mini batch 53, training error = 0.046875, loss = 0.10092699527740479\n","Epoch 46: finishing mini batch 54, training error = 0.015625, loss = 0.09533016383647919\n","Epoch 46: finishing mini batch 55, training error = 0.0, loss = 0.03646893426775932\n","Epoch 46: finishing mini batch 56, training error = 0.0625, loss = 0.14412109553813934\n","Epoch 46: finishing mini batch 57, training error = 0.046875, loss = 0.09869686514139175\n","Epoch 46: finishing mini batch 58, training error = 0.015625, loss = 0.10261087864637375\n","Epoch 46: finishing mini batch 59, training error = 0.09375, loss = 0.18854963779449463\n","Epoch 46: finishing mini batch 60, training error = 0.046875, loss = 0.1305581033229828\n","Epoch 46: finishing mini batch 61, training error = 0.03125, loss = 0.08991627395153046\n","Epoch 46: finishing mini batch 62, training error = 0.03125, loss = 0.07888125628232956\n","Epoch 46: finishing mini batch 63, training error = 0.046875, loss = 0.11077713966369629\n","Epoch 46: finishing mini batch 64, training error = 0.046875, loss = 0.08064388483762741\n","Epoch 46: finishing mini batch 65, training error = 0.046875, loss = 0.07332269847393036\n","Epoch 46: finishing mini batch 66, training error = 0.03125, loss = 0.10879974067211151\n","Epoch 46: finishing mini batch 67, training error = 0.03125, loss = 0.10963843017816544\n","Epoch 46: finishing mini batch 68, training error = 0.046875, loss = 0.08381354063749313\n","Epoch 46: finishing mini batch 69, training error = 0.0625, loss = 0.12149714678525925\n","Epoch 46: finishing mini batch 70, training error = 0.015625, loss = 0.047365035861730576\n","Epoch 46: finishing mini batch 71, training error = 0.109375, loss = 0.2500840723514557\n","Epoch 46: finishing mini batch 72, training error = 0.09375, loss = 0.16388313472270966\n","Epoch 46: finishing mini batch 73, training error = 0.046875, loss = 0.10687004029750824\n","Epoch 46: finishing mini batch 74, training error = 0.03125, loss = 0.06096421182155609\n","Epoch 46: finishing mini batch 75, training error = 0.015625, loss = 0.0458236001431942\n","Epoch 46: finishing mini batch 76, training error = 0.0625, loss = 0.13571880757808685\n","Epoch 46: finishing mini batch 77, training error = 0.03125, loss = 0.09468211233615875\n","Epoch 46: finishing mini batch 78, training error = 0.03125, loss = 0.0526164248585701\n","Epoch 46: finishing mini batch 79, training error = 0.03125, loss = 0.12964612245559692\n","Epoch 46: finishing mini batch 80, training error = 0.09375, loss = 0.18410469591617584\n","Epoch 46: finishing mini batch 81, training error = 0.015625, loss = 0.0487590953707695\n","Epoch 46: finishing mini batch 82, training error = 0.0625, loss = 0.12494613975286484\n","Epoch 46: finishing mini batch 83, training error = 0.078125, loss = 0.17845509946346283\n","Epoch 46: finishing mini batch 84, training error = 0.03125, loss = 0.10653989762067795\n","Epoch 46: finishing mini batch 85, training error = 0.03125, loss = 0.10287903249263763\n","Epoch 46: finishing mini batch 86, training error = 0.046875, loss = 0.0943986177444458\n","Epoch 46: finishing mini batch 87, training error = 0.03125, loss = 0.10451154410839081\n","Epoch 46: finishing mini batch 88, training error = 0.0625, loss = 0.11366280168294907\n","Epoch 46: finishing mini batch 89, training error = 0.015625, loss = 0.12190228700637817\n","Epoch 46: finishing mini batch 90, training error = 0.03125, loss = 0.12391381710767746\n","Epoch 46: finishing mini batch 91, training error = 0.0, loss = 0.03984096273779869\n","Epoch 46: finishing mini batch 92, training error = 0.015625, loss = 0.048001229763031006\n","Epoch 46: finishing mini batch 93, training error = 0.03125, loss = 0.11465419083833694\n","Epoch 46: finishing mini batch 94, training error = 0.03125, loss = 0.08466575294733047\n","Epoch 46: finishing mini batch 95, training error = 0.0625, loss = 0.1389206200838089\n","Epoch 46: finishing mini batch 96, training error = 0.015625, loss = 0.06546823680400848\n","Epoch 46: finishing mini batch 97, training error = 0.078125, loss = 0.1329820156097412\n","Epoch 46: finishing mini batch 98, training error = 0.015625, loss = 0.0831688791513443\n","Epoch 46: finishing mini batch 99, training error = 0.046875, loss = 0.09591906517744064\n","Epoch 46: finishing mini batch 100, training error = 0.046875, loss = 0.08588425815105438\n","Epoch 46: finishing mini batch 101, training error = 0.015625, loss = 0.03167806193232536\n","Epoch 46: finishing mini batch 102, training error = 0.03125, loss = 0.10256151109933853\n","Epoch 46: finishing mini batch 103, training error = 0.078125, loss = 0.1255517154932022\n","Epoch 46: finishing mini batch 104, training error = 0.015625, loss = 0.05357050150632858\n","Epoch 46: finishing mini batch 105, training error = 0.03125, loss = 0.06575196236371994\n","Epoch 46: finishing mini batch 106, training error = 0.109375, loss = 0.1792784333229065\n","Epoch 46: finishing mini batch 107, training error = 0.03125, loss = 0.08548470586538315\n","Epoch 46: finishing mini batch 108, training error = 0.0625, loss = 0.11998210102319717\n","Epoch 46: finishing mini batch 109, training error = 0.0625, loss = 0.25080496072769165\n","Epoch 46: finishing mini batch 110, training error = 0.09375, loss = 0.3497350215911865\n","Epoch 46: finishing mini batch 111, training error = 0.015625, loss = 0.05452865734696388\n","Epoch 46: finishing mini batch 112, training error = 0.046875, loss = 0.09207199513912201\n","Epoch 46: finishing mini batch 113, training error = 0.078125, loss = 0.18720372021198273\n","Epoch 46: finishing mini batch 114, training error = 0.015625, loss = 0.05403931066393852\n","Epoch 46: finishing mini batch 115, training error = 0.0, loss = 0.05928767845034599\n","Epoch 46: finishing mini batch 116, training error = 0.015625, loss = 0.0891442745923996\n","Epoch 46: finishing mini batch 117, training error = 0.015625, loss = 0.04105944558978081\n","Epoch 46: finishing mini batch 118, training error = 0.046875, loss = 0.1535915732383728\n","Epoch 46: finishing mini batch 119, training error = 0.03125, loss = 0.133487269282341\n","Epoch 46: finishing mini batch 120, training error = 0.03125, loss = 0.1105901449918747\n","Epoch 46: finishing mini batch 121, training error = 0.046875, loss = 0.09378816932439804\n","Epoch 46: finishing mini batch 122, training error = 0.03125, loss = 0.09561937302350998\n","Epoch 46: finishing mini batch 123, training error = 0.015625, loss = 0.10550234466791153\n","Epoch 46: finishing mini batch 124, training error = 0.046875, loss = 0.15141692757606506\n","Epoch 46: finishing mini batch 125, training error = 0.0, loss = 0.07451485842466354\n","Epoch 46: finishing mini batch 126, training error = 0.03125, loss = 0.0997113585472107\n","Epoch 46: finishing mini batch 127, training error = 0.015625, loss = 0.05198962986469269\n","Epoch 46: finishing mini batch 128, training error = 0.0625, loss = 0.16607610881328583\n","Epoch 46: finishing mini batch 129, training error = 0.015625, loss = 0.10706686973571777\n","Epoch 46: finishing mini batch 130, training error = 0.0625, loss = 0.10018464922904968\n","Epoch 46: finishing mini batch 131, training error = 0.03125, loss = 0.12963874638080597\n","Epoch 46: finishing mini batch 132, training error = 0.015625, loss = 0.038591478019952774\n","Epoch 46: finishing mini batch 133, training error = 0.046875, loss = 0.08297755569219589\n","Epoch 46: finishing mini batch 134, training error = 0.015625, loss = 0.08128203451633453\n","Epoch 46: finishing mini batch 135, training error = 0.09375, loss = 0.2012922763824463\n","Epoch 46: finishing mini batch 136, training error = 0.03125, loss = 0.09076425433158875\n","Epoch 46: finishing mini batch 137, training error = 0.078125, loss = 0.20244601368904114\n","Epoch 46: finishing mini batch 138, training error = 0.046875, loss = 0.08244428038597107\n","Epoch 46: finishing mini batch 139, training error = 0.0625, loss = 0.11857929080724716\n","Epoch 46: finishing mini batch 140, training error = 0.078125, loss = 0.14089703559875488\n","Epoch 46: finishing mini batch 141, training error = 0.03125, loss = 0.1478595733642578\n","Epoch 46: finishing mini batch 142, training error = 0.046875, loss = 0.17308354377746582\n","Epoch 46: finishing mini batch 143, training error = 0.03125, loss = 0.04680686071515083\n","Epoch 46: finishing mini batch 144, training error = 0.015625, loss = 0.03654349595308304\n","Epoch 46: finishing mini batch 145, training error = 0.078125, loss = 0.19270963966846466\n","Epoch 46: finishing mini batch 146, training error = 0.0, loss = 0.029928212985396385\n","Epoch 46: finishing mini batch 147, training error = 0.0, loss = 0.04165494441986084\n","Epoch 46: finishing mini batch 148, training error = 0.015625, loss = 0.08883166313171387\n","Epoch 46: finishing mini batch 149, training error = 0.046875, loss = 0.10196495056152344\n","Epoch 46: finishing mini batch 150, training error = 0.03125, loss = 0.14146688580513\n","Epoch 46: finishing mini batch 151, training error = 0.046875, loss = 0.1101190447807312\n","Epoch 46: finishing mini batch 152, training error = 0.015625, loss = 0.1031671017408371\n","Epoch 46: finishing mini batch 153, training error = 0.09375, loss = 0.27485793828964233\n","Epoch 46: finishing mini batch 154, training error = 0.078125, loss = 0.172461599111557\n","Epoch 46: finishing mini batch 155, training error = 0.0625, loss = 0.07631152868270874\n","Epoch 46: finishing mini batch 156, training error = 0.03125, loss = 0.06659309566020966\n","Epoch 46: finishing mini batch 157, training error = 0.03125, loss = 0.08035977929830551\n","Epoch 46: finishing mini batch 158, training error = 0.0625, loss = 0.09949617087841034\n","Epoch 46: finishing mini batch 159, training error = 0.0625, loss = 0.12379871308803558\n","Epoch 46: finishing mini batch 160, training error = 0.0625, loss = 0.1493801325559616\n","Epoch 46: finishing mini batch 161, training error = 0.015625, loss = 0.09900218993425369\n","Epoch 46: finishing mini batch 162, training error = 0.046875, loss = 0.08267508447170258\n","Epoch 46: finishing mini batch 163, training error = 0.015625, loss = 0.11022797971963882\n","Epoch 46: finishing mini batch 164, training error = 0.078125, loss = 0.10598444193601608\n","Epoch 46: finishing mini batch 165, training error = 0.09375, loss = 0.17089754343032837\n","Epoch 46: finishing mini batch 166, training error = 0.015625, loss = 0.060432445257902145\n","Epoch 46: finishing mini batch 167, training error = 0.0, loss = 0.019747097045183182\n","Epoch 46: finishing mini batch 168, training error = 0.046875, loss = 0.1283700168132782\n","Epoch 46: finishing mini batch 169, training error = 0.0, loss = 0.03233645483851433\n","Epoch 46: finishing mini batch 170, training error = 0.046875, loss = 0.1504056453704834\n","Epoch 46: finishing mini batch 171, training error = 0.0, loss = 0.02980756014585495\n","Epoch 46: finishing mini batch 172, training error = 0.03125, loss = 0.10257119685411453\n","Epoch 46: finishing mini batch 173, training error = 0.03125, loss = 0.14016568660736084\n","Epoch 46: finishing mini batch 174, training error = 0.0625, loss = 0.1707908660173416\n","Epoch 46: finishing mini batch 175, training error = 0.0625, loss = 0.14155679941177368\n","Epoch 46: finishing mini batch 176, training error = 0.015625, loss = 0.04921341314911842\n","Epoch 46: finishing mini batch 177, training error = 0.0625, loss = 0.12714128196239471\n","Epoch 46: finishing mini batch 178, training error = 0.015625, loss = 0.10046002268791199\n","Epoch 46: finishing mini batch 179, training error = 0.03125, loss = 0.07059453427791595\n","Epoch 46: finishing mini batch 180, training error = 0.0, loss = 0.044003527611494064\n","Epoch 46: finishing mini batch 181, training error = 0.015625, loss = 0.056598976254463196\n","Epoch 46: finishing mini batch 182, training error = 0.0, loss = 0.04813723638653755\n","Epoch 46: finishing mini batch 183, training error = 0.03125, loss = 0.05974242836236954\n","Epoch 46: finishing mini batch 184, training error = 0.0625, loss = 0.15556423366069794\n","Epoch 46: finishing mini batch 185, training error = 0.03125, loss = 0.0962921753525734\n","Epoch 46: finishing mini batch 186, training error = 0.015625, loss = 0.10207222402095795\n","Epoch 46: finishing mini batch 187, training error = 0.015625, loss = 0.07686179876327515\n","Epoch 46: finishing mini batch 188, training error = 0.0, loss = 0.04722899571061134\n","Epoch 46: finishing mini batch 189, training error = 0.046875, loss = 0.1540667861700058\n","Epoch 46: finishing mini batch 190, training error = 0.078125, loss = 0.22975152730941772\n","Epoch 46: finishing mini batch 191, training error = 0.0, loss = 0.06375670433044434\n","Epoch 46: finishing mini batch 192, training error = 0.046875, loss = 0.13236331939697266\n","Epoch 46: finishing mini batch 193, training error = 0.0, loss = 0.04384763166308403\n","Epoch 46: finishing mini batch 194, training error = 0.03125, loss = 0.11567070335149765\n","Epoch 46: finishing mini batch 195, training error = 0.015625, loss = 0.0322989895939827\n","Epoch 46: finishing mini batch 196, training error = 0.03125, loss = 0.05821288749575615\n","Epoch 46: finishing mini batch 197, training error = 0.015625, loss = 0.04300451651215553\n","Epoch 46: finishing mini batch 198, training error = 0.03125, loss = 0.0783916786313057\n","Epoch 46: finishing mini batch 199, training error = 0.03125, loss = 0.06612424552440643\n","Epoch 46: finishing mini batch 200, training error = 0.015625, loss = 0.0905282199382782\n","Epoch 46: finishing mini batch 201, training error = 0.0, loss = 0.03113086149096489\n","Epoch 46: finishing mini batch 202, training error = 0.0625, loss = 0.12015505880117416\n","Epoch 46: finishing mini batch 203, training error = 0.015625, loss = 0.05876704305410385\n","Epoch 46: finishing mini batch 204, training error = 0.0, loss = 0.03536340221762657\n","Epoch 46: finishing mini batch 205, training error = 0.0, loss = 0.02862045168876648\n","Epoch 46: finishing mini batch 206, training error = 0.046875, loss = 0.0685027614235878\n","Epoch 46: finishing mini batch 207, training error = 0.015625, loss = 0.058428842574357986\n","Epoch 46: finishing mini batch 208, training error = 0.03125, loss = 0.10903710126876831\n","Epoch 46: finishing mini batch 209, training error = 0.03125, loss = 0.09804754704236984\n","Epoch 46: finishing mini batch 210, training error = 0.015625, loss = 0.054021358489990234\n","Epoch 46: finishing mini batch 211, training error = 0.015625, loss = 0.09275121241807938\n","Epoch 46: finishing mini batch 212, training error = 0.0, loss = 0.04072177782654762\n","Epoch 46: finishing mini batch 213, training error = 0.03125, loss = 0.10172208398580551\n","Epoch 46: finishing mini batch 214, training error = 0.03125, loss = 0.07750751823186874\n","Epoch 46: finishing mini batch 215, training error = 0.0, loss = 0.04987969994544983\n","Epoch 46: finishing mini batch 216, training error = 0.015625, loss = 0.06529916822910309\n","Epoch 46: finishing mini batch 217, training error = 0.015625, loss = 0.052243687212467194\n","Epoch 46: finishing mini batch 218, training error = 0.0, loss = 0.03409331291913986\n","Epoch 46: finishing mini batch 219, training error = 0.046875, loss = 0.0933360680937767\n","Epoch 46: finishing mini batch 220, training error = 0.03125, loss = 0.04609281197190285\n","Epoch 46: finishing mini batch 221, training error = 0.03125, loss = 0.0751577690243721\n","Epoch 46: finishing mini batch 222, training error = 0.015625, loss = 0.06698716431856155\n","Epoch 46: finishing mini batch 223, training error = 0.046875, loss = 0.10275968164205551\n","Epoch 46: finishing mini batch 224, training error = 0.046875, loss = 0.08921567350625992\n","Epoch 46: finishing mini batch 225, training error = 0.046875, loss = 0.14362750947475433\n","Epoch 46: finishing mini batch 226, training error = 0.046875, loss = 0.10267132520675659\n","Epoch 46: finishing mini batch 227, training error = 0.015625, loss = 0.04548206925392151\n","Epoch 46: finishing mini batch 228, training error = 0.03125, loss = 0.08626110851764679\n","Epoch 46: finishing mini batch 229, training error = 0.0, loss = 0.04693873971700668\n","Epoch 46: finishing mini batch 230, training error = 0.015625, loss = 0.07339455932378769\n","Epoch 46: finishing mini batch 231, training error = 0.03125, loss = 0.09576961398124695\n","Epoch 46: finishing mini batch 232, training error = 0.046875, loss = 0.10749505460262299\n","Epoch 46: finishing mini batch 233, training error = 0.0625, loss = 0.13062091171741486\n","Epoch 46: finishing mini batch 234, training error = 0.046875, loss = 0.09582817554473877\n","Epoch 46: finishing mini batch 235, training error = 0.0, loss = 0.070969358086586\n","Epoch 46: finishing mini batch 236, training error = 0.03125, loss = 0.09395190328359604\n","Epoch 46: finishing mini batch 237, training error = 0.015625, loss = 0.05118140950798988\n","Epoch 46: finishing mini batch 238, training error = 0.078125, loss = 0.21205103397369385\n","Epoch 46: finishing mini batch 239, training error = 0.078125, loss = 0.15820057690143585\n","Epoch 46: finishing mini batch 240, training error = 0.015625, loss = 0.08667004108428955\n","Epoch 46: finishing mini batch 241, training error = 0.03125, loss = 0.06631629914045334\n","Epoch 46: finishing mini batch 242, training error = 0.015625, loss = 0.1112816110253334\n","Epoch 46: finishing mini batch 243, training error = 0.046875, loss = 0.06641144305467606\n","Epoch 46: finishing mini batch 244, training error = 0.03125, loss = 0.08215391635894775\n","Epoch 46: finishing mini batch 245, training error = 0.046875, loss = 0.1228627860546112\n","Epoch 46: finishing mini batch 246, training error = 0.015625, loss = 0.12467031180858612\n","Epoch 46: finishing mini batch 247, training error = 0.046875, loss = 0.1340174376964569\n","Epoch 46: finishing mini batch 248, training error = 0.046875, loss = 0.1708579808473587\n","Epoch 46: finishing mini batch 249, training error = 0.015625, loss = 0.04895728453993797\n","Epoch 46: finishing mini batch 250, training error = 0.03125, loss = 0.10254944860935211\n","Epoch 46: finishing mini batch 251, training error = 0.046875, loss = 0.1333666890859604\n","Epoch 46: finishing mini batch 252, training error = 0.03125, loss = 0.08790745586156845\n","Epoch 46: finishing mini batch 253, training error = 0.078125, loss = 0.15564565360546112\n","Epoch 46: finishing mini batch 254, training error = 0.03125, loss = 0.13480092585086823\n","Epoch 46: finishing mini batch 255, training error = 0.046875, loss = 0.13281115889549255\n","Epoch 46: finishing mini batch 256, training error = 0.03125, loss = 0.12658007442951202\n","Epoch 46: finishing mini batch 257, training error = 0.0, loss = 0.029529079794883728\n","Epoch 46: finishing mini batch 258, training error = 0.0625, loss = 0.20579195022583008\n","Epoch 46: finishing mini batch 259, training error = 0.046875, loss = 0.09537818282842636\n","Epoch 46: finishing mini batch 260, training error = 0.03125, loss = 0.058228712528944016\n","Epoch 46: finishing mini batch 261, training error = 0.03125, loss = 0.2007075995206833\n","Epoch 46: finishing mini batch 262, training error = 0.015625, loss = 0.09055877476930618\n","Epoch 46: finishing mini batch 263, training error = 0.0625, loss = 0.2356487214565277\n","Epoch 46: finishing mini batch 264, training error = 0.0625, loss = 0.13401097059249878\n","Epoch 46: finishing mini batch 265, training error = 0.03125, loss = 0.09179253876209259\n","Epoch 46: finishing mini batch 266, training error = 0.03125, loss = 0.06818383187055588\n","Epoch 46: finishing mini batch 267, training error = 0.015625, loss = 0.07791242748498917\n","Epoch 46: finishing mini batch 268, training error = 0.015625, loss = 0.03886152058839798\n","Epoch 46: finishing mini batch 269, training error = 0.046875, loss = 0.06765434145927429\n","Epoch 46: finishing mini batch 270, training error = 0.015625, loss = 0.051211703568696976\n","Epoch 46: finishing mini batch 271, training error = 0.0625, loss = 0.12267395108938217\n","Epoch 46: finishing mini batch 272, training error = 0.046875, loss = 0.09864784777164459\n","Epoch 46: finishing mini batch 273, training error = 0.078125, loss = 0.2379584014415741\n","Epoch 46: finishing mini batch 274, training error = 0.015625, loss = 0.11149419844150543\n","Epoch 46: finishing mini batch 275, training error = 0.03125, loss = 0.06929146498441696\n","Epoch 46: finishing mini batch 276, training error = 0.046875, loss = 0.11286357045173645\n","Epoch 46: finishing mini batch 277, training error = 0.0, loss = 0.031458571553230286\n","Epoch 46: finishing mini batch 278, training error = 0.03125, loss = 0.07159821689128876\n","Epoch 46: finishing mini batch 279, training error = 0.015625, loss = 0.07010827213525772\n","Epoch 46: finishing mini batch 280, training error = 0.015625, loss = 0.05676715075969696\n","Epoch 46: finishing mini batch 281, training error = 0.03125, loss = 0.06934574991464615\n","Epoch 46: finishing mini batch 282, training error = 0.078125, loss = 0.13094668090343475\n","Epoch 46: finishing mini batch 283, training error = 0.0625, loss = 0.1737433522939682\n","Epoch 46: finishing mini batch 284, training error = 0.0, loss = 0.02411753125488758\n","Epoch 46: finishing mini batch 285, training error = 0.0625, loss = 0.10966166853904724\n","Epoch 46: finishing mini batch 286, training error = 0.0, loss = 0.024329930543899536\n","Epoch 46: finishing mini batch 287, training error = 0.03125, loss = 0.14033162593841553\n","Epoch 46: finishing mini batch 288, training error = 0.03125, loss = 0.10420780628919601\n","Epoch 46: finishing mini batch 289, training error = 0.0, loss = 0.0672634020447731\n","Epoch 46: finishing mini batch 290, training error = 0.015625, loss = 0.03488529473543167\n","Epoch 46: finishing mini batch 291, training error = 0.09375, loss = 0.1800673007965088\n","Epoch 46: finishing mini batch 292, training error = 0.046875, loss = 0.17274212837219238\n","Epoch 46: finishing mini batch 293, training error = 0.03125, loss = 0.13381347060203552\n","Epoch 46: finishing mini batch 294, training error = 0.015625, loss = 0.08529096841812134\n","Epoch 46: finishing mini batch 295, training error = 0.03125, loss = 0.10270174592733383\n","Epoch 46: finishing mini batch 296, training error = 0.078125, loss = 0.18433773517608643\n","Epoch 46: finishing mini batch 297, training error = 0.0625, loss = 0.12157993018627167\n","Epoch 46: finishing mini batch 298, training error = 0.0, loss = 0.04629268869757652\n","Epoch 46: finishing mini batch 299, training error = 0.03125, loss = 0.08794170618057251\n","Epoch 46: finishing mini batch 300, training error = 0.0, loss = 0.023027099668979645\n","Epoch 46: finishing mini batch 301, training error = 0.015625, loss = 0.09435225278139114\n","Epoch 46: finishing mini batch 302, training error = 0.015625, loss = 0.04912630096077919\n","Epoch 46: finishing mini batch 303, training error = 0.03125, loss = 0.08374413102865219\n","Epoch 46: finishing mini batch 304, training error = 0.078125, loss = 0.24886013567447662\n","Epoch 46: finishing mini batch 305, training error = 0.0625, loss = 0.10773713886737823\n","Epoch 46: finishing mini batch 306, training error = 0.046875, loss = 0.10046782344579697\n","Epoch 46: finishing mini batch 307, training error = 0.03125, loss = 0.11665913462638855\n","Epoch 46: finishing mini batch 308, training error = 0.0, loss = 0.04121028259396553\n","Epoch 46: finishing mini batch 309, training error = 0.03125, loss = 0.0707470178604126\n","Epoch 46: finishing mini batch 310, training error = 0.03125, loss = 0.05617896467447281\n","Epoch 46: finishing mini batch 311, training error = 0.046875, loss = 0.11748048663139343\n","Epoch 46: finishing mini batch 312, training error = 0.03125, loss = 0.11049830913543701\n","Epoch 46: finishing mini batch 313, training error = 0.046875, loss = 0.07463734596967697\n","Epoch 46: finishing mini batch 314, training error = 0.0625, loss = 0.171236053109169\n","Epoch 46: finishing mini batch 315, training error = 0.078125, loss = 0.1730954647064209\n","Epoch 46: finishing mini batch 316, training error = 0.03125, loss = 0.11206180602312088\n","Epoch 46: finishing mini batch 317, training error = 0.03125, loss = 0.08671670407056808\n","Epoch 46: finishing mini batch 318, training error = 0.046875, loss = 0.13995769619941711\n","Epoch 46: finishing mini batch 319, training error = 0.0, loss = 0.04086041450500488\n","Epoch 46: finishing mini batch 320, training error = 0.03125, loss = 0.12638111412525177\n","Epoch 46: finishing mini batch 321, training error = 0.03125, loss = 0.07487522065639496\n","Epoch 46: finishing mini batch 322, training error = 0.03125, loss = 0.08538202941417694\n","Epoch 46: finishing mini batch 323, training error = 0.0625, loss = 0.17074239253997803\n","Epoch 46: finishing mini batch 324, training error = 0.078125, loss = 0.20991839468479156\n","Epoch 46: finishing mini batch 325, training error = 0.09375, loss = 0.18982034921646118\n","Epoch 46: finishing mini batch 326, training error = 0.03125, loss = 0.06771756708621979\n","Epoch 46: finishing mini batch 327, training error = 0.0625, loss = 0.16103097796440125\n","Epoch 46: finishing mini batch 328, training error = 0.046875, loss = 0.15325680375099182\n","Epoch 46: finishing mini batch 329, training error = 0.0, loss = 0.051407214254140854\n","Epoch 46: finishing mini batch 330, training error = 0.078125, loss = 0.1723579317331314\n","Epoch 46: finishing mini batch 331, training error = 0.03125, loss = 0.06157384067773819\n","Epoch 46: finishing mini batch 332, training error = 0.046875, loss = 0.1145126223564148\n","Epoch 46: finishing mini batch 333, training error = 0.03125, loss = 0.10777883231639862\n","Epoch 46: finishing mini batch 334, training error = 0.015625, loss = 0.04735589772462845\n","Epoch 46: finishing mini batch 335, training error = 0.0625, loss = 0.14951251447200775\n","Epoch 46: finishing mini batch 336, training error = 0.078125, loss = 0.31676551699638367\n","Epoch 46: finishing mini batch 337, training error = 0.046875, loss = 0.12875740230083466\n","Epoch 46: finishing mini batch 338, training error = 0.03125, loss = 0.04245017096400261\n","Epoch 46: finishing mini batch 339, training error = 0.078125, loss = 0.3032938241958618\n","Epoch 46: finishing mini batch 340, training error = 0.09375, loss = 0.18863099813461304\n","Epoch 46: finishing mini batch 341, training error = 0.0, loss = 0.04523599520325661\n","Epoch 46: finishing mini batch 342, training error = 0.0, loss = 0.04389815405011177\n","Epoch 46: finishing mini batch 343, training error = 0.0625, loss = 0.153817281126976\n","Epoch 46: finishing mini batch 344, training error = 0.0625, loss = 0.13717018067836761\n","Epoch 46: finishing mini batch 345, training error = 0.09375, loss = 0.3603644073009491\n","Epoch 46: finishing mini batch 346, training error = 0.078125, loss = 0.22951555252075195\n","Epoch 46: finishing mini batch 347, training error = 0.03125, loss = 0.08467377722263336\n","Epoch 46: finishing mini batch 348, training error = 0.046875, loss = 0.13623836636543274\n","Epoch 46: finishing mini batch 349, training error = 0.078125, loss = 0.22174590826034546\n","Epoch 46: finishing mini batch 350, training error = 0.015625, loss = 0.06241098418831825\n","Epoch 46: finishing mini batch 351, training error = 0.046875, loss = 0.13252677023410797\n","Epoch 46: finishing mini batch 352, training error = 0.046875, loss = 0.10380915552377701\n","Epoch 46: finishing mini batch 353, training error = 0.0625, loss = 0.13081978261470795\n","Epoch 46: finishing mini batch 354, training error = 0.03125, loss = 0.08899195492267609\n","Epoch 46: finishing mini batch 355, training error = 0.078125, loss = 0.32794108986854553\n","Epoch 46: finishing mini batch 356, training error = 0.046875, loss = 0.16261260211467743\n","Epoch 46: finishing mini batch 357, training error = 0.078125, loss = 0.16938000917434692\n","Epoch 46: finishing mini batch 358, training error = 0.015625, loss = 0.06261328607797623\n","Epoch 46: finishing mini batch 359, training error = 0.03125, loss = 0.07649114727973938\n","Epoch 46: finishing mini batch 360, training error = 0.03125, loss = 0.11821161955595016\n","Epoch 46: finishing mini batch 361, training error = 0.0625, loss = 0.1363913118839264\n","Epoch 46: finishing mini batch 362, training error = 0.0, loss = 0.031044872477650642\n","Epoch 46: finishing mini batch 363, training error = 0.03125, loss = 0.08310195058584213\n","Epoch 46: finishing mini batch 364, training error = 0.0625, loss = 0.1232857033610344\n","Epoch 46: finishing mini batch 365, training error = 0.015625, loss = 0.08111369609832764\n","Epoch 46: finishing mini batch 366, training error = 0.03125, loss = 0.06019875779747963\n","Epoch 46: finishing mini batch 367, training error = 0.03125, loss = 0.10415039956569672\n","Epoch 46: finishing mini batch 368, training error = 0.0625, loss = 0.19902731478214264\n","Epoch 46: finishing mini batch 369, training error = 0.046875, loss = 0.11872493475675583\n","Epoch 46: finishing mini batch 370, training error = 0.015625, loss = 0.054105427116155624\n","Epoch 46: finishing mini batch 371, training error = 0.03125, loss = 0.1089419350028038\n","Epoch 46: finishing mini batch 372, training error = 0.046875, loss = 0.12888237833976746\n","Epoch 46: finishing mini batch 373, training error = 0.046875, loss = 0.1481485664844513\n","Epoch 46: finishing mini batch 374, training error = 0.03125, loss = 0.08082214742898941\n","Epoch 46: finishing mini batch 375, training error = 0.015625, loss = 0.05767985060811043\n","Epoch 46: finishing mini batch 376, training error = 0.03125, loss = 0.06211115047335625\n","Epoch 46: finishing mini batch 377, training error = 0.03125, loss = 0.11141940951347351\n","Epoch 46: finishing mini batch 378, training error = 0.046875, loss = 0.11229518055915833\n","Epoch 46: finishing mini batch 379, training error = 0.015625, loss = 0.053104184567928314\n","Epoch 46: finishing mini batch 380, training error = 0.0625, loss = 0.14820806682109833\n","Epoch 46: finishing mini batch 381, training error = 0.078125, loss = 0.12590403854846954\n","Epoch 46: finishing mini batch 382, training error = 0.03125, loss = 0.12478824704885483\n","Epoch 46: finishing mini batch 383, training error = 0.046875, loss = 0.12002084404230118\n","Epoch 46: finishing mini batch 384, training error = 0.03125, loss = 0.06976000219583511\n","Epoch 46: finishing mini batch 385, training error = 0.0625, loss = 0.1251135617494583\n","Epoch 46: finishing mini batch 386, training error = 0.046875, loss = 0.09943777322769165\n","Epoch 46: finishing mini batch 387, training error = 0.046875, loss = 0.10470473021268845\n","Epoch 46: finishing mini batch 388, training error = 0.0, loss = 0.0824134573340416\n","Epoch 46: finishing mini batch 389, training error = 0.0625, loss = 0.17466121912002563\n","Epoch 46: finishing mini batch 390, training error = 0.0625, loss = 0.1887221783399582\n","Epoch 46: finishing mini batch 391, training error = 0.078125, loss = 0.2740003764629364\n","Epoch 46: finishing mini batch 392, training error = 0.0625, loss = 0.13973425328731537\n","Epoch 46: finishing mini batch 393, training error = 0.0625, loss = 0.1334036886692047\n","Epoch 46: finishing mini batch 394, training error = 0.0625, loss = 0.1600823849439621\n","Epoch 46: finishing mini batch 395, training error = 0.0, loss = 0.03319679945707321\n","Epoch 46: finishing mini batch 396, training error = 0.015625, loss = 0.05345400795340538\n","Epoch 46: finishing mini batch 397, training error = 0.0625, loss = 0.1398952603340149\n","Epoch 46: finishing mini batch 398, training error = 0.015625, loss = 0.04427182301878929\n","Epoch 46: finishing mini batch 399, training error = 0.078125, loss = 0.13781365752220154\n","Epoch 46: finishing mini batch 400, training error = 0.0, loss = 0.03652148321270943\n","Epoch 46: finishing mini batch 401, training error = 0.046875, loss = 0.18483321368694305\n","Epoch 46: finishing mini batch 402, training error = 0.046875, loss = 0.11835877597332001\n","Epoch 46: finishing mini batch 403, training error = 0.015625, loss = 0.08279933035373688\n","Epoch 46: finishing mini batch 404, training error = 0.046875, loss = 0.10463736206293106\n","Epoch 46: finishing mini batch 405, training error = 0.046875, loss = 0.12173806130886078\n","Epoch 46: finishing mini batch 406, training error = 0.0, loss = 0.03500763326883316\n","Epoch 46: finishing mini batch 407, training error = 0.03125, loss = 0.06568676978349686\n","Epoch 46: finishing mini batch 408, training error = 0.03125, loss = 0.07636625319719315\n","Epoch 46: finishing mini batch 409, training error = 0.0625, loss = 0.1253303587436676\n","Epoch 46: finishing mini batch 410, training error = 0.015625, loss = 0.07296322286128998\n","Epoch 46: finishing mini batch 411, training error = 0.046875, loss = 0.08260571211576462\n","Epoch 46: finishing mini batch 412, training error = 0.0, loss = 0.029678761959075928\n","Epoch 46: finishing mini batch 413, training error = 0.03125, loss = 0.06344535201787949\n","Epoch 46: finishing mini batch 414, training error = 0.015625, loss = 0.10611648857593536\n","Epoch 46: finishing mini batch 415, training error = 0.0625, loss = 0.13228289783000946\n","Epoch 46: finishing mini batch 416, training error = 0.046875, loss = 0.11915624141693115\n","Epoch 46: finishing mini batch 417, training error = 0.0625, loss = 0.14817070960998535\n","Epoch 46: finishing mini batch 418, training error = 0.078125, loss = 0.1765362024307251\n","Epoch 46: finishing mini batch 419, training error = 0.0, loss = 0.04856443032622337\n","Epoch 46: finishing mini batch 420, training error = 0.0, loss = 0.030963987112045288\n","Epoch 46: finishing mini batch 421, training error = 0.03125, loss = 0.09525983035564423\n","Epoch 46: finishing mini batch 422, training error = 0.015625, loss = 0.029630353674292564\n","Epoch 46: finishing mini batch 423, training error = 0.015625, loss = 0.06625338643789291\n","Epoch 46: finishing mini batch 424, training error = 0.078125, loss = 0.2154366672039032\n","Epoch 46: finishing mini batch 425, training error = 0.0625, loss = 0.2032921463251114\n","Epoch 46: finishing mini batch 426, training error = 0.015625, loss = 0.09694462269544601\n","Epoch 46: finishing mini batch 427, training error = 0.046875, loss = 0.1486990600824356\n","Epoch 46: finishing mini batch 428, training error = 0.109375, loss = 0.19531109929084778\n","Epoch 46: finishing mini batch 429, training error = 0.015625, loss = 0.051845259964466095\n","Epoch 46: finishing mini batch 430, training error = 0.03125, loss = 0.15564128756523132\n","Epoch 46: finishing mini batch 431, training error = 0.015625, loss = 0.050540633499622345\n","Epoch 46: finishing mini batch 432, training error = 0.015625, loss = 0.050293438136577606\n","Epoch 46: finishing mini batch 433, training error = 0.0625, loss = 0.2247449904680252\n","Epoch 46: finishing mini batch 434, training error = 0.0625, loss = 0.14770960807800293\n","Epoch 46: finishing mini batch 435, training error = 0.0625, loss = 0.11532001942396164\n","Epoch 46: finishing mini batch 436, training error = 0.03125, loss = 0.10375169664621353\n","Epoch 46: finishing mini batch 437, training error = 0.046875, loss = 0.14338047802448273\n","Epoch 46: finishing mini batch 438, training error = 0.046875, loss = 0.13977478444576263\n","Epoch 46: finishing mini batch 439, training error = 0.078125, loss = 0.2877325117588043\n","Epoch 46: finishing mini batch 440, training error = 0.046875, loss = 0.16848568618297577\n","Epoch 46: finishing mini batch 441, training error = 0.0625, loss = 0.13318666815757751\n","Epoch 46: finishing mini batch 442, training error = 0.046875, loss = 0.21999934315681458\n","Epoch 46: finishing mini batch 443, training error = 0.03125, loss = 0.09108393639326096\n","Epoch 46: finishing mini batch 444, training error = 0.0, loss = 0.021142687648534775\n","Epoch 46: finishing mini batch 445, training error = 0.0625, loss = 0.12306097894906998\n","Epoch 46: finishing mini batch 446, training error = 0.015625, loss = 0.04822133481502533\n","Epoch 46: finishing mini batch 447, training error = 0.046875, loss = 0.10738229006528854\n","Epoch 46: finishing mini batch 448, training error = 0.078125, loss = 0.15720582008361816\n","Epoch 46: finishing mini batch 449, training error = 0.046875, loss = 0.09983992576599121\n","Epoch 46: finishing mini batch 450, training error = 0.0, loss = 0.057021692395210266\n","Epoch 46: finishing mini batch 451, training error = 0.046875, loss = 0.1242818608880043\n","Epoch 46: finishing mini batch 452, training error = 0.0625, loss = 0.21587714552879333\n","Epoch 46: finishing mini batch 453, training error = 0.09375, loss = 0.160273939371109\n","Epoch 46: finishing mini batch 454, training error = 0.046875, loss = 0.13553451001644135\n","Epoch 46: finishing mini batch 455, training error = 0.03125, loss = 0.12715017795562744\n","Epoch 46: finishing mini batch 456, training error = 0.015625, loss = 0.06689660996198654\n","Epoch 46: finishing mini batch 457, training error = 0.046875, loss = 0.18180344998836517\n","Epoch 46: finishing mini batch 458, training error = 0.046875, loss = 0.19225697219371796\n","Epoch 46: finishing mini batch 459, training error = 0.015625, loss = 0.05635188892483711\n","Epoch 46: finishing mini batch 460, training error = 0.015625, loss = 0.09869377315044403\n","Epoch 46: finishing mini batch 461, training error = 0.046875, loss = 0.16827160120010376\n","Epoch 46: finishing mini batch 462, training error = 0.046875, loss = 0.12563897669315338\n","Epoch 46: finishing mini batch 463, training error = 0.0625, loss = 0.16590653359889984\n","Epoch 46: finishing mini batch 464, training error = 0.046875, loss = 0.11669956892728806\n","Epoch 46: finishing mini batch 465, training error = 0.015625, loss = 0.05957849323749542\n","Epoch 46: finishing mini batch 466, training error = 0.03125, loss = 0.1191682443022728\n","Epoch 46: finishing mini batch 467, training error = 0.0, loss = 0.046884361654520035\n","Epoch 46: finishing mini batch 468, training error = 0.015625, loss = 0.05931495875120163\n","Epoch 46: finishing mini batch 469, training error = 0.03125, loss = 0.08117461949586868\n","Epoch 46: finishing mini batch 470, training error = 0.015625, loss = 0.055377863347530365\n","Epoch 46: finishing mini batch 471, training error = 0.046875, loss = 0.09085696935653687\n","Epoch 46: finishing mini batch 472, training error = 0.015625, loss = 0.0664944127202034\n","Epoch 46: finishing mini batch 473, training error = 0.015625, loss = 0.0657222718000412\n","Epoch 46: finishing mini batch 474, training error = 0.046875, loss = 0.13278506696224213\n","Epoch 46: finishing mini batch 475, training error = 0.09375, loss = 0.17879366874694824\n","Epoch 46: finishing mini batch 476, training error = 0.015625, loss = 0.1654144823551178\n","Epoch 46: finishing mini batch 477, training error = 0.0625, loss = 0.12406302988529205\n","Epoch 46: finishing mini batch 478, training error = 0.03125, loss = 0.14102104306221008\n","Epoch 46: finishing mini batch 479, training error = 0.046875, loss = 0.19593362510204315\n","Epoch 46: finishing mini batch 480, training error = 0.03125, loss = 0.07930337637662888\n","Epoch 46: finishing mini batch 481, training error = 0.046875, loss = 0.08960895985364914\n","Epoch 46: finishing mini batch 482, training error = 0.03125, loss = 0.08262312412261963\n","Epoch 46: finishing mini batch 483, training error = 0.046875, loss = 0.11763843894004822\n","Epoch 46: finishing mini batch 484, training error = 0.0625, loss = 0.10363692045211792\n","Epoch 46: finishing mini batch 485, training error = 0.03125, loss = 0.10767961293458939\n","Epoch 46: finishing mini batch 486, training error = 0.015625, loss = 0.0748559832572937\n","Epoch 46: finishing mini batch 487, training error = 0.125, loss = 0.2941626012325287\n","Epoch 46: finishing mini batch 488, training error = 0.09375, loss = 0.22331289947032928\n","Epoch 46: finishing mini batch 489, training error = 0.046875, loss = 0.12873034179210663\n","Epoch 46: finishing mini batch 490, training error = 0.03125, loss = 0.15265405178070068\n","Epoch 46: finishing mini batch 491, training error = 0.046875, loss = 0.09015141427516937\n","Epoch 46: finishing mini batch 492, training error = 0.03125, loss = 0.10774363577365875\n","Epoch 46: finishing mini batch 493, training error = 0.03125, loss = 0.08555283397436142\n","Epoch 46: finishing mini batch 494, training error = 0.09375, loss = 0.14400453865528107\n","Epoch 46: finishing mini batch 495, training error = 0.046875, loss = 0.14243672788143158\n","Epoch 46: finishing mini batch 496, training error = 0.078125, loss = 0.20149968564510345\n","Epoch 46: finishing mini batch 497, training error = 0.03125, loss = 0.16084985435009003\n","Epoch 46: finishing mini batch 498, training error = 0.015625, loss = 0.058249980211257935\n","Epoch 46: finishing mini batch 499, training error = 0.09375, loss = 0.15468169748783112\n","Epoch 46: finishing mini batch 500, training error = 0.03125, loss = 0.09496369957923889\n","Epoch 46: finishing mini batch 501, training error = 0.109375, loss = 0.3181968033313751\n","Epoch 46: finishing mini batch 502, training error = 0.0625, loss = 0.13928428292274475\n","Epoch 46: finishing mini batch 503, training error = 0.015625, loss = 0.07641113549470901\n","Epoch 46: finishing mini batch 504, training error = 0.046875, loss = 0.1475803107023239\n","Epoch 46: finishing mini batch 505, training error = 0.015625, loss = 0.06597679853439331\n","Epoch 46: finishing mini batch 506, training error = 0.078125, loss = 0.21153675019741058\n","Epoch 46: finishing mini batch 507, training error = 0.078125, loss = 0.1731395423412323\n","Epoch 46: finishing mini batch 508, training error = 0.0625, loss = 0.1455743908882141\n","Epoch 46: finishing mini batch 509, training error = 0.078125, loss = 0.15840288996696472\n","Epoch 46: finishing mini batch 510, training error = 0.03125, loss = 0.11181171238422394\n","Epoch 46: finishing mini batch 511, training error = 0.09375, loss = 0.13836346566677094\n","Epoch 46: finishing mini batch 512, training error = 0.0, loss = 0.0478895865380764\n","Epoch 46: finishing mini batch 513, training error = 0.015625, loss = 0.08900643140077591\n","Epoch 46: finishing mini batch 514, training error = 0.0625, loss = 0.1934744119644165\n","Epoch 46: finishing mini batch 515, training error = 0.0625, loss = 0.1629410982131958\n","Epoch 46: finishing mini batch 516, training error = 0.0625, loss = 0.2525378167629242\n","Epoch 46: finishing mini batch 517, training error = 0.0625, loss = 0.1593385487794876\n","Epoch 46: finishing mini batch 518, training error = 0.109375, loss = 0.22093921899795532\n","Epoch 46: finishing mini batch 519, training error = 0.0625, loss = 0.153408020734787\n","Epoch 46: finishing mini batch 520, training error = 0.015625, loss = 0.10767371207475662\n","Epoch 46: finishing mini batch 521, training error = 0.046875, loss = 0.10891958326101303\n","Epoch 46: finishing mini batch 522, training error = 0.03125, loss = 0.08239947259426117\n","Epoch 46: finishing mini batch 523, training error = 0.03125, loss = 0.10989775508642197\n","Epoch 46: finishing mini batch 524, training error = 0.078125, loss = 0.17409296333789825\n","Epoch 46: finishing mini batch 525, training error = 0.046875, loss = 0.10834217071533203\n","Epoch 46: finishing mini batch 526, training error = 0.015625, loss = 0.0655912533402443\n","Epoch 46: finishing mini batch 527, training error = 0.0, loss = 0.08459103107452393\n","Epoch 46: finishing mini batch 528, training error = 0.015625, loss = 0.0730142593383789\n","Epoch 46: finishing mini batch 529, training error = 0.0625, loss = 0.10380568355321884\n","Epoch 46: finishing mini batch 530, training error = 0.015625, loss = 0.0753738135099411\n","Epoch 46: finishing mini batch 531, training error = 0.0625, loss = 0.15475395321846008\n","Epoch 46: finishing mini batch 532, training error = 0.015625, loss = 0.03827634081244469\n","Epoch 46: finishing mini batch 533, training error = 0.046875, loss = 0.1757267713546753\n","Epoch 46: finishing mini batch 534, training error = 0.03125, loss = 0.11703351140022278\n","Epoch 46: finishing mini batch 535, training error = 0.046875, loss = 0.12745779752731323\n","Epoch 46: finishing mini batch 536, training error = 0.015625, loss = 0.050839509814977646\n","Epoch 46: finishing mini batch 537, training error = 0.03125, loss = 0.06580999493598938\n","Epoch 46: finishing mini batch 538, training error = 0.03125, loss = 0.07926124334335327\n","Epoch 46: finishing mini batch 539, training error = 0.03125, loss = 0.0824073851108551\n","Epoch 46: finishing mini batch 540, training error = 0.078125, loss = 0.16567371785640717\n","Epoch 46: finishing mini batch 541, training error = 0.046875, loss = 0.16395129263401031\n","Epoch 46: finishing mini batch 542, training error = 0.015625, loss = 0.05721829831600189\n","Epoch 46: finishing mini batch 543, training error = 0.046875, loss = 0.10291929543018341\n","Epoch 46: finishing mini batch 544, training error = 0.0, loss = 0.03930352255702019\n","Epoch 46: finishing mini batch 545, training error = 0.015625, loss = 0.07948821783065796\n","Epoch 46: finishing mini batch 546, training error = 0.046875, loss = 0.18878276646137238\n","Epoch 46: finishing mini batch 547, training error = 0.09375, loss = 0.26222923398017883\n","Epoch 46: finishing mini batch 548, training error = 0.078125, loss = 0.2210972160100937\n","Epoch 46: finishing mini batch 549, training error = 0.0625, loss = 0.1589483767747879\n","Epoch 46: finishing mini batch 550, training error = 0.03125, loss = 0.06866289675235748\n","Epoch 46: finishing mini batch 551, training error = 0.03125, loss = 0.08158355206251144\n","Epoch 46: finishing mini batch 552, training error = 0.046875, loss = 0.11605988442897797\n","Epoch 46: finishing mini batch 553, training error = 0.03125, loss = 0.07483571767807007\n","Epoch 46: finishing mini batch 554, training error = 0.078125, loss = 0.21513713896274567\n","Epoch 46: finishing mini batch 555, training error = 0.078125, loss = 0.2069428414106369\n","Epoch 46: finishing mini batch 556, training error = 0.0625, loss = 0.12702462077140808\n","Epoch 46: finishing mini batch 557, training error = 0.03125, loss = 0.10460473597049713\n","Epoch 46: finishing mini batch 558, training error = 0.03125, loss = 0.09954939037561417\n","Epoch 46: finishing mini batch 559, training error = 0.078125, loss = 0.2037435621023178\n","Epoch 46: finishing mini batch 560, training error = 0.046875, loss = 0.25031957030296326\n","Epoch 46: finishing mini batch 561, training error = 0.046875, loss = 0.14581887423992157\n","Epoch 46: finishing mini batch 562, training error = 0.03125, loss = 0.08004458993673325\n","Epoch 46: finishing mini batch 563, training error = 0.046875, loss = 0.09603561460971832\n","Epoch 46: finishing mini batch 564, training error = 0.046875, loss = 0.1211201548576355\n","Epoch 46: finishing mini batch 565, training error = 0.046875, loss = 0.09139777719974518\n","Epoch 46: finishing mini batch 566, training error = 0.03125, loss = 0.0926135778427124\n","Epoch 46: finishing mini batch 567, training error = 0.03125, loss = 0.10897921025753021\n","Epoch 46: finishing mini batch 568, training error = 0.078125, loss = 0.1963891237974167\n","Epoch 46: finishing mini batch 569, training error = 0.078125, loss = 0.15772263705730438\n","Epoch 46: finishing mini batch 570, training error = 0.03125, loss = 0.10320036858320236\n","Epoch 46: finishing mini batch 571, training error = 0.046875, loss = 0.15009987354278564\n","Epoch 46: finishing mini batch 572, training error = 0.046875, loss = 0.15130586922168732\n","Epoch 46: finishing mini batch 573, training error = 0.078125, loss = 0.1921088993549347\n","Epoch 46: finishing mini batch 574, training error = 0.0, loss = 0.026390686631202698\n","Epoch 46: finishing mini batch 575, training error = 0.03125, loss = 0.09800354391336441\n","Epoch 46: finishing mini batch 576, training error = 0.015625, loss = 0.05832784250378609\n","Epoch 46: finishing mini batch 577, training error = 0.046875, loss = 0.16648191213607788\n","Epoch 46: finishing mini batch 578, training error = 0.03125, loss = 0.11419256031513214\n","Epoch 46: finishing mini batch 579, training error = 0.046875, loss = 0.1202227994799614\n","Epoch 46: finishing mini batch 580, training error = 0.0, loss = 0.029117872938513756\n","Epoch 46: finishing mini batch 581, training error = 0.03125, loss = 0.1964171975851059\n","Epoch 46: finishing mini batch 582, training error = 0.078125, loss = 0.146564781665802\n","Epoch 46: finishing mini batch 583, training error = 0.046875, loss = 0.12602941691875458\n","Epoch 46: finishing mini batch 584, training error = 0.046875, loss = 0.11654814332723618\n","Epoch 46: finishing mini batch 585, training error = 0.0625, loss = 0.16427826881408691\n","Epoch 46: finishing mini batch 586, training error = 0.015625, loss = 0.05821017920970917\n","Epoch 46: finishing mini batch 587, training error = 0.046875, loss = 0.138103649020195\n","Epoch 46: finishing mini batch 588, training error = 0.03125, loss = 0.09689158201217651\n","Epoch 46: finishing mini batch 589, training error = 0.03125, loss = 0.15872403979301453\n","Epoch 46: finishing mini batch 590, training error = 0.0625, loss = 0.12846513092517853\n","Epoch 46: finishing mini batch 591, training error = 0.015625, loss = 0.05312350392341614\n","Epoch 46: finishing mini batch 592, training error = 0.0625, loss = 0.10199417173862457\n","Epoch 46: finishing mini batch 593, training error = 0.078125, loss = 0.21388760209083557\n","Epoch 46: finishing mini batch 594, training error = 0.015625, loss = 0.07489887624979019\n","Epoch 46: finishing mini batch 595, training error = 0.0625, loss = 0.12103375792503357\n","Epoch 46: finishing mini batch 596, training error = 0.015625, loss = 0.057786595076322556\n","Epoch 46: finishing mini batch 597, training error = 0.109375, loss = 0.3347134590148926\n","Epoch 46: finishing mini batch 598, training error = 0.0625, loss = 0.09608680009841919\n","Epoch 46: finishing mini batch 599, training error = 0.015625, loss = 0.07907760143280029\n","Epoch 46: finishing mini batch 600, training error = 0.03125, loss = 0.10970180481672287\n","Epoch 46: finishing mini batch 601, training error = 0.015625, loss = 0.06847318261861801\n","Epoch 46: finishing mini batch 602, training error = 0.0625, loss = 0.15855750441551208\n","Epoch 46: finishing mini batch 603, training error = 0.0625, loss = 0.20379731059074402\n","Epoch 46: finishing mini batch 604, training error = 0.03125, loss = 0.12276598811149597\n","Epoch 46: finishing mini batch 605, training error = 0.09375, loss = 0.23418714106082916\n","Epoch 46: finishing mini batch 606, training error = 0.0625, loss = 0.15352575480937958\n","Epoch 46: finishing mini batch 607, training error = 0.046875, loss = 0.15925896167755127\n","Epoch 46: finishing mini batch 608, training error = 0.078125, loss = 0.2110772430896759\n","Epoch 46: finishing mini batch 609, training error = 0.0625, loss = 0.2532849907875061\n","Epoch 46: finishing mini batch 610, training error = 0.046875, loss = 0.13896620273590088\n","Epoch 46: finishing mini batch 611, training error = 0.078125, loss = 0.198990136384964\n","Epoch 46: finishing mini batch 612, training error = 0.0625, loss = 0.16210056841373444\n","Epoch 46: finishing mini batch 613, training error = 0.0625, loss = 0.21567267179489136\n","Epoch 46: finishing mini batch 614, training error = 0.015625, loss = 0.07841455191373825\n","Epoch 46: finishing mini batch 615, training error = 0.015625, loss = 0.09490389376878738\n","Epoch 46: finishing mini batch 616, training error = 0.046875, loss = 0.11935873329639435\n","Epoch 46: finishing mini batch 617, training error = 0.0625, loss = 0.11156152188777924\n","Epoch 46: finishing mini batch 618, training error = 0.03125, loss = 0.09852270036935806\n","Epoch 46: finishing mini batch 619, training error = 0.078125, loss = 0.2592184543609619\n","Epoch 46: finishing mini batch 620, training error = 0.046875, loss = 0.09540459513664246\n","Epoch 46: finishing mini batch 621, training error = 0.078125, loss = 0.24098843336105347\n","Epoch 46: finishing mini batch 622, training error = 0.03125, loss = 0.11126507818698883\n","Epoch 46: finishing mini batch 623, training error = 0.078125, loss = 0.1862298548221588\n","Epoch 46: finishing mini batch 624, training error = 0.046875, loss = 0.11841163039207458\n","Epoch 46: finishing mini batch 625, training error = 0.03125, loss = 0.09788002818822861\n","Epoch 46: finishing mini batch 626, training error = 0.09375, loss = 0.1844642013311386\n","Epoch 46: finishing mini batch 627, training error = 0.09375, loss = 0.26200029253959656\n","Epoch 46: finishing mini batch 628, training error = 0.03125, loss = 0.12037937343120575\n","Epoch 46: finishing mini batch 629, training error = 0.09375, loss = 0.1930147409439087\n","Epoch 46: finishing mini batch 630, training error = 0.125, loss = 0.33039426803588867\n","Epoch 46: finishing mini batch 631, training error = 0.140625, loss = 0.2717333436012268\n","Epoch 46: finishing mini batch 632, training error = 0.03125, loss = 0.06216038763523102\n","Epoch 46: finishing mini batch 633, training error = 0.0625, loss = 0.1439315378665924\n","Epoch 46: finishing mini batch 634, training error = 0.0625, loss = 0.2191673219203949\n","Epoch 46: finishing mini batch 635, training error = 0.015625, loss = 0.06431106477975845\n","Epoch 46: finishing mini batch 636, training error = 0.03125, loss = 0.11281420290470123\n","Epoch 46: finishing mini batch 637, training error = 0.03125, loss = 0.06926453113555908\n","Epoch 46: finishing mini batch 638, training error = 0.125, loss = 0.28062599897384644\n","Epoch 46: finishing mini batch 639, training error = 0.03125, loss = 0.08023230731487274\n","Epoch 46: finishing mini batch 640, training error = 0.046875, loss = 0.10629649460315704\n","Epoch 46: finishing mini batch 641, training error = 0.078125, loss = 0.16559350490570068\n","Epoch 46: finishing mini batch 642, training error = 0.078125, loss = 0.17892971634864807\n","Epoch 46: finishing mini batch 643, training error = 0.03125, loss = 0.09384765475988388\n","Epoch 46: finishing mini batch 644, training error = 0.0625, loss = 0.14608564972877502\n","Epoch 46: finishing mini batch 645, training error = 0.03125, loss = 0.1394638568162918\n","Epoch 46: finishing mini batch 646, training error = 0.0625, loss = 0.17933063209056854\n","Epoch 46: finishing mini batch 647, training error = 0.046875, loss = 0.14681477844715118\n","Epoch 46: finishing mini batch 648, training error = 0.140625, loss = 0.3585973083972931\n","Epoch 46: finishing mini batch 649, training error = 0.125, loss = 0.25623196363449097\n","Epoch 46: finishing mini batch 650, training error = 0.0625, loss = 0.15440663695335388\n","Epoch 46: finishing mini batch 651, training error = 0.046875, loss = 0.10530991852283478\n","Epoch 46: finishing mini batch 652, training error = 0.0625, loss = 0.14889593422412872\n","Epoch 46: finishing mini batch 653, training error = 0.078125, loss = 0.19584310054779053\n","Epoch 46: finishing mini batch 654, training error = 0.09375, loss = 0.2597945034503937\n","Epoch 46: finishing mini batch 655, training error = 0.078125, loss = 0.1491728276014328\n","Epoch 46: finishing mini batch 656, training error = 0.0625, loss = 0.23557060956954956\n","Epoch 46: finishing mini batch 657, training error = 0.046875, loss = 0.10867595672607422\n","Epoch 46: finishing mini batch 658, training error = 0.046875, loss = 0.18553121387958527\n","Epoch 46: finishing mini batch 659, training error = 0.09375, loss = 0.2881568968296051\n","Epoch 46: finishing mini batch 660, training error = 0.03125, loss = 0.13398109376430511\n","Epoch 46: finishing mini batch 661, training error = 0.078125, loss = 0.14237870275974274\n","Epoch 46: finishing mini batch 662, training error = 0.109375, loss = 0.2046596258878708\n","Epoch 46: finishing mini batch 663, training error = 0.0625, loss = 0.22581098973751068\n","Epoch 46: finishing mini batch 664, training error = 0.046875, loss = 0.1150311604142189\n","Epoch 46: finishing mini batch 665, training error = 0.046875, loss = 0.08950349688529968\n","Epoch 46: finishing mini batch 666, training error = 0.078125, loss = 0.2024136632680893\n","Epoch 46: finishing mini batch 667, training error = 0.015625, loss = 0.0879567489027977\n","Epoch 46: finishing mini batch 668, training error = 0.015625, loss = 0.07951325178146362\n","Epoch 46: finishing mini batch 669, training error = 0.046875, loss = 0.1563950926065445\n","Epoch 46: finishing mini batch 670, training error = 0.078125, loss = 0.25553181767463684\n","Epoch 46: finishing mini batch 671, training error = 0.046875, loss = 0.15653212368488312\n","Epoch 46: finishing mini batch 672, training error = 0.109375, loss = 0.2420656830072403\n","Epoch 46: finishing mini batch 673, training error = 0.09375, loss = 0.2711460590362549\n","Epoch 46: finishing mini batch 674, training error = 0.0625, loss = 0.16323257982730865\n","Epoch 46: finishing mini batch 675, training error = 0.0625, loss = 0.12904682755470276\n","Epoch 46: finishing mini batch 676, training error = 0.078125, loss = 0.23593172430992126\n","Epoch 46: finishing mini batch 677, training error = 0.0, loss = 0.03804914653301239\n","Epoch 46: finishing mini batch 678, training error = 0.015625, loss = 0.10472071170806885\n","Epoch 46: finishing mini batch 679, training error = 0.03125, loss = 0.09766191244125366\n","Epoch 46: finishing mini batch 680, training error = 0.0625, loss = 0.1558234542608261\n","Epoch 46: finishing mini batch 681, training error = 0.078125, loss = 0.1663924753665924\n","Epoch 46: finishing mini batch 682, training error = 0.046875, loss = 0.1778305023908615\n","Epoch 46: finishing mini batch 683, training error = 0.046875, loss = 0.17417185008525848\n","Epoch 46: finishing mini batch 684, training error = 0.046875, loss = 0.11592642962932587\n","Epoch 46: finishing mini batch 685, training error = 0.015625, loss = 0.07937482744455338\n","Epoch 46: finishing mini batch 686, training error = 0.046875, loss = 0.12122834473848343\n","Epoch 46: finishing mini batch 687, training error = 0.0625, loss = 0.11665179580450058\n","Epoch 46: finishing mini batch 688, training error = 0.046875, loss = 0.10389330238103867\n","Epoch 46: finishing mini batch 689, training error = 0.046875, loss = 0.13935573399066925\n","Epoch 46: finishing mini batch 690, training error = 0.03125, loss = 0.07491555064916611\n","Epoch 46: finishing mini batch 691, training error = 0.0625, loss = 0.21399562060832977\n","Epoch 46: finishing mini batch 692, training error = 0.015625, loss = 0.051384761929512024\n","Epoch 46: finishing mini batch 693, training error = 0.046875, loss = 0.16332218050956726\n","Epoch 46: finishing mini batch 694, training error = 0.046875, loss = 0.10011006146669388\n","Epoch 46: finishing mini batch 695, training error = 0.078125, loss = 0.20543000102043152\n","Epoch 46: finishing mini batch 696, training error = 0.03125, loss = 0.12204600870609283\n","Epoch 46: finishing mini batch 697, training error = 0.03125, loss = 0.10623592138290405\n","Epoch 46: finishing mini batch 698, training error = 0.015625, loss = 0.04599684849381447\n","Epoch 46: finishing mini batch 699, training error = 0.046875, loss = 0.14757846295833588\n","Epoch 46: finishing mini batch 700, training error = 0.0, loss = 0.025548212230205536\n","Epoch 46: finishing mini batch 701, training error = 0.046875, loss = 0.16429267823696136\n","Epoch 46: finishing mini batch 702, training error = 0.046875, loss = 0.09800510853528976\n","Epoch 46: finishing mini batch 703, training error = 0.015625, loss = 0.056847911328077316\n","Epoch 46: finishing mini batch 704, training error = 0.046875, loss = 0.11817779392004013\n","Epoch 46: finishing mini batch 705, training error = 0.09375, loss = 0.19376638531684875\n","Epoch 46: finishing mini batch 706, training error = 0.140625, loss = 0.3524823486804962\n","Epoch 46: finishing mini batch 707, training error = 0.03125, loss = 0.09736032038927078\n","Epoch 46: finishing mini batch 708, training error = 0.03125, loss = 0.15109078586101532\n","Epoch 46: finishing mini batch 709, training error = 0.046875, loss = 0.08161278814077377\n","Epoch 46: finishing mini batch 710, training error = 0.03125, loss = 0.11813875287771225\n","Epoch 46: finishing mini batch 711, training error = 0.046875, loss = 0.12756028771400452\n","Epoch 46: finishing mini batch 712, training error = 0.015625, loss = 0.048218920826911926\n","Epoch 46: finishing mini batch 713, training error = 0.0625, loss = 0.14861983060836792\n","Epoch 46: finishing mini batch 714, training error = 0.03125, loss = 0.12021056562662125\n","Epoch 46: finishing mini batch 715, training error = 0.046875, loss = 0.14114481210708618\n","Epoch 46: finishing mini batch 716, training error = 0.0625, loss = 0.15270067751407623\n","Epoch 46: finishing mini batch 717, training error = 0.03125, loss = 0.07943243533372879\n","Epoch 46: finishing mini batch 718, training error = 0.0625, loss = 0.1504136472940445\n","Epoch 46: finishing mini batch 719, training error = 0.046875, loss = 0.16505128145217896\n","Epoch 46: finishing mini batch 720, training error = 0.03125, loss = 0.07156252861022949\n","Epoch 46: finishing mini batch 721, training error = 0.015625, loss = 0.10633239895105362\n","Epoch 46: finishing mini batch 722, training error = 0.0625, loss = 0.12087900936603546\n","Epoch 46: finishing mini batch 723, training error = 0.015625, loss = 0.06010768935084343\n","Epoch 46: finishing mini batch 724, training error = 0.015625, loss = 0.05518519878387451\n","Epoch 46: finishing mini batch 725, training error = 0.078125, loss = 0.15484951436519623\n","Epoch 46: finishing mini batch 726, training error = 0.015625, loss = 0.07303793728351593\n","Epoch 46: finishing mini batch 727, training error = 0.03125, loss = 0.13655070960521698\n","Epoch 46: finishing mini batch 728, training error = 0.078125, loss = 0.16819213330745697\n","Epoch 46: finishing mini batch 729, training error = 0.046875, loss = 0.11498984694480896\n","Epoch 46: finishing mini batch 730, training error = 0.0625, loss = 0.12857308983802795\n","Epoch 46: finishing mini batch 731, training error = 0.078125, loss = 0.2118295133113861\n","Epoch 46: finishing mini batch 732, training error = 0.03125, loss = 0.10776493698358536\n","Epoch 46: finishing mini batch 733, training error = 0.0625, loss = 0.15315181016921997\n","Epoch 46: finishing mini batch 734, training error = 0.09375, loss = 0.19762621819972992\n","Epoch 46: finishing mini batch 735, training error = 0.078125, loss = 0.1783607304096222\n","Epoch 46: finishing mini batch 736, training error = 0.0625, loss = 0.19169744849205017\n","Epoch 46: finishing mini batch 737, training error = 0.015625, loss = 0.08396589010953903\n","Epoch 46: finishing mini batch 738, training error = 0.0, loss = 0.05208863317966461\n","Epoch 46: finishing mini batch 739, training error = 0.0625, loss = 0.17480415105819702\n","Epoch 46: finishing mini batch 740, training error = 0.015625, loss = 0.07999297231435776\n","Epoch 46: finishing mini batch 741, training error = 0.0625, loss = 0.21264982223510742\n","Epoch 46: finishing mini batch 742, training error = 0.046875, loss = 0.1266864836215973\n","Epoch 46: finishing mini batch 743, training error = 0.046875, loss = 0.15952229499816895\n","Epoch 46: finishing mini batch 744, training error = 0.046875, loss = 0.12754802405834198\n","Epoch 46: finishing mini batch 745, training error = 0.046875, loss = 0.15494462847709656\n","Epoch 46: finishing mini batch 746, training error = 0.0, loss = 0.054784152656793594\n","Epoch 46: finishing mini batch 747, training error = 0.046875, loss = 0.18767769634723663\n","Epoch 46: finishing mini batch 748, training error = 0.09375, loss = 0.3057756721973419\n","Epoch 46: finishing mini batch 749, training error = 0.0625, loss = 0.10961320251226425\n","Epoch 46: finishing mini batch 750, training error = 0.046875, loss = 0.13858897984027863\n","Epoch 46: finishing mini batch 751, training error = 0.03125, loss = 0.11726762354373932\n","Epoch 46: finishing mini batch 752, training error = 0.03125, loss = 0.09901328384876251\n","Epoch 46: finishing mini batch 753, training error = 0.0625, loss = 0.15505798161029816\n","Epoch 46: finishing mini batch 754, training error = 0.0625, loss = 0.22400647401809692\n","Epoch 46: finishing mini batch 755, training error = 0.03125, loss = 0.08802007883787155\n","Epoch 46: finishing mini batch 756, training error = 0.015625, loss = 0.1487019807100296\n","Epoch 46: finishing mini batch 757, training error = 0.0625, loss = 0.1397566795349121\n","Epoch 46: finishing mini batch 758, training error = 0.015625, loss = 0.09745299816131592\n","Epoch 46: finishing mini batch 759, training error = 0.09375, loss = 0.19681908190250397\n","Epoch 46: finishing mini batch 760, training error = 0.046875, loss = 0.1781415194272995\n","Epoch 46: finishing mini batch 761, training error = 0.09375, loss = 0.21312563121318817\n","Epoch 46: finishing mini batch 762, training error = 0.078125, loss = 0.1934492290019989\n","Epoch 46: finishing mini batch 763, training error = 0.046875, loss = 0.13662123680114746\n","Epoch 46: finishing mini batch 764, training error = 0.078125, loss = 0.21906983852386475\n","Epoch 46: finishing mini batch 765, training error = 0.109375, loss = 0.26234373450279236\n","Epoch 46: finishing mini batch 766, training error = 0.03125, loss = 0.07708229124546051\n","Epoch 46: finishing mini batch 767, training error = 0.0625, loss = 0.25938576459884644\n","Epoch 46: finishing mini batch 768, training error = 0.03125, loss = 0.13327480852603912\n","Epoch 46: finishing mini batch 769, training error = 0.015625, loss = 0.09540069103240967\n","Epoch 46: finishing mini batch 770, training error = 0.078125, loss = 0.2742467224597931\n","Epoch 46: finishing mini batch 771, training error = 0.03125, loss = 0.09895898401737213\n","Epoch 46: finishing mini batch 772, training error = 0.0625, loss = 0.18873807787895203\n","Epoch 46: finishing mini batch 773, training error = 0.046875, loss = 0.13930170238018036\n","Epoch 46: finishing mini batch 774, training error = 0.078125, loss = 0.1631498783826828\n","Epoch 46: finishing mini batch 775, training error = 0.09375, loss = 0.22513285279273987\n","Epoch 46: finishing mini batch 776, training error = 0.046875, loss = 0.11867180466651917\n","Epoch 46: finishing mini batch 777, training error = 0.109375, loss = 0.24585482478141785\n","Epoch 46: finishing mini batch 778, training error = 0.03125, loss = 0.084742471575737\n","Epoch 46: finishing mini batch 779, training error = 0.0625, loss = 0.1599171906709671\n","Epoch 46: finishing mini batch 780, training error = 0.046875, loss = 0.09490300714969635\n","Epoch 46: finishing mini batch 781, training error = 0.015625, loss = 0.06250148266553879\n","Epoch 46: finishing mini batch 782, training error = 0.0625, loss = 0.14666368067264557\n","Epoch 46 completed, acc_loss = 95.31258643604815\n","Starting epoch 47...\n","Epoch 47: finishing mini batch 1, training error = 0.0625, loss = 0.18820688128471375\n","Epoch 47: finishing mini batch 2, training error = 0.03125, loss = 0.0796758159995079\n","Epoch 47: finishing mini batch 3, training error = 0.0625, loss = 0.14592164754867554\n","Epoch 47: finishing mini batch 4, training error = 0.015625, loss = 0.05511074885725975\n","Epoch 47: finishing mini batch 5, training error = 0.03125, loss = 0.2081635445356369\n","Epoch 47: finishing mini batch 6, training error = 0.0625, loss = 0.11340425163507462\n","Epoch 47: finishing mini batch 7, training error = 0.015625, loss = 0.07464549690485\n","Epoch 47: finishing mini batch 8, training error = 0.03125, loss = 0.15262722969055176\n","Epoch 47: finishing mini batch 9, training error = 0.015625, loss = 0.06119416654109955\n","Epoch 47: finishing mini batch 10, training error = 0.046875, loss = 0.1411103457212448\n","Epoch 47: finishing mini batch 11, training error = 0.015625, loss = 0.10995058715343475\n","Epoch 47: finishing mini batch 12, training error = 0.09375, loss = 0.24694189429283142\n","Epoch 47: finishing mini batch 13, training error = 0.0625, loss = 0.13481749594211578\n","Epoch 47: finishing mini batch 14, training error = 0.015625, loss = 0.06942655891180038\n","Epoch 47: finishing mini batch 15, training error = 0.0, loss = 0.03846118971705437\n","Epoch 47: finishing mini batch 16, training error = 0.09375, loss = 0.1583699733018875\n","Epoch 47: finishing mini batch 17, training error = 0.015625, loss = 0.08140479773283005\n","Epoch 47: finishing mini batch 18, training error = 0.015625, loss = 0.06190326809883118\n","Epoch 47: finishing mini batch 19, training error = 0.03125, loss = 0.08565361797809601\n","Epoch 47: finishing mini batch 20, training error = 0.046875, loss = 0.11617438495159149\n","Epoch 47: finishing mini batch 21, training error = 0.046875, loss = 0.1615101844072342\n","Epoch 47: finishing mini batch 22, training error = 0.03125, loss = 0.08122389018535614\n","Epoch 47: finishing mini batch 23, training error = 0.0625, loss = 0.17596235871315002\n","Epoch 47: finishing mini batch 24, training error = 0.0625, loss = 0.1496647447347641\n","Epoch 47: finishing mini batch 25, training error = 0.015625, loss = 0.06541711091995239\n","Epoch 47: finishing mini batch 26, training error = 0.046875, loss = 0.09041324257850647\n","Epoch 47: finishing mini batch 27, training error = 0.046875, loss = 0.11619856208562851\n","Epoch 47: finishing mini batch 28, training error = 0.046875, loss = 0.10105422139167786\n","Epoch 47: finishing mini batch 29, training error = 0.046875, loss = 0.11816955357789993\n","Epoch 47: finishing mini batch 30, training error = 0.0625, loss = 0.1261204481124878\n","Epoch 47: finishing mini batch 31, training error = 0.015625, loss = 0.06695941090583801\n","Epoch 47: finishing mini batch 32, training error = 0.046875, loss = 0.15895451605319977\n","Epoch 47: finishing mini batch 33, training error = 0.03125, loss = 0.08362381160259247\n","Epoch 47: finishing mini batch 34, training error = 0.015625, loss = 0.04961191490292549\n","Epoch 47: finishing mini batch 35, training error = 0.03125, loss = 0.11754131317138672\n","Epoch 47: finishing mini batch 36, training error = 0.046875, loss = 0.0864436998963356\n","Epoch 47: finishing mini batch 37, training error = 0.03125, loss = 0.1544370949268341\n","Epoch 47: finishing mini batch 38, training error = 0.046875, loss = 0.11467862129211426\n","Epoch 47: finishing mini batch 39, training error = 0.078125, loss = 0.17363925278186798\n","Epoch 47: finishing mini batch 40, training error = 0.078125, loss = 0.18103758990764618\n","Epoch 47: finishing mini batch 41, training error = 0.078125, loss = 0.1610373556613922\n","Epoch 47: finishing mini batch 42, training error = 0.046875, loss = 0.10673652589321136\n","Epoch 47: finishing mini batch 43, training error = 0.03125, loss = 0.14803269505500793\n","Epoch 47: finishing mini batch 44, training error = 0.015625, loss = 0.07986107468605042\n","Epoch 47: finishing mini batch 45, training error = 0.015625, loss = 0.06302733719348907\n","Epoch 47: finishing mini batch 46, training error = 0.03125, loss = 0.06903655081987381\n","Epoch 47: finishing mini batch 47, training error = 0.03125, loss = 0.10597532987594604\n","Epoch 47: finishing mini batch 48, training error = 0.015625, loss = 0.0748143121600151\n","Epoch 47: finishing mini batch 49, training error = 0.03125, loss = 0.09246900677680969\n","Epoch 47: finishing mini batch 50, training error = 0.0625, loss = 0.11200828850269318\n","Epoch 47: finishing mini batch 51, training error = 0.09375, loss = 0.16887512803077698\n","Epoch 47: finishing mini batch 52, training error = 0.0625, loss = 0.1714855581521988\n","Epoch 47: finishing mini batch 53, training error = 0.03125, loss = 0.07653553038835526\n","Epoch 47: finishing mini batch 54, training error = 0.046875, loss = 0.15541541576385498\n","Epoch 47: finishing mini batch 55, training error = 0.046875, loss = 0.11614463478326797\n","Epoch 47: finishing mini batch 56, training error = 0.046875, loss = 0.08207865059375763\n","Epoch 47: finishing mini batch 57, training error = 0.0, loss = 0.048229850828647614\n","Epoch 47: finishing mini batch 58, training error = 0.015625, loss = 0.0838780626654625\n","Epoch 47: finishing mini batch 59, training error = 0.046875, loss = 0.09904028475284576\n","Epoch 47: finishing mini batch 60, training error = 0.015625, loss = 0.042111486196517944\n","Epoch 47: finishing mini batch 61, training error = 0.015625, loss = 0.04720601439476013\n","Epoch 47: finishing mini batch 62, training error = 0.03125, loss = 0.06660834699869156\n","Epoch 47: finishing mini batch 63, training error = 0.015625, loss = 0.09685281664133072\n","Epoch 47: finishing mini batch 64, training error = 0.03125, loss = 0.10759362578392029\n","Epoch 47: finishing mini batch 65, training error = 0.046875, loss = 0.1802244335412979\n","Epoch 47: finishing mini batch 66, training error = 0.0625, loss = 0.1526142656803131\n","Epoch 47: finishing mini batch 67, training error = 0.015625, loss = 0.08701398223638535\n","Epoch 47: finishing mini batch 68, training error = 0.046875, loss = 0.11313978582620621\n","Epoch 47: finishing mini batch 69, training error = 0.015625, loss = 0.0843057930469513\n","Epoch 47: finishing mini batch 70, training error = 0.015625, loss = 0.0456443727016449\n","Epoch 47: finishing mini batch 71, training error = 0.109375, loss = 0.17888160049915314\n","Epoch 47: finishing mini batch 72, training error = 0.046875, loss = 0.12897777557373047\n","Epoch 47: finishing mini batch 73, training error = 0.046875, loss = 0.11475120484828949\n","Epoch 47: finishing mini batch 74, training error = 0.0, loss = 0.0438169427216053\n","Epoch 47: finishing mini batch 75, training error = 0.03125, loss = 0.08560628443956375\n","Epoch 47: finishing mini batch 76, training error = 0.046875, loss = 0.22171035408973694\n","Epoch 47: finishing mini batch 77, training error = 0.046875, loss = 0.07925380021333694\n","Epoch 47: finishing mini batch 78, training error = 0.0625, loss = 0.14345619082450867\n","Epoch 47: finishing mini batch 79, training error = 0.0625, loss = 0.1518062800168991\n","Epoch 47: finishing mini batch 80, training error = 0.0, loss = 0.027431350201368332\n","Epoch 47: finishing mini batch 81, training error = 0.0625, loss = 0.1781962364912033\n","Epoch 47: finishing mini batch 82, training error = 0.0625, loss = 0.1388474404811859\n","Epoch 47: finishing mini batch 83, training error = 0.0625, loss = 0.11860144138336182\n","Epoch 47: finishing mini batch 84, training error = 0.03125, loss = 0.09414010494947433\n","Epoch 47: finishing mini batch 85, training error = 0.015625, loss = 0.04256739839911461\n","Epoch 47: finishing mini batch 86, training error = 0.015625, loss = 0.0642576739192009\n","Epoch 47: finishing mini batch 87, training error = 0.046875, loss = 0.19240666925907135\n","Epoch 47: finishing mini batch 88, training error = 0.03125, loss = 0.054343827068805695\n","Epoch 47: finishing mini batch 89, training error = 0.015625, loss = 0.041889775544404984\n","Epoch 47: finishing mini batch 90, training error = 0.015625, loss = 0.0904087945818901\n","Epoch 47: finishing mini batch 91, training error = 0.046875, loss = 0.06927702575922012\n","Epoch 47: finishing mini batch 92, training error = 0.09375, loss = 0.1803566962480545\n","Epoch 47: finishing mini batch 93, training error = 0.015625, loss = 0.08876027911901474\n","Epoch 47: finishing mini batch 94, training error = 0.046875, loss = 0.12157432734966278\n","Epoch 47: finishing mini batch 95, training error = 0.015625, loss = 0.04573356732726097\n","Epoch 47: finishing mini batch 96, training error = 0.0, loss = 0.02762814797461033\n","Epoch 47: finishing mini batch 97, training error = 0.0, loss = 0.038472529500722885\n","Epoch 47: finishing mini batch 98, training error = 0.03125, loss = 0.09645342081785202\n","Epoch 47: finishing mini batch 99, training error = 0.03125, loss = 0.08703471720218658\n","Epoch 47: finishing mini batch 100, training error = 0.09375, loss = 0.1870916485786438\n","Epoch 47: finishing mini batch 101, training error = 0.015625, loss = 0.09157077968120575\n","Epoch 47: finishing mini batch 102, training error = 0.078125, loss = 0.21882717311382294\n","Epoch 47: finishing mini batch 103, training error = 0.0625, loss = 0.14681404829025269\n","Epoch 47: finishing mini batch 104, training error = 0.015625, loss = 0.07005155086517334\n","Epoch 47: finishing mini batch 105, training error = 0.015625, loss = 0.04636925458908081\n","Epoch 47: finishing mini batch 106, training error = 0.0625, loss = 0.15165993571281433\n","Epoch 47: finishing mini batch 107, training error = 0.015625, loss = 0.04705065116286278\n","Epoch 47: finishing mini batch 108, training error = 0.046875, loss = 0.10918226093053818\n","Epoch 47: finishing mini batch 109, training error = 0.0625, loss = 0.10001692175865173\n","Epoch 47: finishing mini batch 110, training error = 0.03125, loss = 0.13219287991523743\n","Epoch 47: finishing mini batch 111, training error = 0.0625, loss = 0.201239213347435\n","Epoch 47: finishing mini batch 112, training error = 0.03125, loss = 0.16473150253295898\n","Epoch 47: finishing mini batch 113, training error = 0.03125, loss = 0.08420250564813614\n","Epoch 47: finishing mini batch 114, training error = 0.0, loss = 0.049406394362449646\n","Epoch 47: finishing mini batch 115, training error = 0.03125, loss = 0.09535522758960724\n","Epoch 47: finishing mini batch 116, training error = 0.0625, loss = 0.17527946829795837\n","Epoch 47: finishing mini batch 117, training error = 0.015625, loss = 0.05476521700620651\n","Epoch 47: finishing mini batch 118, training error = 0.015625, loss = 0.04375283792614937\n","Epoch 47: finishing mini batch 119, training error = 0.03125, loss = 0.08969852328300476\n","Epoch 47: finishing mini batch 120, training error = 0.03125, loss = 0.09773789346218109\n","Epoch 47: finishing mini batch 121, training error = 0.03125, loss = 0.09157707542181015\n","Epoch 47: finishing mini batch 122, training error = 0.046875, loss = 0.11204930394887924\n","Epoch 47: finishing mini batch 123, training error = 0.03125, loss = 0.062321338802576065\n","Epoch 47: finishing mini batch 124, training error = 0.015625, loss = 0.05119706317782402\n","Epoch 47: finishing mini batch 125, training error = 0.046875, loss = 0.1359378695487976\n","Epoch 47: finishing mini batch 126, training error = 0.03125, loss = 0.07885884493589401\n","Epoch 47: finishing mini batch 127, training error = 0.046875, loss = 0.16313719749450684\n","Epoch 47: finishing mini batch 128, training error = 0.03125, loss = 0.06733771413564682\n","Epoch 47: finishing mini batch 129, training error = 0.046875, loss = 0.08328909426927567\n","Epoch 47: finishing mini batch 130, training error = 0.015625, loss = 0.05468583106994629\n","Epoch 47: finishing mini batch 131, training error = 0.046875, loss = 0.12275810539722443\n","Epoch 47: finishing mini batch 132, training error = 0.078125, loss = 0.19115278124809265\n","Epoch 47: finishing mini batch 133, training error = 0.046875, loss = 0.12269838899374008\n","Epoch 47: finishing mini batch 134, training error = 0.015625, loss = 0.07552290707826614\n","Epoch 47: finishing mini batch 135, training error = 0.0625, loss = 0.21955841779708862\n","Epoch 47: finishing mini batch 136, training error = 0.046875, loss = 0.12615950405597687\n","Epoch 47: finishing mini batch 137, training error = 0.046875, loss = 0.0895375907421112\n","Epoch 47: finishing mini batch 138, training error = 0.015625, loss = 0.06096777692437172\n","Epoch 47: finishing mini batch 139, training error = 0.046875, loss = 0.12916383147239685\n","Epoch 47: finishing mini batch 140, training error = 0.09375, loss = 0.16441293060779572\n","Epoch 47: finishing mini batch 141, training error = 0.015625, loss = 0.08821582794189453\n","Epoch 47: finishing mini batch 142, training error = 0.046875, loss = 0.11747242510318756\n","Epoch 47: finishing mini batch 143, training error = 0.015625, loss = 0.06834651529788971\n","Epoch 47: finishing mini batch 144, training error = 0.03125, loss = 0.07452458888292313\n","Epoch 47: finishing mini batch 145, training error = 0.03125, loss = 0.06293808668851852\n","Epoch 47: finishing mini batch 146, training error = 0.046875, loss = 0.16848179697990417\n","Epoch 47: finishing mini batch 147, training error = 0.046875, loss = 0.11956920474767685\n","Epoch 47: finishing mini batch 148, training error = 0.03125, loss = 0.08153124898672104\n","Epoch 47: finishing mini batch 149, training error = 0.046875, loss = 0.1567247211933136\n","Epoch 47: finishing mini batch 150, training error = 0.0625, loss = 0.1408894956111908\n","Epoch 47: finishing mini batch 151, training error = 0.09375, loss = 0.15679940581321716\n","Epoch 47: finishing mini batch 152, training error = 0.03125, loss = 0.07130032032728195\n","Epoch 47: finishing mini batch 153, training error = 0.03125, loss = 0.09677766263484955\n","Epoch 47: finishing mini batch 154, training error = 0.046875, loss = 0.11675997078418732\n","Epoch 47: finishing mini batch 155, training error = 0.03125, loss = 0.08944641798734665\n","Epoch 47: finishing mini batch 156, training error = 0.0, loss = 0.027928628027439117\n","Epoch 47: finishing mini batch 157, training error = 0.015625, loss = 0.058287881314754486\n","Epoch 47: finishing mini batch 158, training error = 0.0625, loss = 0.12950466573238373\n","Epoch 47: finishing mini batch 159, training error = 0.0625, loss = 0.17696960270404816\n","Epoch 47: finishing mini batch 160, training error = 0.0, loss = 0.03190569207072258\n","Epoch 47: finishing mini batch 161, training error = 0.0625, loss = 0.17592665553092957\n","Epoch 47: finishing mini batch 162, training error = 0.046875, loss = 0.1972433626651764\n","Epoch 47: finishing mini batch 163, training error = 0.015625, loss = 0.051114317029714584\n","Epoch 47: finishing mini batch 164, training error = 0.046875, loss = 0.14686432480812073\n","Epoch 47: finishing mini batch 165, training error = 0.015625, loss = 0.05234939604997635\n","Epoch 47: finishing mini batch 166, training error = 0.015625, loss = 0.10830552875995636\n","Epoch 47: finishing mini batch 167, training error = 0.015625, loss = 0.05615866929292679\n","Epoch 47: finishing mini batch 168, training error = 0.078125, loss = 0.23384878039360046\n","Epoch 47: finishing mini batch 169, training error = 0.03125, loss = 0.1176750585436821\n","Epoch 47: finishing mini batch 170, training error = 0.078125, loss = 0.20384450256824493\n","Epoch 47: finishing mini batch 171, training error = 0.03125, loss = 0.08241996169090271\n","Epoch 47: finishing mini batch 172, training error = 0.046875, loss = 0.09874239563941956\n","Epoch 47: finishing mini batch 173, training error = 0.015625, loss = 0.07028903067111969\n","Epoch 47: finishing mini batch 174, training error = 0.03125, loss = 0.08687922358512878\n","Epoch 47: finishing mini batch 175, training error = 0.015625, loss = 0.0885874330997467\n","Epoch 47: finishing mini batch 176, training error = 0.0, loss = 0.034061938524246216\n","Epoch 47: finishing mini batch 177, training error = 0.109375, loss = 0.23306702077388763\n","Epoch 47: finishing mini batch 178, training error = 0.046875, loss = 0.08887793123722076\n","Epoch 47: finishing mini batch 179, training error = 0.03125, loss = 0.09269128739833832\n","Epoch 47: finishing mini batch 180, training error = 0.015625, loss = 0.04458455368876457\n","Epoch 47: finishing mini batch 181, training error = 0.015625, loss = 0.08250872790813446\n","Epoch 47: finishing mini batch 182, training error = 0.078125, loss = 0.13228023052215576\n","Epoch 47: finishing mini batch 183, training error = 0.0625, loss = 0.20302066206932068\n","Epoch 47: finishing mini batch 184, training error = 0.0625, loss = 0.11203745752573013\n","Epoch 47: finishing mini batch 185, training error = 0.0625, loss = 0.20866887271404266\n","Epoch 47: finishing mini batch 186, training error = 0.046875, loss = 0.17539677023887634\n","Epoch 47: finishing mini batch 187, training error = 0.015625, loss = 0.05746624246239662\n","Epoch 47: finishing mini batch 188, training error = 0.0625, loss = 0.13632647693157196\n","Epoch 47: finishing mini batch 189, training error = 0.03125, loss = 0.09303303062915802\n","Epoch 47: finishing mini batch 190, training error = 0.046875, loss = 0.11088714003562927\n","Epoch 47: finishing mini batch 191, training error = 0.046875, loss = 0.11224710941314697\n","Epoch 47: finishing mini batch 192, training error = 0.0, loss = 0.032195381820201874\n","Epoch 47: finishing mini batch 193, training error = 0.046875, loss = 0.09123995900154114\n","Epoch 47: finishing mini batch 194, training error = 0.078125, loss = 0.1857892870903015\n","Epoch 47: finishing mini batch 195, training error = 0.03125, loss = 0.06457279622554779\n","Epoch 47: finishing mini batch 196, training error = 0.0625, loss = 0.13611915707588196\n","Epoch 47: finishing mini batch 197, training error = 0.0, loss = 0.05679167062044144\n","Epoch 47: finishing mini batch 198, training error = 0.03125, loss = 0.08416477590799332\n","Epoch 47: finishing mini batch 199, training error = 0.046875, loss = 0.07934645563364029\n","Epoch 47: finishing mini batch 200, training error = 0.046875, loss = 0.19249767065048218\n","Epoch 47: finishing mini batch 201, training error = 0.03125, loss = 0.08307288587093353\n","Epoch 47: finishing mini batch 202, training error = 0.0625, loss = 0.14555414021015167\n","Epoch 47: finishing mini batch 203, training error = 0.046875, loss = 0.07508130371570587\n","Epoch 47: finishing mini batch 204, training error = 0.03125, loss = 0.06978058815002441\n","Epoch 47: finishing mini batch 205, training error = 0.03125, loss = 0.08056268095970154\n","Epoch 47: finishing mini batch 206, training error = 0.0, loss = 0.014333242550492287\n","Epoch 47: finishing mini batch 207, training error = 0.078125, loss = 0.18759074807167053\n","Epoch 47: finishing mini batch 208, training error = 0.015625, loss = 0.06250296533107758\n","Epoch 47: finishing mini batch 209, training error = 0.03125, loss = 0.07787080109119415\n","Epoch 47: finishing mini batch 210, training error = 0.03125, loss = 0.07439084351062775\n","Epoch 47: finishing mini batch 211, training error = 0.015625, loss = 0.042347174137830734\n","Epoch 47: finishing mini batch 212, training error = 0.015625, loss = 0.10439997166395187\n","Epoch 47: finishing mini batch 213, training error = 0.03125, loss = 0.13776738941669464\n","Epoch 47: finishing mini batch 214, training error = 0.078125, loss = 0.15998676419258118\n","Epoch 47: finishing mini batch 215, training error = 0.046875, loss = 0.1196788027882576\n","Epoch 47: finishing mini batch 216, training error = 0.046875, loss = 0.11469867825508118\n","Epoch 47: finishing mini batch 217, training error = 0.015625, loss = 0.04313445836305618\n","Epoch 47: finishing mini batch 218, training error = 0.015625, loss = 0.04589851200580597\n","Epoch 47: finishing mini batch 219, training error = 0.015625, loss = 0.031197674572467804\n","Epoch 47: finishing mini batch 220, training error = 0.078125, loss = 0.16065563261508942\n","Epoch 47: finishing mini batch 221, training error = 0.015625, loss = 0.03840601071715355\n","Epoch 47: finishing mini batch 222, training error = 0.015625, loss = 0.06095385551452637\n","Epoch 47: finishing mini batch 223, training error = 0.015625, loss = 0.055613283067941666\n","Epoch 47: finishing mini batch 224, training error = 0.015625, loss = 0.07645004242658615\n","Epoch 47: finishing mini batch 225, training error = 0.0, loss = 0.03625459969043732\n","Epoch 47: finishing mini batch 226, training error = 0.015625, loss = 0.09933121502399445\n","Epoch 47: finishing mini batch 227, training error = 0.046875, loss = 0.0915779322385788\n","Epoch 47: finishing mini batch 228, training error = 0.03125, loss = 0.08219380676746368\n","Epoch 47: finishing mini batch 229, training error = 0.015625, loss = 0.05570429190993309\n","Epoch 47: finishing mini batch 230, training error = 0.046875, loss = 0.09918922185897827\n","Epoch 47: finishing mini batch 231, training error = 0.015625, loss = 0.06597603112459183\n","Epoch 47: finishing mini batch 232, training error = 0.03125, loss = 0.07429356127977371\n","Epoch 47: finishing mini batch 233, training error = 0.03125, loss = 0.08988133072853088\n","Epoch 47: finishing mini batch 234, training error = 0.109375, loss = 0.3297979235649109\n","Epoch 47: finishing mini batch 235, training error = 0.015625, loss = 0.04469192400574684\n","Epoch 47: finishing mini batch 236, training error = 0.0625, loss = 0.09664562344551086\n","Epoch 47: finishing mini batch 237, training error = 0.015625, loss = 0.05116603523492813\n","Epoch 47: finishing mini batch 238, training error = 0.046875, loss = 0.14154677093029022\n","Epoch 47: finishing mini batch 239, training error = 0.03125, loss = 0.0838887095451355\n","Epoch 47: finishing mini batch 240, training error = 0.015625, loss = 0.061518821865320206\n","Epoch 47: finishing mini batch 241, training error = 0.0, loss = 0.02716716378927231\n","Epoch 47: finishing mini batch 242, training error = 0.03125, loss = 0.06281980872154236\n","Epoch 47: finishing mini batch 243, training error = 0.046875, loss = 0.09997852146625519\n","Epoch 47: finishing mini batch 244, training error = 0.03125, loss = 0.06878379732370377\n","Epoch 47: finishing mini batch 245, training error = 0.03125, loss = 0.05526681989431381\n","Epoch 47: finishing mini batch 246, training error = 0.015625, loss = 0.08222444355487823\n","Epoch 47: finishing mini batch 247, training error = 0.0625, loss = 0.13982586562633514\n","Epoch 47: finishing mini batch 248, training error = 0.046875, loss = 0.11967933177947998\n","Epoch 47: finishing mini batch 249, training error = 0.0, loss = 0.04998381808400154\n","Epoch 47: finishing mini batch 250, training error = 0.0625, loss = 0.14620141685009003\n","Epoch 47: finishing mini batch 251, training error = 0.03125, loss = 0.13204918801784515\n","Epoch 47: finishing mini batch 252, training error = 0.015625, loss = 0.03096720576286316\n","Epoch 47: finishing mini batch 253, training error = 0.03125, loss = 0.11242426186800003\n","Epoch 47: finishing mini batch 254, training error = 0.0, loss = 0.0583147369325161\n","Epoch 47: finishing mini batch 255, training error = 0.015625, loss = 0.06637318432331085\n","Epoch 47: finishing mini batch 256, training error = 0.03125, loss = 0.07489527016878128\n","Epoch 47: finishing mini batch 257, training error = 0.046875, loss = 0.0886022076010704\n","Epoch 47: finishing mini batch 258, training error = 0.046875, loss = 0.09978637844324112\n","Epoch 47: finishing mini batch 259, training error = 0.015625, loss = 0.04402157664299011\n","Epoch 47: finishing mini batch 260, training error = 0.03125, loss = 0.1600826531648636\n","Epoch 47: finishing mini batch 261, training error = 0.015625, loss = 0.10012236982584\n","Epoch 47: finishing mini batch 262, training error = 0.03125, loss = 0.07835401594638824\n","Epoch 47: finishing mini batch 263, training error = 0.0, loss = 0.03443596139550209\n","Epoch 47: finishing mini batch 264, training error = 0.046875, loss = 0.18418766558170319\n","Epoch 47: finishing mini batch 265, training error = 0.046875, loss = 0.11377400904893875\n","Epoch 47: finishing mini batch 266, training error = 0.03125, loss = 0.13125117123126984\n","Epoch 47: finishing mini batch 267, training error = 0.015625, loss = 0.08327573537826538\n","Epoch 47: finishing mini batch 268, training error = 0.015625, loss = 0.07478100061416626\n","Epoch 47: finishing mini batch 269, training error = 0.078125, loss = 0.21800418198108673\n","Epoch 47: finishing mini batch 270, training error = 0.03125, loss = 0.07677967101335526\n","Epoch 47: finishing mini batch 271, training error = 0.046875, loss = 0.20194023847579956\n","Epoch 47: finishing mini batch 272, training error = 0.046875, loss = 0.1457197517156601\n","Epoch 47: finishing mini batch 273, training error = 0.046875, loss = 0.08497839421033859\n","Epoch 47: finishing mini batch 274, training error = 0.03125, loss = 0.0598594956099987\n","Epoch 47: finishing mini batch 275, training error = 0.03125, loss = 0.07663676887750626\n","Epoch 47: finishing mini batch 276, training error = 0.046875, loss = 0.12645244598388672\n","Epoch 47: finishing mini batch 277, training error = 0.046875, loss = 0.12011640518903732\n","Epoch 47: finishing mini batch 278, training error = 0.015625, loss = 0.06323125213384628\n","Epoch 47: finishing mini batch 279, training error = 0.015625, loss = 0.049080390483140945\n","Epoch 47: finishing mini batch 280, training error = 0.015625, loss = 0.10229596495628357\n","Epoch 47: finishing mini batch 281, training error = 0.015625, loss = 0.048931363970041275\n","Epoch 47: finishing mini batch 282, training error = 0.015625, loss = 0.06451067328453064\n","Epoch 47: finishing mini batch 283, training error = 0.015625, loss = 0.10370786488056183\n","Epoch 47: finishing mini batch 284, training error = 0.015625, loss = 0.06182675063610077\n","Epoch 47: finishing mini batch 285, training error = 0.015625, loss = 0.042790625244379044\n","Epoch 47: finishing mini batch 286, training error = 0.015625, loss = 0.0748935341835022\n","Epoch 47: finishing mini batch 287, training error = 0.078125, loss = 0.15174493193626404\n","Epoch 47: finishing mini batch 288, training error = 0.03125, loss = 0.05298084020614624\n","Epoch 47: finishing mini batch 289, training error = 0.046875, loss = 0.11235775053501129\n","Epoch 47: finishing mini batch 290, training error = 0.03125, loss = 0.059173453599214554\n","Epoch 47: finishing mini batch 291, training error = 0.09375, loss = 0.18035155534744263\n","Epoch 47: finishing mini batch 292, training error = 0.0, loss = 0.04485161602497101\n","Epoch 47: finishing mini batch 293, training error = 0.078125, loss = 0.1660914123058319\n","Epoch 47: finishing mini batch 294, training error = 0.015625, loss = 0.09268046915531158\n","Epoch 47: finishing mini batch 295, training error = 0.0625, loss = 0.1601024866104126\n","Epoch 47: finishing mini batch 296, training error = 0.015625, loss = 0.03803950920701027\n","Epoch 47: finishing mini batch 297, training error = 0.03125, loss = 0.12880630791187286\n","Epoch 47: finishing mini batch 298, training error = 0.046875, loss = 0.1831532120704651\n","Epoch 47: finishing mini batch 299, training error = 0.03125, loss = 0.0788615494966507\n","Epoch 47: finishing mini batch 300, training error = 0.03125, loss = 0.05580446869134903\n","Epoch 47: finishing mini batch 301, training error = 0.046875, loss = 0.11042675375938416\n","Epoch 47: finishing mini batch 302, training error = 0.046875, loss = 0.1241416186094284\n","Epoch 47: finishing mini batch 303, training error = 0.0625, loss = 0.19490523636341095\n","Epoch 47: finishing mini batch 304, training error = 0.046875, loss = 0.10743517428636551\n","Epoch 47: finishing mini batch 305, training error = 0.03125, loss = 0.08196582645177841\n","Epoch 47: finishing mini batch 306, training error = 0.078125, loss = 0.17196746170520782\n","Epoch 47: finishing mini batch 307, training error = 0.015625, loss = 0.11089915037155151\n","Epoch 47: finishing mini batch 308, training error = 0.03125, loss = 0.08543436229228973\n","Epoch 47: finishing mini batch 309, training error = 0.0, loss = 0.03365136682987213\n","Epoch 47: finishing mini batch 310, training error = 0.046875, loss = 0.10988819599151611\n","Epoch 47: finishing mini batch 311, training error = 0.015625, loss = 0.05036551505327225\n","Epoch 47: finishing mini batch 312, training error = 0.03125, loss = 0.11648821085691452\n","Epoch 47: finishing mini batch 313, training error = 0.046875, loss = 0.10975009948015213\n","Epoch 47: finishing mini batch 314, training error = 0.0625, loss = 0.09936504065990448\n","Epoch 47: finishing mini batch 315, training error = 0.015625, loss = 0.048278361558914185\n","Epoch 47: finishing mini batch 316, training error = 0.0625, loss = 0.16697748005390167\n","Epoch 47: finishing mini batch 317, training error = 0.0625, loss = 0.16512642800807953\n","Epoch 47: finishing mini batch 318, training error = 0.015625, loss = 0.10730380564928055\n","Epoch 47: finishing mini batch 319, training error = 0.09375, loss = 0.1855781525373459\n","Epoch 47: finishing mini batch 320, training error = 0.0625, loss = 0.16923272609710693\n","Epoch 47: finishing mini batch 321, training error = 0.078125, loss = 0.15472009778022766\n","Epoch 47: finishing mini batch 322, training error = 0.015625, loss = 0.053720682859420776\n","Epoch 47: finishing mini batch 323, training error = 0.03125, loss = 0.08537262678146362\n","Epoch 47: finishing mini batch 324, training error = 0.0, loss = 0.037455737590789795\n","Epoch 47: finishing mini batch 325, training error = 0.0625, loss = 0.17150571942329407\n","Epoch 47: finishing mini batch 326, training error = 0.0625, loss = 0.14809775352478027\n","Epoch 47: finishing mini batch 327, training error = 0.015625, loss = 0.06523564457893372\n","Epoch 47: finishing mini batch 328, training error = 0.078125, loss = 0.15672408044338226\n","Epoch 47: finishing mini batch 329, training error = 0.03125, loss = 0.0795363336801529\n","Epoch 47: finishing mini batch 330, training error = 0.03125, loss = 0.07791444659233093\n","Epoch 47: finishing mini batch 331, training error = 0.03125, loss = 0.09013489633798599\n","Epoch 47: finishing mini batch 332, training error = 0.015625, loss = 0.04983927309513092\n","Epoch 47: finishing mini batch 333, training error = 0.0625, loss = 0.1920899897813797\n","Epoch 47: finishing mini batch 334, training error = 0.046875, loss = 0.14257504045963287\n","Epoch 47: finishing mini batch 335, training error = 0.03125, loss = 0.06943206489086151\n","Epoch 47: finishing mini batch 336, training error = 0.03125, loss = 0.08298955857753754\n","Epoch 47: finishing mini batch 337, training error = 0.0, loss = 0.04861423745751381\n","Epoch 47: finishing mini batch 338, training error = 0.03125, loss = 0.08160024881362915\n","Epoch 47: finishing mini batch 339, training error = 0.0, loss = 0.02912266179919243\n","Epoch 47: finishing mini batch 340, training error = 0.03125, loss = 0.05215880274772644\n","Epoch 47: finishing mini batch 341, training error = 0.046875, loss = 0.15130944550037384\n","Epoch 47: finishing mini batch 342, training error = 0.046875, loss = 0.09440895915031433\n","Epoch 47: finishing mini batch 343, training error = 0.015625, loss = 0.04731814190745354\n","Epoch 47: finishing mini batch 344, training error = 0.0, loss = 0.043157920241355896\n","Epoch 47: finishing mini batch 345, training error = 0.015625, loss = 0.04907640814781189\n","Epoch 47: finishing mini batch 346, training error = 0.0, loss = 0.03544296696782112\n","Epoch 47: finishing mini batch 347, training error = 0.03125, loss = 0.10505025088787079\n","Epoch 47: finishing mini batch 348, training error = 0.046875, loss = 0.1434181034564972\n","Epoch 47: finishing mini batch 349, training error = 0.03125, loss = 0.07094267755746841\n","Epoch 47: finishing mini batch 350, training error = 0.03125, loss = 0.09459980577230453\n","Epoch 47: finishing mini batch 351, training error = 0.015625, loss = 0.08974263072013855\n","Epoch 47: finishing mini batch 352, training error = 0.015625, loss = 0.0951584056019783\n","Epoch 47: finishing mini batch 353, training error = 0.03125, loss = 0.10926096886396408\n","Epoch 47: finishing mini batch 354, training error = 0.03125, loss = 0.1827584207057953\n","Epoch 47: finishing mini batch 355, training error = 0.0, loss = 0.017192628234624863\n","Epoch 47: finishing mini batch 356, training error = 0.078125, loss = 0.19273129105567932\n","Epoch 47: finishing mini batch 357, training error = 0.03125, loss = 0.06957453489303589\n","Epoch 47: finishing mini batch 358, training error = 0.0, loss = 0.03864828869700432\n","Epoch 47: finishing mini batch 359, training error = 0.0625, loss = 0.18425783514976501\n","Epoch 47: finishing mini batch 360, training error = 0.03125, loss = 0.10551483929157257\n","Epoch 47: finishing mini batch 361, training error = 0.03125, loss = 0.08769091963768005\n","Epoch 47: finishing mini batch 362, training error = 0.0, loss = 0.02272801660001278\n","Epoch 47: finishing mini batch 363, training error = 0.0625, loss = 0.17807114124298096\n","Epoch 47: finishing mini batch 364, training error = 0.0625, loss = 0.16397811472415924\n","Epoch 47: finishing mini batch 365, training error = 0.078125, loss = 0.18820659816265106\n","Epoch 47: finishing mini batch 366, training error = 0.03125, loss = 0.05798964574933052\n","Epoch 47: finishing mini batch 367, training error = 0.046875, loss = 0.12975150346755981\n","Epoch 47: finishing mini batch 368, training error = 0.015625, loss = 0.07283683866262436\n","Epoch 47: finishing mini batch 369, training error = 0.078125, loss = 0.13233120739459991\n","Epoch 47: finishing mini batch 370, training error = 0.0625, loss = 0.1549515426158905\n","Epoch 47: finishing mini batch 371, training error = 0.03125, loss = 0.0456167496740818\n","Epoch 47: finishing mini batch 372, training error = 0.03125, loss = 0.07923843711614609\n","Epoch 47: finishing mini batch 373, training error = 0.015625, loss = 0.08327232301235199\n","Epoch 47: finishing mini batch 374, training error = 0.046875, loss = 0.08780622482299805\n","Epoch 47: finishing mini batch 375, training error = 0.109375, loss = 0.29550984501838684\n","Epoch 47: finishing mini batch 376, training error = 0.03125, loss = 0.06661020964384079\n","Epoch 47: finishing mini batch 377, training error = 0.046875, loss = 0.15497881174087524\n","Epoch 47: finishing mini batch 378, training error = 0.0, loss = 0.027949640527367592\n","Epoch 47: finishing mini batch 379, training error = 0.015625, loss = 0.07812883704900742\n","Epoch 47: finishing mini batch 380, training error = 0.03125, loss = 0.11157947033643723\n","Epoch 47: finishing mini batch 381, training error = 0.015625, loss = 0.13238303363323212\n","Epoch 47: finishing mini batch 382, training error = 0.046875, loss = 0.08747539669275284\n","Epoch 47: finishing mini batch 383, training error = 0.03125, loss = 0.1451915204524994\n","Epoch 47: finishing mini batch 384, training error = 0.046875, loss = 0.14402927458286285\n","Epoch 47: finishing mini batch 385, training error = 0.046875, loss = 0.09672315418720245\n","Epoch 47: finishing mini batch 386, training error = 0.03125, loss = 0.1057162806391716\n","Epoch 47: finishing mini batch 387, training error = 0.03125, loss = 0.07639255374670029\n","Epoch 47: finishing mini batch 388, training error = 0.015625, loss = 0.037673503160476685\n","Epoch 47: finishing mini batch 389, training error = 0.046875, loss = 0.15983669459819794\n","Epoch 47: finishing mini batch 390, training error = 0.03125, loss = 0.08677686005830765\n","Epoch 47: finishing mini batch 391, training error = 0.015625, loss = 0.07509204745292664\n","Epoch 47: finishing mini batch 392, training error = 0.046875, loss = 0.1427384316921234\n","Epoch 47: finishing mini batch 393, training error = 0.046875, loss = 0.1645226925611496\n","Epoch 47: finishing mini batch 394, training error = 0.046875, loss = 0.11309243738651276\n","Epoch 47: finishing mini batch 395, training error = 0.015625, loss = 0.06326346099376678\n","Epoch 47: finishing mini batch 396, training error = 0.046875, loss = 0.11478552967309952\n","Epoch 47: finishing mini batch 397, training error = 0.0625, loss = 0.125249981880188\n","Epoch 47: finishing mini batch 398, training error = 0.015625, loss = 0.05137684941291809\n","Epoch 47: finishing mini batch 399, training error = 0.0, loss = 0.03212829679250717\n","Epoch 47: finishing mini batch 400, training error = 0.03125, loss = 0.08454540371894836\n","Epoch 47: finishing mini batch 401, training error = 0.046875, loss = 0.08391173183917999\n","Epoch 47: finishing mini batch 402, training error = 0.015625, loss = 0.055059682577848434\n","Epoch 47: finishing mini batch 403, training error = 0.078125, loss = 0.20968694984912872\n","Epoch 47: finishing mini batch 404, training error = 0.015625, loss = 0.05946526303887367\n","Epoch 47: finishing mini batch 405, training error = 0.046875, loss = 0.09933795034885406\n","Epoch 47: finishing mini batch 406, training error = 0.109375, loss = 0.20020072162151337\n","Epoch 47: finishing mini batch 407, training error = 0.03125, loss = 0.08543778955936432\n","Epoch 47: finishing mini batch 408, training error = 0.078125, loss = 0.15043647587299347\n","Epoch 47: finishing mini batch 409, training error = 0.015625, loss = 0.039791058748960495\n","Epoch 47: finishing mini batch 410, training error = 0.046875, loss = 0.12893763184547424\n","Epoch 47: finishing mini batch 411, training error = 0.03125, loss = 0.10674501955509186\n","Epoch 47: finishing mini batch 412, training error = 0.03125, loss = 0.13668464124202728\n","Epoch 47: finishing mini batch 413, training error = 0.03125, loss = 0.07849916815757751\n","Epoch 47: finishing mini batch 414, training error = 0.015625, loss = 0.09402506798505783\n","Epoch 47: finishing mini batch 415, training error = 0.0, loss = 0.05971192568540573\n","Epoch 47: finishing mini batch 416, training error = 0.03125, loss = 0.07866661995649338\n","Epoch 47: finishing mini batch 417, training error = 0.015625, loss = 0.07408379763364792\n","Epoch 47: finishing mini batch 418, training error = 0.015625, loss = 0.06294052302837372\n","Epoch 47: finishing mini batch 419, training error = 0.03125, loss = 0.052711594849824905\n","Epoch 47: finishing mini batch 420, training error = 0.078125, loss = 0.17984126508235931\n","Epoch 47: finishing mini batch 421, training error = 0.015625, loss = 0.06156976893544197\n","Epoch 47: finishing mini batch 422, training error = 0.046875, loss = 0.07752473652362823\n","Epoch 47: finishing mini batch 423, training error = 0.078125, loss = 0.27141135931015015\n","Epoch 47: finishing mini batch 424, training error = 0.09375, loss = 0.20227624475955963\n","Epoch 47: finishing mini batch 425, training error = 0.046875, loss = 0.11620787531137466\n","Epoch 47: finishing mini batch 426, training error = 0.0, loss = 0.019008493050932884\n","Epoch 47: finishing mini batch 427, training error = 0.015625, loss = 0.026189688593149185\n","Epoch 47: finishing mini batch 428, training error = 0.015625, loss = 0.10574992746114731\n","Epoch 47: finishing mini batch 429, training error = 0.0, loss = 0.02644425816833973\n","Epoch 47: finishing mini batch 430, training error = 0.03125, loss = 0.10346752405166626\n","Epoch 47: finishing mini batch 431, training error = 0.046875, loss = 0.13241346180438995\n","Epoch 47: finishing mini batch 432, training error = 0.03125, loss = 0.07954975962638855\n","Epoch 47: finishing mini batch 433, training error = 0.0, loss = 0.04974012449383736\n","Epoch 47: finishing mini batch 434, training error = 0.078125, loss = 0.18710868060588837\n","Epoch 47: finishing mini batch 435, training error = 0.0, loss = 0.049103301018476486\n","Epoch 47: finishing mini batch 436, training error = 0.015625, loss = 0.08149181306362152\n","Epoch 47: finishing mini batch 437, training error = 0.0625, loss = 0.1470583975315094\n","Epoch 47: finishing mini batch 438, training error = 0.03125, loss = 0.11889450997114182\n","Epoch 47: finishing mini batch 439, training error = 0.0625, loss = 0.12160190939903259\n","Epoch 47: finishing mini batch 440, training error = 0.09375, loss = 0.199562206864357\n","Epoch 47: finishing mini batch 441, training error = 0.0625, loss = 0.1173822432756424\n","Epoch 47: finishing mini batch 442, training error = 0.015625, loss = 0.10010378807783127\n","Epoch 47: finishing mini batch 443, training error = 0.03125, loss = 0.09170445054769516\n","Epoch 47: finishing mini batch 444, training error = 0.03125, loss = 0.1115327700972557\n","Epoch 47: finishing mini batch 445, training error = 0.0625, loss = 0.13554805517196655\n","Epoch 47: finishing mini batch 446, training error = 0.03125, loss = 0.13926395773887634\n","Epoch 47: finishing mini batch 447, training error = 0.015625, loss = 0.15730491280555725\n","Epoch 47: finishing mini batch 448, training error = 0.015625, loss = 0.06769271194934845\n","Epoch 47: finishing mini batch 449, training error = 0.078125, loss = 0.15176621079444885\n","Epoch 47: finishing mini batch 450, training error = 0.046875, loss = 0.10494980216026306\n","Epoch 47: finishing mini batch 451, training error = 0.078125, loss = 0.17486587166786194\n","Epoch 47: finishing mini batch 452, training error = 0.015625, loss = 0.06828927248716354\n","Epoch 47: finishing mini batch 453, training error = 0.046875, loss = 0.07778248935937881\n","Epoch 47: finishing mini batch 454, training error = 0.0625, loss = 0.2211502343416214\n","Epoch 47: finishing mini batch 455, training error = 0.015625, loss = 0.040508706122636795\n","Epoch 47: finishing mini batch 456, training error = 0.0625, loss = 0.1427432894706726\n","Epoch 47: finishing mini batch 457, training error = 0.015625, loss = 0.11474217474460602\n","Epoch 47: finishing mini batch 458, training error = 0.046875, loss = 0.16249987483024597\n","Epoch 47: finishing mini batch 459, training error = 0.03125, loss = 0.11195388436317444\n","Epoch 47: finishing mini batch 460, training error = 0.0625, loss = 0.16672223806381226\n","Epoch 47: finishing mini batch 461, training error = 0.015625, loss = 0.06566114723682404\n","Epoch 47: finishing mini batch 462, training error = 0.0, loss = 0.03410962596535683\n","Epoch 47: finishing mini batch 463, training error = 0.03125, loss = 0.1029442772269249\n","Epoch 47: finishing mini batch 464, training error = 0.0625, loss = 0.16046695411205292\n","Epoch 47: finishing mini batch 465, training error = 0.015625, loss = 0.07421006262302399\n","Epoch 47: finishing mini batch 466, training error = 0.09375, loss = 0.22019071877002716\n","Epoch 47: finishing mini batch 467, training error = 0.125, loss = 0.26823997497558594\n","Epoch 47: finishing mini batch 468, training error = 0.078125, loss = 0.20178136229515076\n","Epoch 47: finishing mini batch 469, training error = 0.046875, loss = 0.07433757185935974\n","Epoch 47: finishing mini batch 470, training error = 0.046875, loss = 0.09153758734464645\n","Epoch 47: finishing mini batch 471, training error = 0.046875, loss = 0.1710323840379715\n","Epoch 47: finishing mini batch 472, training error = 0.15625, loss = 0.39275509119033813\n","Epoch 47: finishing mini batch 473, training error = 0.0, loss = 0.01763877272605896\n","Epoch 47: finishing mini batch 474, training error = 0.046875, loss = 0.13557878136634827\n","Epoch 47: finishing mini batch 475, training error = 0.03125, loss = 0.14535178244113922\n","Epoch 47: finishing mini batch 476, training error = 0.03125, loss = 0.09792926907539368\n","Epoch 47: finishing mini batch 477, training error = 0.078125, loss = 0.19269314408302307\n","Epoch 47: finishing mini batch 478, training error = 0.046875, loss = 0.14913880825042725\n","Epoch 47: finishing mini batch 479, training error = 0.078125, loss = 0.3106391131877899\n","Epoch 47: finishing mini batch 480, training error = 0.015625, loss = 0.1648956686258316\n","Epoch 47: finishing mini batch 481, training error = 0.078125, loss = 0.21519002318382263\n","Epoch 47: finishing mini batch 482, training error = 0.078125, loss = 0.18014155328273773\n","Epoch 47: finishing mini batch 483, training error = 0.046875, loss = 0.1316879540681839\n","Epoch 47: finishing mini batch 484, training error = 0.015625, loss = 0.05677250400185585\n","Epoch 47: finishing mini batch 485, training error = 0.0625, loss = 0.14639180898666382\n","Epoch 47: finishing mini batch 486, training error = 0.03125, loss = 0.1195693090558052\n","Epoch 47: finishing mini batch 487, training error = 0.0625, loss = 0.23415341973304749\n","Epoch 47: finishing mini batch 488, training error = 0.046875, loss = 0.14366155862808228\n","Epoch 47: finishing mini batch 489, training error = 0.109375, loss = 0.3407703936100006\n","Epoch 47: finishing mini batch 490, training error = 0.03125, loss = 0.06817012280225754\n","Epoch 47: finishing mini batch 491, training error = 0.078125, loss = 0.19662217795848846\n","Epoch 47: finishing mini batch 492, training error = 0.015625, loss = 0.08582506328821182\n","Epoch 47: finishing mini batch 493, training error = 0.0625, loss = 0.2634285092353821\n","Epoch 47: finishing mini batch 494, training error = 0.046875, loss = 0.12577177584171295\n","Epoch 47: finishing mini batch 495, training error = 0.0625, loss = 0.09116087853908539\n","Epoch 47: finishing mini batch 496, training error = 0.09375, loss = 0.16268379986286163\n","Epoch 47: finishing mini batch 497, training error = 0.078125, loss = 0.14848919212818146\n","Epoch 47: finishing mini batch 498, training error = 0.109375, loss = 0.26768985390663147\n","Epoch 47: finishing mini batch 499, training error = 0.078125, loss = 0.14490775763988495\n","Epoch 47: finishing mini batch 500, training error = 0.03125, loss = 0.10176735371351242\n","Epoch 47: finishing mini batch 501, training error = 0.0625, loss = 0.13746710121631622\n","Epoch 47: finishing mini batch 502, training error = 0.09375, loss = 0.17140838503837585\n","Epoch 47: finishing mini batch 503, training error = 0.015625, loss = 0.11339747160673141\n","Epoch 47: finishing mini batch 504, training error = 0.0625, loss = 0.18334588408470154\n","Epoch 47: finishing mini batch 505, training error = 0.015625, loss = 0.07164450734853745\n","Epoch 47: finishing mini batch 506, training error = 0.0625, loss = 0.19477665424346924\n","Epoch 47: finishing mini batch 507, training error = 0.078125, loss = 0.2528029978275299\n","Epoch 47: finishing mini batch 508, training error = 0.0, loss = 0.025431398302316666\n","Epoch 47: finishing mini batch 509, training error = 0.0625, loss = 0.18725109100341797\n","Epoch 47: finishing mini batch 510, training error = 0.078125, loss = 0.17001749575138092\n","Epoch 47: finishing mini batch 511, training error = 0.03125, loss = 0.08099819719791412\n","Epoch 47: finishing mini batch 512, training error = 0.046875, loss = 0.20936235785484314\n","Epoch 47: finishing mini batch 513, training error = 0.015625, loss = 0.08880335092544556\n","Epoch 47: finishing mini batch 514, training error = 0.03125, loss = 0.09797070920467377\n","Epoch 47: finishing mini batch 515, training error = 0.03125, loss = 0.09390410035848618\n","Epoch 47: finishing mini batch 516, training error = 0.0625, loss = 0.14421086013317108\n","Epoch 47: finishing mini batch 517, training error = 0.015625, loss = 0.07596230506896973\n","Epoch 47: finishing mini batch 518, training error = 0.078125, loss = 0.2459544539451599\n","Epoch 47: finishing mini batch 519, training error = 0.0625, loss = 0.1482411026954651\n","Epoch 47: finishing mini batch 520, training error = 0.078125, loss = 0.23767948150634766\n","Epoch 47: finishing mini batch 521, training error = 0.046875, loss = 0.09338799118995667\n","Epoch 47: finishing mini batch 522, training error = 0.046875, loss = 0.14614945650100708\n","Epoch 47: finishing mini batch 523, training error = 0.0, loss = 0.012639014981687069\n","Epoch 47: finishing mini batch 524, training error = 0.0625, loss = 0.1595492660999298\n","Epoch 47: finishing mini batch 525, training error = 0.03125, loss = 0.13454705476760864\n","Epoch 47: finishing mini batch 526, training error = 0.0625, loss = 0.23444432020187378\n","Epoch 47: finishing mini batch 527, training error = 0.09375, loss = 0.1565796285867691\n","Epoch 47: finishing mini batch 528, training error = 0.09375, loss = 0.2226763814687729\n","Epoch 47: finishing mini batch 529, training error = 0.03125, loss = 0.14400440454483032\n","Epoch 47: finishing mini batch 530, training error = 0.0625, loss = 0.14362522959709167\n","Epoch 47: finishing mini batch 531, training error = 0.03125, loss = 0.10205826163291931\n","Epoch 47: finishing mini batch 532, training error = 0.0625, loss = 0.12527458369731903\n","Epoch 47: finishing mini batch 533, training error = 0.03125, loss = 0.13964015245437622\n","Epoch 47: finishing mini batch 534, training error = 0.03125, loss = 0.09596284478902817\n","Epoch 47: finishing mini batch 535, training error = 0.046875, loss = 0.09954992681741714\n","Epoch 47: finishing mini batch 536, training error = 0.046875, loss = 0.14092499017715454\n","Epoch 47: finishing mini batch 537, training error = 0.015625, loss = 0.10936731100082397\n","Epoch 47: finishing mini batch 538, training error = 0.046875, loss = 0.13428737223148346\n","Epoch 47: finishing mini batch 539, training error = 0.0625, loss = 0.19202373921871185\n","Epoch 47: finishing mini batch 540, training error = 0.03125, loss = 0.23846940696239471\n","Epoch 47: finishing mini batch 541, training error = 0.046875, loss = 0.2048211246728897\n","Epoch 47: finishing mini batch 542, training error = 0.03125, loss = 0.11783803999423981\n","Epoch 47: finishing mini batch 543, training error = 0.046875, loss = 0.15494759380817413\n","Epoch 47: finishing mini batch 544, training error = 0.03125, loss = 0.05689423903822899\n","Epoch 47: finishing mini batch 545, training error = 0.046875, loss = 0.0918181836605072\n","Epoch 47: finishing mini batch 546, training error = 0.03125, loss = 0.07353868335485458\n","Epoch 47: finishing mini batch 547, training error = 0.046875, loss = 0.17112843692302704\n","Epoch 47: finishing mini batch 548, training error = 0.046875, loss = 0.1571231633424759\n","Epoch 47: finishing mini batch 549, training error = 0.046875, loss = 0.15466554462909698\n","Epoch 47: finishing mini batch 550, training error = 0.03125, loss = 0.08460133522748947\n","Epoch 47: finishing mini batch 551, training error = 0.046875, loss = 0.11483928561210632\n","Epoch 47: finishing mini batch 552, training error = 0.03125, loss = 0.07763009518384933\n","Epoch 47: finishing mini batch 553, training error = 0.0, loss = 0.04030981287360191\n","Epoch 47: finishing mini batch 554, training error = 0.046875, loss = 0.156098872423172\n","Epoch 47: finishing mini batch 555, training error = 0.015625, loss = 0.10246546566486359\n","Epoch 47: finishing mini batch 556, training error = 0.046875, loss = 0.1182817816734314\n","Epoch 47: finishing mini batch 557, training error = 0.0625, loss = 0.168887659907341\n","Epoch 47: finishing mini batch 558, training error = 0.015625, loss = 0.05315793678164482\n","Epoch 47: finishing mini batch 559, training error = 0.046875, loss = 0.10115062445402145\n","Epoch 47: finishing mini batch 560, training error = 0.0625, loss = 0.12115132063627243\n","Epoch 47: finishing mini batch 561, training error = 0.015625, loss = 0.08796705305576324\n","Epoch 47: finishing mini batch 562, training error = 0.046875, loss = 0.11266917735338211\n","Epoch 47: finishing mini batch 563, training error = 0.046875, loss = 0.19679979979991913\n","Epoch 47: finishing mini batch 564, training error = 0.078125, loss = 0.1292649656534195\n","Epoch 47: finishing mini batch 565, training error = 0.046875, loss = 0.17728812992572784\n","Epoch 47: finishing mini batch 566, training error = 0.0625, loss = 0.134868323802948\n","Epoch 47: finishing mini batch 567, training error = 0.046875, loss = 0.18976400792598724\n","Epoch 47: finishing mini batch 568, training error = 0.046875, loss = 0.07931774854660034\n","Epoch 47: finishing mini batch 569, training error = 0.015625, loss = 0.06297942250967026\n","Epoch 47: finishing mini batch 570, training error = 0.078125, loss = 0.2112644761800766\n","Epoch 47: finishing mini batch 571, training error = 0.078125, loss = 0.1924319565296173\n","Epoch 47: finishing mini batch 572, training error = 0.015625, loss = 0.04742465168237686\n","Epoch 47: finishing mini batch 573, training error = 0.078125, loss = 0.17774321138858795\n","Epoch 47: finishing mini batch 574, training error = 0.03125, loss = 0.11621657013893127\n","Epoch 47: finishing mini batch 575, training error = 0.0625, loss = 0.13064901530742645\n","Epoch 47: finishing mini batch 576, training error = 0.0, loss = 0.03476843982934952\n","Epoch 47: finishing mini batch 577, training error = 0.046875, loss = 0.13242925703525543\n","Epoch 47: finishing mini batch 578, training error = 0.046875, loss = 0.1510610282421112\n","Epoch 47: finishing mini batch 579, training error = 0.03125, loss = 0.07682986557483673\n","Epoch 47: finishing mini batch 580, training error = 0.046875, loss = 0.13579410314559937\n","Epoch 47: finishing mini batch 581, training error = 0.0625, loss = 0.162937730550766\n","Epoch 47: finishing mini batch 582, training error = 0.015625, loss = 0.04121996462345123\n","Epoch 47: finishing mini batch 583, training error = 0.03125, loss = 0.10936213284730911\n","Epoch 47: finishing mini batch 584, training error = 0.03125, loss = 0.12598015367984772\n","Epoch 47: finishing mini batch 585, training error = 0.09375, loss = 0.28092193603515625\n","Epoch 47: finishing mini batch 586, training error = 0.125, loss = 0.373954176902771\n","Epoch 47: finishing mini batch 587, training error = 0.0625, loss = 0.14556670188903809\n","Epoch 47: finishing mini batch 588, training error = 0.046875, loss = 0.12298867106437683\n","Epoch 47: finishing mini batch 589, training error = 0.015625, loss = 0.06416863203048706\n","Epoch 47: finishing mini batch 590, training error = 0.0625, loss = 0.2071371227502823\n","Epoch 47: finishing mini batch 591, training error = 0.03125, loss = 0.08755144476890564\n","Epoch 47: finishing mini batch 592, training error = 0.0625, loss = 0.13885091245174408\n","Epoch 47: finishing mini batch 593, training error = 0.046875, loss = 0.19606471061706543\n","Epoch 47: finishing mini batch 594, training error = 0.0625, loss = 0.2566234767436981\n","Epoch 47: finishing mini batch 595, training error = 0.078125, loss = 0.17507591843605042\n","Epoch 47: finishing mini batch 596, training error = 0.03125, loss = 0.13004779815673828\n","Epoch 47: finishing mini batch 597, training error = 0.015625, loss = 0.11818665266036987\n","Epoch 47: finishing mini batch 598, training error = 0.078125, loss = 0.17504549026489258\n","Epoch 47: finishing mini batch 599, training error = 0.015625, loss = 0.05643509328365326\n","Epoch 47: finishing mini batch 600, training error = 0.0, loss = 0.05067787319421768\n","Epoch 47: finishing mini batch 601, training error = 0.0625, loss = 0.2582889795303345\n","Epoch 47: finishing mini batch 602, training error = 0.078125, loss = 0.22429153323173523\n","Epoch 47: finishing mini batch 603, training error = 0.109375, loss = 0.17637337744235992\n","Epoch 47: finishing mini batch 604, training error = 0.078125, loss = 0.18153083324432373\n","Epoch 47: finishing mini batch 605, training error = 0.09375, loss = 0.2081611305475235\n","Epoch 47: finishing mini batch 606, training error = 0.046875, loss = 0.12315382063388824\n","Epoch 47: finishing mini batch 607, training error = 0.078125, loss = 0.16465215384960175\n","Epoch 47: finishing mini batch 608, training error = 0.046875, loss = 0.11308322846889496\n","Epoch 47: finishing mini batch 609, training error = 0.046875, loss = 0.10068488866090775\n","Epoch 47: finishing mini batch 610, training error = 0.03125, loss = 0.06676577776670456\n","Epoch 47: finishing mini batch 611, training error = 0.03125, loss = 0.0831838995218277\n","Epoch 47: finishing mini batch 612, training error = 0.015625, loss = 0.1424427628517151\n","Epoch 47: finishing mini batch 613, training error = 0.046875, loss = 0.1459956169128418\n","Epoch 47: finishing mini batch 614, training error = 0.078125, loss = 0.22341817617416382\n","Epoch 47: finishing mini batch 615, training error = 0.046875, loss = 0.10428041964769363\n","Epoch 47: finishing mini batch 616, training error = 0.0625, loss = 0.11024950444698334\n","Epoch 47: finishing mini batch 617, training error = 0.0625, loss = 0.22551995515823364\n","Epoch 47: finishing mini batch 618, training error = 0.03125, loss = 0.0734463781118393\n","Epoch 47: finishing mini batch 619, training error = 0.03125, loss = 0.07658383250236511\n","Epoch 47: finishing mini batch 620, training error = 0.046875, loss = 0.1186363473534584\n","Epoch 47: finishing mini batch 621, training error = 0.03125, loss = 0.09520359337329865\n","Epoch 47: finishing mini batch 622, training error = 0.03125, loss = 0.07583796977996826\n","Epoch 47: finishing mini batch 623, training error = 0.0625, loss = 0.16148416697978973\n","Epoch 47: finishing mini batch 624, training error = 0.0625, loss = 0.17907683551311493\n","Epoch 47: finishing mini batch 625, training error = 0.03125, loss = 0.09980355948209763\n","Epoch 47: finishing mini batch 626, training error = 0.046875, loss = 0.16931231319904327\n","Epoch 47: finishing mini batch 627, training error = 0.078125, loss = 0.21959257125854492\n","Epoch 47: finishing mini batch 628, training error = 0.03125, loss = 0.11664162576198578\n","Epoch 47: finishing mini batch 629, training error = 0.078125, loss = 0.20416250824928284\n","Epoch 47: finishing mini batch 630, training error = 0.046875, loss = 0.12764345109462738\n","Epoch 47: finishing mini batch 631, training error = 0.078125, loss = 0.2362326979637146\n","Epoch 47: finishing mini batch 632, training error = 0.046875, loss = 0.09279552847146988\n","Epoch 47: finishing mini batch 633, training error = 0.03125, loss = 0.0725569948554039\n","Epoch 47: finishing mini batch 634, training error = 0.0625, loss = 0.10472744703292847\n","Epoch 47: finishing mini batch 635, training error = 0.109375, loss = 0.27727410197257996\n","Epoch 47: finishing mini batch 636, training error = 0.046875, loss = 0.14907206594944\n","Epoch 47: finishing mini batch 637, training error = 0.03125, loss = 0.10411420464515686\n","Epoch 47: finishing mini batch 638, training error = 0.015625, loss = 0.05424121767282486\n","Epoch 47: finishing mini batch 639, training error = 0.046875, loss = 0.11259102076292038\n","Epoch 47: finishing mini batch 640, training error = 0.0, loss = 0.06268196552991867\n","Epoch 47: finishing mini batch 641, training error = 0.09375, loss = 0.17203451693058014\n","Epoch 47: finishing mini batch 642, training error = 0.046875, loss = 0.0971401035785675\n","Epoch 47: finishing mini batch 643, training error = 0.0625, loss = 0.19769561290740967\n","Epoch 47: finishing mini batch 644, training error = 0.046875, loss = 0.1288144439458847\n","Epoch 47: finishing mini batch 645, training error = 0.078125, loss = 0.17570748925209045\n","Epoch 47: finishing mini batch 646, training error = 0.03125, loss = 0.1385740339756012\n","Epoch 47: finishing mini batch 647, training error = 0.046875, loss = 0.1150030791759491\n","Epoch 47: finishing mini batch 648, training error = 0.0, loss = 0.0471467487514019\n","Epoch 47: finishing mini batch 649, training error = 0.03125, loss = 0.10211927443742752\n","Epoch 47: finishing mini batch 650, training error = 0.0625, loss = 0.1563991904258728\n","Epoch 47: finishing mini batch 651, training error = 0.0, loss = 0.02052522823214531\n","Epoch 47: finishing mini batch 652, training error = 0.078125, loss = 0.2322646528482437\n","Epoch 47: finishing mini batch 653, training error = 0.046875, loss = 0.11460502445697784\n","Epoch 47: finishing mini batch 654, training error = 0.03125, loss = 0.07431063055992126\n","Epoch 47: finishing mini batch 655, training error = 0.0, loss = 0.057029739022254944\n","Epoch 47: finishing mini batch 656, training error = 0.0, loss = 0.019040828570723534\n","Epoch 47: finishing mini batch 657, training error = 0.046875, loss = 0.10231687128543854\n","Epoch 47: finishing mini batch 658, training error = 0.0625, loss = 0.1742503046989441\n","Epoch 47: finishing mini batch 659, training error = 0.046875, loss = 0.18533959984779358\n","Epoch 47: finishing mini batch 660, training error = 0.015625, loss = 0.11011293530464172\n","Epoch 47: finishing mini batch 661, training error = 0.03125, loss = 0.11093088984489441\n","Epoch 47: finishing mini batch 662, training error = 0.09375, loss = 0.23554810881614685\n","Epoch 47: finishing mini batch 663, training error = 0.046875, loss = 0.0913408100605011\n","Epoch 47: finishing mini batch 664, training error = 0.03125, loss = 0.07479555159807205\n","Epoch 47: finishing mini batch 665, training error = 0.03125, loss = 0.12824514508247375\n","Epoch 47: finishing mini batch 666, training error = 0.078125, loss = 0.12529978156089783\n","Epoch 47: finishing mini batch 667, training error = 0.0625, loss = 0.1108229011297226\n","Epoch 47: finishing mini batch 668, training error = 0.046875, loss = 0.11203339695930481\n","Epoch 47: finishing mini batch 669, training error = 0.0625, loss = 0.1350947916507721\n","Epoch 47: finishing mini batch 670, training error = 0.0625, loss = 0.12442681938409805\n","Epoch 47: finishing mini batch 671, training error = 0.03125, loss = 0.12928545475006104\n","Epoch 47: finishing mini batch 672, training error = 0.0625, loss = 0.15354447066783905\n","Epoch 47: finishing mini batch 673, training error = 0.03125, loss = 0.14781594276428223\n","Epoch 47: finishing mini batch 674, training error = 0.046875, loss = 0.1398048847913742\n","Epoch 47: finishing mini batch 675, training error = 0.078125, loss = 0.18924832344055176\n","Epoch 47: finishing mini batch 676, training error = 0.078125, loss = 0.199211984872818\n","Epoch 47: finishing mini batch 677, training error = 0.078125, loss = 0.2840578854084015\n","Epoch 47: finishing mini batch 678, training error = 0.0625, loss = 0.22524869441986084\n","Epoch 47: finishing mini batch 679, training error = 0.046875, loss = 0.06744638830423355\n","Epoch 47: finishing mini batch 680, training error = 0.015625, loss = 0.16101908683776855\n","Epoch 47: finishing mini batch 681, training error = 0.03125, loss = 0.13732650876045227\n","Epoch 47: finishing mini batch 682, training error = 0.03125, loss = 0.0770532563328743\n","Epoch 47: finishing mini batch 683, training error = 0.015625, loss = 0.05493256822228432\n","Epoch 47: finishing mini batch 684, training error = 0.078125, loss = 0.22331295907497406\n","Epoch 47: finishing mini batch 685, training error = 0.03125, loss = 0.11363010853528976\n","Epoch 47: finishing mini batch 686, training error = 0.078125, loss = 0.15066207945346832\n","Epoch 47: finishing mini batch 687, training error = 0.078125, loss = 0.2674831748008728\n","Epoch 47: finishing mini batch 688, training error = 0.0625, loss = 0.13338257372379303\n","Epoch 47: finishing mini batch 689, training error = 0.03125, loss = 0.11289925873279572\n","Epoch 47: finishing mini batch 690, training error = 0.046875, loss = 0.13274921476840973\n","Epoch 47: finishing mini batch 691, training error = 0.0, loss = 0.025815356522798538\n","Epoch 47: finishing mini batch 692, training error = 0.078125, loss = 0.10690775513648987\n","Epoch 47: finishing mini batch 693, training error = 0.046875, loss = 0.0776577815413475\n","Epoch 47: finishing mini batch 694, training error = 0.015625, loss = 0.0805714800953865\n","Epoch 47: finishing mini batch 695, training error = 0.078125, loss = 0.1997319459915161\n","Epoch 47: finishing mini batch 696, training error = 0.09375, loss = 0.31298840045928955\n","Epoch 47: finishing mini batch 697, training error = 0.078125, loss = 0.28945645689964294\n","Epoch 47: finishing mini batch 698, training error = 0.0625, loss = 0.16208380460739136\n","Epoch 47: finishing mini batch 699, training error = 0.015625, loss = 0.10067956149578094\n","Epoch 47: finishing mini batch 700, training error = 0.046875, loss = 0.08269814401865005\n","Epoch 47: finishing mini batch 701, training error = 0.078125, loss = 0.1924877017736435\n","Epoch 47: finishing mini batch 702, training error = 0.0625, loss = 0.20317532122135162\n","Epoch 47: finishing mini batch 703, training error = 0.046875, loss = 0.10329008102416992\n","Epoch 47: finishing mini batch 704, training error = 0.03125, loss = 0.08666890859603882\n","Epoch 47: finishing mini batch 705, training error = 0.015625, loss = 0.04702794924378395\n","Epoch 47: finishing mini batch 706, training error = 0.03125, loss = 0.09624883532524109\n","Epoch 47: finishing mini batch 707, training error = 0.03125, loss = 0.07257379591464996\n","Epoch 47: finishing mini batch 708, training error = 0.03125, loss = 0.20611833035945892\n","Epoch 47: finishing mini batch 709, training error = 0.015625, loss = 0.07430168241262436\n","Epoch 47: finishing mini batch 710, training error = 0.015625, loss = 0.0566750094294548\n","Epoch 47: finishing mini batch 711, training error = 0.015625, loss = 0.05199453607201576\n","Epoch 47: finishing mini batch 712, training error = 0.078125, loss = 0.15889765322208405\n","Epoch 47: finishing mini batch 713, training error = 0.03125, loss = 0.07102319598197937\n","Epoch 47: finishing mini batch 714, training error = 0.03125, loss = 0.06450443714857101\n","Epoch 47: finishing mini batch 715, training error = 0.09375, loss = 0.22850818932056427\n","Epoch 47: finishing mini batch 716, training error = 0.03125, loss = 0.16463658213615417\n","Epoch 47: finishing mini batch 717, training error = 0.03125, loss = 0.11494069546461105\n","Epoch 47: finishing mini batch 718, training error = 0.078125, loss = 0.20389720797538757\n","Epoch 47: finishing mini batch 719, training error = 0.109375, loss = 0.2481108158826828\n","Epoch 47: finishing mini batch 720, training error = 0.0625, loss = 0.10791987180709839\n","Epoch 47: finishing mini batch 721, training error = 0.03125, loss = 0.1708904206752777\n","Epoch 47: finishing mini batch 722, training error = 0.046875, loss = 0.10217897593975067\n","Epoch 47: finishing mini batch 723, training error = 0.03125, loss = 0.07577405869960785\n","Epoch 47: finishing mini batch 724, training error = 0.046875, loss = 0.09015127271413803\n","Epoch 47: finishing mini batch 725, training error = 0.046875, loss = 0.08684833347797394\n","Epoch 47: finishing mini batch 726, training error = 0.078125, loss = 0.2561624050140381\n","Epoch 47: finishing mini batch 727, training error = 0.078125, loss = 0.27716314792633057\n","Epoch 47: finishing mini batch 728, training error = 0.09375, loss = 0.18521904945373535\n","Epoch 47: finishing mini batch 729, training error = 0.109375, loss = 0.2508031725883484\n","Epoch 47: finishing mini batch 730, training error = 0.078125, loss = 0.22870385646820068\n","Epoch 47: finishing mini batch 731, training error = 0.09375, loss = 0.19617223739624023\n","Epoch 47: finishing mini batch 732, training error = 0.03125, loss = 0.10735547542572021\n","Epoch 47: finishing mini batch 733, training error = 0.03125, loss = 0.09358186274766922\n","Epoch 47: finishing mini batch 734, training error = 0.046875, loss = 0.11033327877521515\n","Epoch 47: finishing mini batch 735, training error = 0.015625, loss = 0.07605753093957901\n","Epoch 47: finishing mini batch 736, training error = 0.046875, loss = 0.103133425116539\n","Epoch 47: finishing mini batch 737, training error = 0.015625, loss = 0.08434408158063889\n","Epoch 47: finishing mini batch 738, training error = 0.015625, loss = 0.04810893535614014\n","Epoch 47: finishing mini batch 739, training error = 0.03125, loss = 0.12007120251655579\n","Epoch 47: finishing mini batch 740, training error = 0.015625, loss = 0.058299724012613297\n","Epoch 47: finishing mini batch 741, training error = 0.03125, loss = 0.10138045251369476\n","Epoch 47: finishing mini batch 742, training error = 0.0625, loss = 0.17237797379493713\n","Epoch 47: finishing mini batch 743, training error = 0.09375, loss = 0.21069517731666565\n","Epoch 47: finishing mini batch 744, training error = 0.046875, loss = 0.24584195017814636\n","Epoch 47: finishing mini batch 745, training error = 0.078125, loss = 0.2085489183664322\n","Epoch 47: finishing mini batch 746, training error = 0.0625, loss = 0.2015964686870575\n","Epoch 47: finishing mini batch 747, training error = 0.0, loss = 0.03182978183031082\n","Epoch 47: finishing mini batch 748, training error = 0.0625, loss = 0.19036643207073212\n","Epoch 47: finishing mini batch 749, training error = 0.046875, loss = 0.11966522783041\n","Epoch 47: finishing mini batch 750, training error = 0.03125, loss = 0.09663388133049011\n","Epoch 47: finishing mini batch 751, training error = 0.03125, loss = 0.09721505641937256\n","Epoch 47: finishing mini batch 752, training error = 0.0625, loss = 0.21245171129703522\n","Epoch 47: finishing mini batch 753, training error = 0.015625, loss = 0.1196833923459053\n","Epoch 47: finishing mini batch 754, training error = 0.046875, loss = 0.07602593302726746\n","Epoch 47: finishing mini batch 755, training error = 0.046875, loss = 0.0925256609916687\n","Epoch 47: finishing mini batch 756, training error = 0.03125, loss = 0.09615623205900192\n","Epoch 47: finishing mini batch 757, training error = 0.0625, loss = 0.192501038312912\n","Epoch 47: finishing mini batch 758, training error = 0.015625, loss = 0.03920264169573784\n","Epoch 47: finishing mini batch 759, training error = 0.0, loss = 0.05059095099568367\n","Epoch 47: finishing mini batch 760, training error = 0.0625, loss = 0.20000438392162323\n","Epoch 47: finishing mini batch 761, training error = 0.09375, loss = 0.18269199132919312\n","Epoch 47: finishing mini batch 762, training error = 0.0, loss = 0.07609330117702484\n","Epoch 47: finishing mini batch 763, training error = 0.03125, loss = 0.12158625572919846\n","Epoch 47: finishing mini batch 764, training error = 0.046875, loss = 0.09354650974273682\n","Epoch 47: finishing mini batch 765, training error = 0.046875, loss = 0.10944969952106476\n","Epoch 47: finishing mini batch 766, training error = 0.03125, loss = 0.0980888307094574\n","Epoch 47: finishing mini batch 767, training error = 0.0625, loss = 0.1744392216205597\n","Epoch 47: finishing mini batch 768, training error = 0.046875, loss = 0.1659434586763382\n","Epoch 47: finishing mini batch 769, training error = 0.015625, loss = 0.07786567509174347\n","Epoch 47: finishing mini batch 770, training error = 0.03125, loss = 0.1003497838973999\n","Epoch 47: finishing mini batch 771, training error = 0.078125, loss = 0.14589446783065796\n","Epoch 47: finishing mini batch 772, training error = 0.078125, loss = 0.34729182720184326\n","Epoch 47: finishing mini batch 773, training error = 0.046875, loss = 0.13597172498703003\n","Epoch 47: finishing mini batch 774, training error = 0.046875, loss = 0.08808104693889618\n","Epoch 47: finishing mini batch 775, training error = 0.0625, loss = 0.1613580882549286\n","Epoch 47: finishing mini batch 776, training error = 0.0625, loss = 0.12783169746398926\n","Epoch 47: finishing mini batch 777, training error = 0.0625, loss = 0.14548702538013458\n","Epoch 47: finishing mini batch 778, training error = 0.015625, loss = 0.07212991267442703\n","Epoch 47: finishing mini batch 779, training error = 0.109375, loss = 0.3226569890975952\n","Epoch 47: finishing mini batch 780, training error = 0.0625, loss = 0.29321613907814026\n","Epoch 47: finishing mini batch 781, training error = 0.03125, loss = 0.10079289227724075\n","Epoch 47: finishing mini batch 782, training error = 0.0625, loss = 0.4862150549888611\n","Epoch 47 completed, acc_loss = 93.73265647608787\n","Starting epoch 48...\n","Epoch 48: finishing mini batch 1, training error = 0.015625, loss = 0.10041709244251251\n","Epoch 48: finishing mini batch 2, training error = 0.046875, loss = 0.16449017822742462\n","Epoch 48: finishing mini batch 3, training error = 0.0, loss = 0.04025685787200928\n","Epoch 48: finishing mini batch 4, training error = 0.03125, loss = 0.06341692805290222\n","Epoch 48: finishing mini batch 5, training error = 0.09375, loss = 0.3782155513763428\n","Epoch 48: finishing mini batch 6, training error = 0.046875, loss = 0.15000949800014496\n","Epoch 48: finishing mini batch 7, training error = 0.078125, loss = 0.2427663654088974\n","Epoch 48: finishing mini batch 8, training error = 0.0625, loss = 0.1604088991880417\n","Epoch 48: finishing mini batch 9, training error = 0.0625, loss = 0.2732039988040924\n","Epoch 48: finishing mini batch 10, training error = 0.078125, loss = 0.21651488542556763\n","Epoch 48: finishing mini batch 11, training error = 0.078125, loss = 0.22412839531898499\n","Epoch 48: finishing mini batch 12, training error = 0.0625, loss = 0.1543194055557251\n","Epoch 48: finishing mini batch 13, training error = 0.046875, loss = 0.0685000941157341\n","Epoch 48: finishing mini batch 14, training error = 0.078125, loss = 0.23066836595535278\n","Epoch 48: finishing mini batch 15, training error = 0.0625, loss = 0.1503269523382187\n","Epoch 48: finishing mini batch 16, training error = 0.046875, loss = 0.12433501332998276\n","Epoch 48: finishing mini batch 17, training error = 0.109375, loss = 0.3037983179092407\n","Epoch 48: finishing mini batch 18, training error = 0.03125, loss = 0.13258571922779083\n","Epoch 48: finishing mini batch 19, training error = 0.078125, loss = 0.26754873991012573\n","Epoch 48: finishing mini batch 20, training error = 0.046875, loss = 0.11507219076156616\n","Epoch 48: finishing mini batch 21, training error = 0.0625, loss = 0.12741026282310486\n","Epoch 48: finishing mini batch 22, training error = 0.046875, loss = 0.12512391805648804\n","Epoch 48: finishing mini batch 23, training error = 0.046875, loss = 0.1044241189956665\n","Epoch 48: finishing mini batch 24, training error = 0.03125, loss = 0.0913407951593399\n","Epoch 48: finishing mini batch 25, training error = 0.015625, loss = 0.07092843949794769\n","Epoch 48: finishing mini batch 26, training error = 0.0625, loss = 0.1703387200832367\n","Epoch 48: finishing mini batch 27, training error = 0.078125, loss = 0.2621607184410095\n","Epoch 48: finishing mini batch 28, training error = 0.03125, loss = 0.06246175244450569\n","Epoch 48: finishing mini batch 29, training error = 0.0625, loss = 0.16081665456295013\n","Epoch 48: finishing mini batch 30, training error = 0.03125, loss = 0.07892859727144241\n","Epoch 48: finishing mini batch 31, training error = 0.0625, loss = 0.15882794559001923\n","Epoch 48: finishing mini batch 32, training error = 0.03125, loss = 0.13046008348464966\n","Epoch 48: finishing mini batch 33, training error = 0.0625, loss = 0.09607553482055664\n","Epoch 48: finishing mini batch 34, training error = 0.078125, loss = 0.20902663469314575\n","Epoch 48: finishing mini batch 35, training error = 0.046875, loss = 0.09958583861589432\n","Epoch 48: finishing mini batch 36, training error = 0.0, loss = 0.06286396831274033\n","Epoch 48: finishing mini batch 37, training error = 0.015625, loss = 0.07398735731840134\n","Epoch 48: finishing mini batch 38, training error = 0.109375, loss = 0.20204676687717438\n","Epoch 48: finishing mini batch 39, training error = 0.046875, loss = 0.09823621809482574\n","Epoch 48: finishing mini batch 40, training error = 0.046875, loss = 0.14048528671264648\n","Epoch 48: finishing mini batch 41, training error = 0.0, loss = 0.036217134445905685\n","Epoch 48: finishing mini batch 42, training error = 0.015625, loss = 0.062066610902547836\n","Epoch 48: finishing mini batch 43, training error = 0.09375, loss = 0.2751729190349579\n","Epoch 48: finishing mini batch 44, training error = 0.078125, loss = 0.22819934785366058\n","Epoch 48: finishing mini batch 45, training error = 0.0, loss = 0.05441899225115776\n","Epoch 48: finishing mini batch 46, training error = 0.046875, loss = 0.124226875603199\n","Epoch 48: finishing mini batch 47, training error = 0.015625, loss = 0.11128565669059753\n","Epoch 48: finishing mini batch 48, training error = 0.03125, loss = 0.09103382378816605\n","Epoch 48: finishing mini batch 49, training error = 0.0625, loss = 0.2324395328760147\n","Epoch 48: finishing mini batch 50, training error = 0.046875, loss = 0.13138990104198456\n","Epoch 48: finishing mini batch 51, training error = 0.09375, loss = 0.27564242482185364\n","Epoch 48: finishing mini batch 52, training error = 0.046875, loss = 0.1352882981300354\n","Epoch 48: finishing mini batch 53, training error = 0.046875, loss = 0.11150487512350082\n","Epoch 48: finishing mini batch 54, training error = 0.0, loss = 0.03974176198244095\n","Epoch 48: finishing mini batch 55, training error = 0.0625, loss = 0.131700798869133\n","Epoch 48: finishing mini batch 56, training error = 0.0, loss = 0.06292437762022018\n","Epoch 48: finishing mini batch 57, training error = 0.046875, loss = 0.12348280847072601\n","Epoch 48: finishing mini batch 58, training error = 0.0, loss = 0.031592581421136856\n","Epoch 48: finishing mini batch 59, training error = 0.0, loss = 0.03060838207602501\n","Epoch 48: finishing mini batch 60, training error = 0.046875, loss = 0.12262623012065887\n","Epoch 48: finishing mini batch 61, training error = 0.015625, loss = 0.06585858762264252\n","Epoch 48: finishing mini batch 62, training error = 0.0625, loss = 0.18227426707744598\n","Epoch 48: finishing mini batch 63, training error = 0.09375, loss = 0.25795772671699524\n","Epoch 48: finishing mini batch 64, training error = 0.03125, loss = 0.06719288975000381\n","Epoch 48: finishing mini batch 65, training error = 0.0, loss = 0.054793115705251694\n","Epoch 48: finishing mini batch 66, training error = 0.015625, loss = 0.05972471833229065\n","Epoch 48: finishing mini batch 67, training error = 0.0625, loss = 0.2627742886543274\n","Epoch 48: finishing mini batch 68, training error = 0.015625, loss = 0.05380922555923462\n","Epoch 48: finishing mini batch 69, training error = 0.015625, loss = 0.05430178716778755\n","Epoch 48: finishing mini batch 70, training error = 0.046875, loss = 0.12299486994743347\n","Epoch 48: finishing mini batch 71, training error = 0.046875, loss = 0.12549686431884766\n","Epoch 48: finishing mini batch 72, training error = 0.015625, loss = 0.04435097426176071\n","Epoch 48: finishing mini batch 73, training error = 0.09375, loss = 0.17806367576122284\n","Epoch 48: finishing mini batch 74, training error = 0.03125, loss = 0.10825087130069733\n","Epoch 48: finishing mini batch 75, training error = 0.03125, loss = 0.08553653955459595\n","Epoch 48: finishing mini batch 76, training error = 0.09375, loss = 0.15458329021930695\n","Epoch 48: finishing mini batch 77, training error = 0.0, loss = 0.0357208251953125\n","Epoch 48: finishing mini batch 78, training error = 0.09375, loss = 0.22248528897762299\n","Epoch 48: finishing mini batch 79, training error = 0.046875, loss = 0.13311772048473358\n","Epoch 48: finishing mini batch 80, training error = 0.046875, loss = 0.08425980806350708\n","Epoch 48: finishing mini batch 81, training error = 0.078125, loss = 0.24063740670681\n","Epoch 48: finishing mini batch 82, training error = 0.0, loss = 0.036242272704839706\n","Epoch 48: finishing mini batch 83, training error = 0.03125, loss = 0.07679755240678787\n","Epoch 48: finishing mini batch 84, training error = 0.078125, loss = 0.18862468004226685\n","Epoch 48: finishing mini batch 85, training error = 0.015625, loss = 0.10319746285676956\n","Epoch 48: finishing mini batch 86, training error = 0.0625, loss = 0.1249186247587204\n","Epoch 48: finishing mini batch 87, training error = 0.03125, loss = 0.053381599485874176\n","Epoch 48: finishing mini batch 88, training error = 0.0625, loss = 0.17988044023513794\n","Epoch 48: finishing mini batch 89, training error = 0.046875, loss = 0.09975704550743103\n","Epoch 48: finishing mini batch 90, training error = 0.078125, loss = 0.15157102048397064\n","Epoch 48: finishing mini batch 91, training error = 0.015625, loss = 0.0467156320810318\n","Epoch 48: finishing mini batch 92, training error = 0.03125, loss = 0.11712568998336792\n","Epoch 48: finishing mini batch 93, training error = 0.0625, loss = 0.12409194558858871\n","Epoch 48: finishing mini batch 94, training error = 0.0625, loss = 0.1221570074558258\n","Epoch 48: finishing mini batch 95, training error = 0.046875, loss = 0.1450025886297226\n","Epoch 48: finishing mini batch 96, training error = 0.03125, loss = 0.08669258654117584\n","Epoch 48: finishing mini batch 97, training error = 0.03125, loss = 0.1252516210079193\n","Epoch 48: finishing mini batch 98, training error = 0.046875, loss = 0.080459363758564\n","Epoch 48: finishing mini batch 99, training error = 0.078125, loss = 0.18264557421207428\n","Epoch 48: finishing mini batch 100, training error = 0.046875, loss = 0.159373939037323\n","Epoch 48: finishing mini batch 101, training error = 0.078125, loss = 0.2350618988275528\n","Epoch 48: finishing mini batch 102, training error = 0.046875, loss = 0.11821141839027405\n","Epoch 48: finishing mini batch 103, training error = 0.03125, loss = 0.1469748467206955\n","Epoch 48: finishing mini batch 104, training error = 0.015625, loss = 0.0935359075665474\n","Epoch 48: finishing mini batch 105, training error = 0.0625, loss = 0.17803743481636047\n","Epoch 48: finishing mini batch 106, training error = 0.078125, loss = 0.20347781479358673\n","Epoch 48: finishing mini batch 107, training error = 0.0625, loss = 0.2024218738079071\n","Epoch 48: finishing mini batch 108, training error = 0.015625, loss = 0.0554717555642128\n","Epoch 48: finishing mini batch 109, training error = 0.015625, loss = 0.09832626581192017\n","Epoch 48: finishing mini batch 110, training error = 0.015625, loss = 0.0988774374127388\n","Epoch 48: finishing mini batch 111, training error = 0.0, loss = 0.054970208555459976\n","Epoch 48: finishing mini batch 112, training error = 0.03125, loss = 0.08919623494148254\n","Epoch 48: finishing mini batch 113, training error = 0.03125, loss = 0.10672303289175034\n","Epoch 48: finishing mini batch 114, training error = 0.0625, loss = 0.14600549638271332\n","Epoch 48: finishing mini batch 115, training error = 0.046875, loss = 0.11409877985715866\n","Epoch 48: finishing mini batch 116, training error = 0.0625, loss = 0.1976407766342163\n","Epoch 48: finishing mini batch 117, training error = 0.046875, loss = 0.07814472913742065\n","Epoch 48: finishing mini batch 118, training error = 0.015625, loss = 0.057525213807821274\n","Epoch 48: finishing mini batch 119, training error = 0.0, loss = 0.023893972858786583\n","Epoch 48: finishing mini batch 120, training error = 0.046875, loss = 0.17460931837558746\n","Epoch 48: finishing mini batch 121, training error = 0.015625, loss = 0.07278183102607727\n","Epoch 48: finishing mini batch 122, training error = 0.03125, loss = 0.10721568763256073\n","Epoch 48: finishing mini batch 123, training error = 0.015625, loss = 0.05231061577796936\n","Epoch 48: finishing mini batch 124, training error = 0.03125, loss = 0.11498603224754333\n","Epoch 48: finishing mini batch 125, training error = 0.03125, loss = 0.09379962831735611\n","Epoch 48: finishing mini batch 126, training error = 0.015625, loss = 0.05024423822760582\n","Epoch 48: finishing mini batch 127, training error = 0.015625, loss = 0.04400726780295372\n","Epoch 48: finishing mini batch 128, training error = 0.015625, loss = 0.023015471175312996\n","Epoch 48: finishing mini batch 129, training error = 0.046875, loss = 0.10035158693790436\n","Epoch 48: finishing mini batch 130, training error = 0.03125, loss = 0.08679575473070145\n","Epoch 48: finishing mini batch 131, training error = 0.0625, loss = 0.09049899131059647\n","Epoch 48: finishing mini batch 132, training error = 0.09375, loss = 0.2365286946296692\n","Epoch 48: finishing mini batch 133, training error = 0.09375, loss = 0.2499621957540512\n","Epoch 48: finishing mini batch 134, training error = 0.03125, loss = 0.0792170837521553\n","Epoch 48: finishing mini batch 135, training error = 0.03125, loss = 0.11183754354715347\n","Epoch 48: finishing mini batch 136, training error = 0.0625, loss = 0.24713045358657837\n","Epoch 48: finishing mini batch 137, training error = 0.03125, loss = 0.08862198144197464\n","Epoch 48: finishing mini batch 138, training error = 0.015625, loss = 0.09317243844270706\n","Epoch 48: finishing mini batch 139, training error = 0.0625, loss = 0.16136184334754944\n","Epoch 48: finishing mini batch 140, training error = 0.046875, loss = 0.12633247673511505\n","Epoch 48: finishing mini batch 141, training error = 0.0625, loss = 0.15687258541584015\n","Epoch 48: finishing mini batch 142, training error = 0.03125, loss = 0.07959690690040588\n","Epoch 48: finishing mini batch 143, training error = 0.0, loss = 0.034784819930791855\n","Epoch 48: finishing mini batch 144, training error = 0.046875, loss = 0.21114777028560638\n","Epoch 48: finishing mini batch 145, training error = 0.015625, loss = 0.04298178851604462\n","Epoch 48: finishing mini batch 146, training error = 0.03125, loss = 0.10734941065311432\n","Epoch 48: finishing mini batch 147, training error = 0.03125, loss = 0.07130871713161469\n","Epoch 48: finishing mini batch 148, training error = 0.015625, loss = 0.05749666318297386\n","Epoch 48: finishing mini batch 149, training error = 0.0, loss = 0.056835971772670746\n","Epoch 48: finishing mini batch 150, training error = 0.015625, loss = 0.0425611212849617\n","Epoch 48: finishing mini batch 151, training error = 0.046875, loss = 0.10715354979038239\n","Epoch 48: finishing mini batch 152, training error = 0.078125, loss = 0.17909610271453857\n","Epoch 48: finishing mini batch 153, training error = 0.03125, loss = 0.11250665038824081\n","Epoch 48: finishing mini batch 154, training error = 0.0625, loss = 0.10751258581876755\n","Epoch 48: finishing mini batch 155, training error = 0.0, loss = 0.03723027929663658\n","Epoch 48: finishing mini batch 156, training error = 0.015625, loss = 0.10025201737880707\n","Epoch 48: finishing mini batch 157, training error = 0.03125, loss = 0.057227760553359985\n","Epoch 48: finishing mini batch 158, training error = 0.03125, loss = 0.0898342877626419\n","Epoch 48: finishing mini batch 159, training error = 0.03125, loss = 0.07597560435533524\n","Epoch 48: finishing mini batch 160, training error = 0.09375, loss = 0.1403038203716278\n","Epoch 48: finishing mini batch 161, training error = 0.0625, loss = 0.20632481575012207\n","Epoch 48: finishing mini batch 162, training error = 0.03125, loss = 0.06118529289960861\n","Epoch 48: finishing mini batch 163, training error = 0.0625, loss = 0.13293114304542542\n","Epoch 48: finishing mini batch 164, training error = 0.03125, loss = 0.05709788575768471\n","Epoch 48: finishing mini batch 165, training error = 0.0, loss = 0.04043092206120491\n","Epoch 48: finishing mini batch 166, training error = 0.046875, loss = 0.07487260550260544\n","Epoch 48: finishing mini batch 167, training error = 0.015625, loss = 0.0742984414100647\n","Epoch 48: finishing mini batch 168, training error = 0.09375, loss = 0.15806540846824646\n","Epoch 48: finishing mini batch 169, training error = 0.09375, loss = 0.24067023396492004\n","Epoch 48: finishing mini batch 170, training error = 0.046875, loss = 0.16729742288589478\n","Epoch 48: finishing mini batch 171, training error = 0.03125, loss = 0.06288883835077286\n","Epoch 48: finishing mini batch 172, training error = 0.03125, loss = 0.10291973501443863\n","Epoch 48: finishing mini batch 173, training error = 0.03125, loss = 0.10988161712884903\n","Epoch 48: finishing mini batch 174, training error = 0.0625, loss = 0.13477011024951935\n","Epoch 48: finishing mini batch 175, training error = 0.015625, loss = 0.07149099558591843\n","Epoch 48: finishing mini batch 176, training error = 0.046875, loss = 0.13399368524551392\n","Epoch 48: finishing mini batch 177, training error = 0.0625, loss = 0.12046042084693909\n","Epoch 48: finishing mini batch 178, training error = 0.03125, loss = 0.09897882491350174\n","Epoch 48: finishing mini batch 179, training error = 0.046875, loss = 0.08683539181947708\n","Epoch 48: finishing mini batch 180, training error = 0.046875, loss = 0.20113998651504517\n","Epoch 48: finishing mini batch 181, training error = 0.0625, loss = 0.10423089563846588\n","Epoch 48: finishing mini batch 182, training error = 0.03125, loss = 0.12255989015102386\n","Epoch 48: finishing mini batch 183, training error = 0.046875, loss = 0.09943653643131256\n","Epoch 48: finishing mini batch 184, training error = 0.015625, loss = 0.04437128081917763\n","Epoch 48: finishing mini batch 185, training error = 0.0625, loss = 0.12747567892074585\n","Epoch 48: finishing mini batch 186, training error = 0.03125, loss = 0.08698323369026184\n","Epoch 48: finishing mini batch 187, training error = 0.078125, loss = 0.15826694667339325\n","Epoch 48: finishing mini batch 188, training error = 0.046875, loss = 0.13606110215187073\n","Epoch 48: finishing mini batch 189, training error = 0.0625, loss = 0.13756497204303741\n","Epoch 48: finishing mini batch 190, training error = 0.03125, loss = 0.12559039890766144\n","Epoch 48: finishing mini batch 191, training error = 0.046875, loss = 0.1050688773393631\n","Epoch 48: finishing mini batch 192, training error = 0.078125, loss = 0.17096459865570068\n","Epoch 48: finishing mini batch 193, training error = 0.046875, loss = 0.1114344447851181\n","Epoch 48: finishing mini batch 194, training error = 0.078125, loss = 0.15281987190246582\n","Epoch 48: finishing mini batch 195, training error = 0.03125, loss = 0.10385935008525848\n","Epoch 48: finishing mini batch 196, training error = 0.0625, loss = 0.1403053253889084\n","Epoch 48: finishing mini batch 197, training error = 0.0, loss = 0.026682406663894653\n","Epoch 48: finishing mini batch 198, training error = 0.03125, loss = 0.09427700936794281\n","Epoch 48: finishing mini batch 199, training error = 0.078125, loss = 0.1678883135318756\n","Epoch 48: finishing mini batch 200, training error = 0.03125, loss = 0.09721419960260391\n","Epoch 48: finishing mini batch 201, training error = 0.015625, loss = 0.086504727602005\n","Epoch 48: finishing mini batch 202, training error = 0.0625, loss = 0.12754444777965546\n","Epoch 48: finishing mini batch 203, training error = 0.03125, loss = 0.11217507719993591\n","Epoch 48: finishing mini batch 204, training error = 0.0, loss = 0.01697392761707306\n","Epoch 48: finishing mini batch 205, training error = 0.046875, loss = 0.10682853311300278\n","Epoch 48: finishing mini batch 206, training error = 0.015625, loss = 0.08163398504257202\n","Epoch 48: finishing mini batch 207, training error = 0.078125, loss = 0.18586964905261993\n","Epoch 48: finishing mini batch 208, training error = 0.015625, loss = 0.058375999331474304\n","Epoch 48: finishing mini batch 209, training error = 0.03125, loss = 0.08711078763008118\n","Epoch 48: finishing mini batch 210, training error = 0.015625, loss = 0.07140251249074936\n","Epoch 48: finishing mini batch 211, training error = 0.03125, loss = 0.0911414846777916\n","Epoch 48: finishing mini batch 212, training error = 0.078125, loss = 0.17046703398227692\n","Epoch 48: finishing mini batch 213, training error = 0.046875, loss = 0.11591269820928574\n","Epoch 48: finishing mini batch 214, training error = 0.015625, loss = 0.04886145517230034\n","Epoch 48: finishing mini batch 215, training error = 0.015625, loss = 0.06410033255815506\n","Epoch 48: finishing mini batch 216, training error = 0.078125, loss = 0.16118034720420837\n","Epoch 48: finishing mini batch 217, training error = 0.03125, loss = 0.07187516987323761\n","Epoch 48: finishing mini batch 218, training error = 0.015625, loss = 0.042830150574445724\n","Epoch 48: finishing mini batch 219, training error = 0.03125, loss = 0.13205762207508087\n","Epoch 48: finishing mini batch 220, training error = 0.046875, loss = 0.14105695486068726\n","Epoch 48: finishing mini batch 221, training error = 0.015625, loss = 0.05078350007534027\n","Epoch 48: finishing mini batch 222, training error = 0.015625, loss = 0.0990084782242775\n","Epoch 48: finishing mini batch 223, training error = 0.03125, loss = 0.16566725075244904\n","Epoch 48: finishing mini batch 224, training error = 0.046875, loss = 0.11278041452169418\n","Epoch 48: finishing mini batch 225, training error = 0.078125, loss = 0.12592960894107819\n","Epoch 48: finishing mini batch 226, training error = 0.0, loss = 0.027402756735682487\n","Epoch 48: finishing mini batch 227, training error = 0.0625, loss = 0.12480363249778748\n","Epoch 48: finishing mini batch 228, training error = 0.03125, loss = 0.09276901185512543\n","Epoch 48: finishing mini batch 229, training error = 0.046875, loss = 0.14185675978660583\n","Epoch 48: finishing mini batch 230, training error = 0.078125, loss = 0.15983058512210846\n","Epoch 48: finishing mini batch 231, training error = 0.015625, loss = 0.09476060420274734\n","Epoch 48: finishing mini batch 232, training error = 0.03125, loss = 0.06482821702957153\n","Epoch 48: finishing mini batch 233, training error = 0.0625, loss = 0.18514810502529144\n","Epoch 48: finishing mini batch 234, training error = 0.03125, loss = 0.18450544774532318\n","Epoch 48: finishing mini batch 235, training error = 0.015625, loss = 0.08945508301258087\n","Epoch 48: finishing mini batch 236, training error = 0.015625, loss = 0.0543886199593544\n","Epoch 48: finishing mini batch 237, training error = 0.03125, loss = 0.10539332032203674\n","Epoch 48: finishing mini batch 238, training error = 0.03125, loss = 0.08203136920928955\n","Epoch 48: finishing mini batch 239, training error = 0.078125, loss = 0.2352239191532135\n","Epoch 48: finishing mini batch 240, training error = 0.078125, loss = 0.10413652658462524\n","Epoch 48: finishing mini batch 241, training error = 0.0, loss = 0.03851671516895294\n","Epoch 48: finishing mini batch 242, training error = 0.046875, loss = 0.16983966529369354\n","Epoch 48: finishing mini batch 243, training error = 0.046875, loss = 0.1612037718296051\n","Epoch 48: finishing mini batch 244, training error = 0.03125, loss = 0.07451403141021729\n","Epoch 48: finishing mini batch 245, training error = 0.03125, loss = 0.11362854391336441\n","Epoch 48: finishing mini batch 246, training error = 0.015625, loss = 0.03665214031934738\n","Epoch 48: finishing mini batch 247, training error = 0.046875, loss = 0.08036705106496811\n","Epoch 48: finishing mini batch 248, training error = 0.109375, loss = 0.23173469305038452\n","Epoch 48: finishing mini batch 249, training error = 0.015625, loss = 0.06031707301735878\n","Epoch 48: finishing mini batch 250, training error = 0.015625, loss = 0.06193024665117264\n","Epoch 48: finishing mini batch 251, training error = 0.078125, loss = 0.2053159475326538\n","Epoch 48: finishing mini batch 252, training error = 0.078125, loss = 0.21694044768810272\n","Epoch 48: finishing mini batch 253, training error = 0.125, loss = 0.2646801769733429\n","Epoch 48: finishing mini batch 254, training error = 0.046875, loss = 0.14103777706623077\n","Epoch 48: finishing mini batch 255, training error = 0.03125, loss = 0.08676684647798538\n","Epoch 48: finishing mini batch 256, training error = 0.0625, loss = 0.29551953077316284\n","Epoch 48: finishing mini batch 257, training error = 0.03125, loss = 0.10694509744644165\n","Epoch 48: finishing mini batch 258, training error = 0.015625, loss = 0.03890537843108177\n","Epoch 48: finishing mini batch 259, training error = 0.03125, loss = 0.09839630126953125\n","Epoch 48: finishing mini batch 260, training error = 0.0625, loss = 0.1377425640821457\n","Epoch 48: finishing mini batch 261, training error = 0.0, loss = 0.07723850756883621\n","Epoch 48: finishing mini batch 262, training error = 0.015625, loss = 0.0854140892624855\n","Epoch 48: finishing mini batch 263, training error = 0.0, loss = 0.03352482244372368\n","Epoch 48: finishing mini batch 264, training error = 0.046875, loss = 0.15015602111816406\n","Epoch 48: finishing mini batch 265, training error = 0.015625, loss = 0.07252207398414612\n","Epoch 48: finishing mini batch 266, training error = 0.0625, loss = 0.14416612684726715\n","Epoch 48: finishing mini batch 267, training error = 0.078125, loss = 0.15564283728599548\n","Epoch 48: finishing mini batch 268, training error = 0.0625, loss = 0.1422034353017807\n","Epoch 48: finishing mini batch 269, training error = 0.046875, loss = 0.10456512868404388\n","Epoch 48: finishing mini batch 270, training error = 0.015625, loss = 0.08973729610443115\n","Epoch 48: finishing mini batch 271, training error = 0.03125, loss = 0.09350164234638214\n","Epoch 48: finishing mini batch 272, training error = 0.046875, loss = 0.09234724193811417\n","Epoch 48: finishing mini batch 273, training error = 0.03125, loss = 0.1636115312576294\n","Epoch 48: finishing mini batch 274, training error = 0.046875, loss = 0.12167640030384064\n","Epoch 48: finishing mini batch 275, training error = 0.09375, loss = 0.20842044055461884\n","Epoch 48: finishing mini batch 276, training error = 0.078125, loss = 0.1656545251607895\n","Epoch 48: finishing mini batch 277, training error = 0.015625, loss = 0.06027932092547417\n","Epoch 48: finishing mini batch 278, training error = 0.046875, loss = 0.11351098865270615\n","Epoch 48: finishing mini batch 279, training error = 0.03125, loss = 0.07395146787166595\n","Epoch 48: finishing mini batch 280, training error = 0.03125, loss = 0.06881833076477051\n","Epoch 48: finishing mini batch 281, training error = 0.0625, loss = 0.12387801706790924\n","Epoch 48: finishing mini batch 282, training error = 0.046875, loss = 0.16421839594841003\n","Epoch 48: finishing mini batch 283, training error = 0.0625, loss = 0.20029141008853912\n","Epoch 48: finishing mini batch 284, training error = 0.0, loss = 0.049169138073921204\n","Epoch 48: finishing mini batch 285, training error = 0.03125, loss = 0.06908942759037018\n","Epoch 48: finishing mini batch 286, training error = 0.078125, loss = 0.1714775115251541\n","Epoch 48: finishing mini batch 287, training error = 0.03125, loss = 0.16457392275333405\n","Epoch 48: finishing mini batch 288, training error = 0.0, loss = 0.030574174597859383\n","Epoch 48: finishing mini batch 289, training error = 0.03125, loss = 0.08024879544973373\n","Epoch 48: finishing mini batch 290, training error = 0.0, loss = 0.02086324244737625\n","Epoch 48: finishing mini batch 291, training error = 0.015625, loss = 0.057125531136989594\n","Epoch 48: finishing mini batch 292, training error = 0.03125, loss = 0.10077062994241714\n","Epoch 48: finishing mini batch 293, training error = 0.0625, loss = 0.14794492721557617\n","Epoch 48: finishing mini batch 294, training error = 0.015625, loss = 0.08688129484653473\n","Epoch 48: finishing mini batch 295, training error = 0.046875, loss = 0.12919101119041443\n","Epoch 48: finishing mini batch 296, training error = 0.046875, loss = 0.17888490855693817\n","Epoch 48: finishing mini batch 297, training error = 0.046875, loss = 0.07738867402076721\n","Epoch 48: finishing mini batch 298, training error = 0.046875, loss = 0.16980040073394775\n","Epoch 48: finishing mini batch 299, training error = 0.046875, loss = 0.11016174405813217\n","Epoch 48: finishing mini batch 300, training error = 0.0625, loss = 0.2077849805355072\n","Epoch 48: finishing mini batch 301, training error = 0.0625, loss = 0.21168221533298492\n","Epoch 48: finishing mini batch 302, training error = 0.0, loss = 0.04075910151004791\n","Epoch 48: finishing mini batch 303, training error = 0.03125, loss = 0.11520381271839142\n","Epoch 48: finishing mini batch 304, training error = 0.03125, loss = 0.06993768364191055\n","Epoch 48: finishing mini batch 305, training error = 0.015625, loss = 0.1003871038556099\n","Epoch 48: finishing mini batch 306, training error = 0.078125, loss = 0.20406170189380646\n","Epoch 48: finishing mini batch 307, training error = 0.046875, loss = 0.11426535248756409\n","Epoch 48: finishing mini batch 308, training error = 0.03125, loss = 0.08924233913421631\n","Epoch 48: finishing mini batch 309, training error = 0.0625, loss = 0.11352938413619995\n","Epoch 48: finishing mini batch 310, training error = 0.046875, loss = 0.11478562653064728\n","Epoch 48: finishing mini batch 311, training error = 0.03125, loss = 0.10938955843448639\n","Epoch 48: finishing mini batch 312, training error = 0.046875, loss = 0.1869664192199707\n","Epoch 48: finishing mini batch 313, training error = 0.03125, loss = 0.09388041496276855\n","Epoch 48: finishing mini batch 314, training error = 0.03125, loss = 0.06181005388498306\n","Epoch 48: finishing mini batch 315, training error = 0.078125, loss = 0.24022409319877625\n","Epoch 48: finishing mini batch 316, training error = 0.03125, loss = 0.09093227982521057\n","Epoch 48: finishing mini batch 317, training error = 0.0625, loss = 0.18113930523395538\n","Epoch 48: finishing mini batch 318, training error = 0.046875, loss = 0.1331879198551178\n","Epoch 48: finishing mini batch 319, training error = 0.015625, loss = 0.04414293169975281\n","Epoch 48: finishing mini batch 320, training error = 0.03125, loss = 0.10389906167984009\n","Epoch 48: finishing mini batch 321, training error = 0.03125, loss = 0.06337269395589828\n","Epoch 48: finishing mini batch 322, training error = 0.09375, loss = 0.2916424870491028\n","Epoch 48: finishing mini batch 323, training error = 0.0625, loss = 0.19995497167110443\n","Epoch 48: finishing mini batch 324, training error = 0.03125, loss = 0.07527599483728409\n","Epoch 48: finishing mini batch 325, training error = 0.046875, loss = 0.08801421523094177\n","Epoch 48: finishing mini batch 326, training error = 0.015625, loss = 0.05130178853869438\n","Epoch 48: finishing mini batch 327, training error = 0.0, loss = 0.05651411414146423\n","Epoch 48: finishing mini batch 328, training error = 0.046875, loss = 0.1273488849401474\n","Epoch 48: finishing mini batch 329, training error = 0.03125, loss = 0.08124097436666489\n","Epoch 48: finishing mini batch 330, training error = 0.046875, loss = 0.09973038733005524\n","Epoch 48: finishing mini batch 331, training error = 0.0625, loss = 0.21405178308486938\n","Epoch 48: finishing mini batch 332, training error = 0.0625, loss = 0.15105175971984863\n","Epoch 48: finishing mini batch 333, training error = 0.03125, loss = 0.07932247966527939\n","Epoch 48: finishing mini batch 334, training error = 0.03125, loss = 0.06084416061639786\n","Epoch 48: finishing mini batch 335, training error = 0.0, loss = 0.03658827766776085\n","Epoch 48: finishing mini batch 336, training error = 0.03125, loss = 0.05301903560757637\n","Epoch 48: finishing mini batch 337, training error = 0.046875, loss = 0.09314625710248947\n","Epoch 48: finishing mini batch 338, training error = 0.03125, loss = 0.11262490600347519\n","Epoch 48: finishing mini batch 339, training error = 0.015625, loss = 0.05263391137123108\n","Epoch 48: finishing mini batch 340, training error = 0.046875, loss = 0.13716040551662445\n","Epoch 48: finishing mini batch 341, training error = 0.078125, loss = 0.11314593255519867\n","Epoch 48: finishing mini batch 342, training error = 0.078125, loss = 0.22320130467414856\n","Epoch 48: finishing mini batch 343, training error = 0.0, loss = 0.029598472639918327\n","Epoch 48: finishing mini batch 344, training error = 0.015625, loss = 0.06266553699970245\n","Epoch 48: finishing mini batch 345, training error = 0.046875, loss = 0.17745715379714966\n","Epoch 48: finishing mini batch 346, training error = 0.03125, loss = 0.10338049381971359\n","Epoch 48: finishing mini batch 347, training error = 0.03125, loss = 0.07897275686264038\n","Epoch 48: finishing mini batch 348, training error = 0.046875, loss = 0.11630415916442871\n","Epoch 48: finishing mini batch 349, training error = 0.078125, loss = 0.1499786525964737\n","Epoch 48: finishing mini batch 350, training error = 0.015625, loss = 0.07561064511537552\n","Epoch 48: finishing mini batch 351, training error = 0.046875, loss = 0.11819496750831604\n","Epoch 48: finishing mini batch 352, training error = 0.03125, loss = 0.13700397312641144\n","Epoch 48: finishing mini batch 353, training error = 0.015625, loss = 0.07021958380937576\n","Epoch 48: finishing mini batch 354, training error = 0.0625, loss = 0.13350418210029602\n","Epoch 48: finishing mini batch 355, training error = 0.0, loss = 0.034368764609098434\n","Epoch 48: finishing mini batch 356, training error = 0.046875, loss = 0.1372106969356537\n","Epoch 48: finishing mini batch 357, training error = 0.0, loss = 0.0649317130446434\n","Epoch 48: finishing mini batch 358, training error = 0.015625, loss = 0.07414961606264114\n","Epoch 48: finishing mini batch 359, training error = 0.03125, loss = 0.0834466740489006\n","Epoch 48: finishing mini batch 360, training error = 0.03125, loss = 0.09187453985214233\n","Epoch 48: finishing mini batch 361, training error = 0.078125, loss = 0.1236005499958992\n","Epoch 48: finishing mini batch 362, training error = 0.0625, loss = 0.18014247715473175\n","Epoch 48: finishing mini batch 363, training error = 0.0, loss = 0.033152222633361816\n","Epoch 48: finishing mini batch 364, training error = 0.015625, loss = 0.04007088392972946\n","Epoch 48: finishing mini batch 365, training error = 0.125, loss = 0.3285493552684784\n","Epoch 48: finishing mini batch 366, training error = 0.078125, loss = 0.11605720221996307\n","Epoch 48: finishing mini batch 367, training error = 0.015625, loss = 0.03451615199446678\n","Epoch 48: finishing mini batch 368, training error = 0.03125, loss = 0.11599551886320114\n","Epoch 48: finishing mini batch 369, training error = 0.03125, loss = 0.09450322389602661\n","Epoch 48: finishing mini batch 370, training error = 0.046875, loss = 0.08786691725254059\n","Epoch 48: finishing mini batch 371, training error = 0.03125, loss = 0.08383683115243912\n","Epoch 48: finishing mini batch 372, training error = 0.046875, loss = 0.12828630208969116\n","Epoch 48: finishing mini batch 373, training error = 0.015625, loss = 0.04935329407453537\n","Epoch 48: finishing mini batch 374, training error = 0.046875, loss = 0.10399144142866135\n","Epoch 48: finishing mini batch 375, training error = 0.0, loss = 0.047861263155937195\n","Epoch 48: finishing mini batch 376, training error = 0.0, loss = 0.05400750786066055\n","Epoch 48: finishing mini batch 377, training error = 0.03125, loss = 0.11034294962882996\n","Epoch 48: finishing mini batch 378, training error = 0.0, loss = 0.035600170493125916\n","Epoch 48: finishing mini batch 379, training error = 0.03125, loss = 0.1085413247346878\n","Epoch 48: finishing mini batch 380, training error = 0.03125, loss = 0.0743812546133995\n","Epoch 48: finishing mini batch 381, training error = 0.078125, loss = 0.18180696666240692\n","Epoch 48: finishing mini batch 382, training error = 0.03125, loss = 0.07211578637361526\n","Epoch 48: finishing mini batch 383, training error = 0.015625, loss = 0.0712478905916214\n","Epoch 48: finishing mini batch 384, training error = 0.015625, loss = 0.057913731783628464\n","Epoch 48: finishing mini batch 385, training error = 0.078125, loss = 0.2104509323835373\n","Epoch 48: finishing mini batch 386, training error = 0.078125, loss = 0.15582387149333954\n","Epoch 48: finishing mini batch 387, training error = 0.03125, loss = 0.08693592995405197\n","Epoch 48: finishing mini batch 388, training error = 0.046875, loss = 0.11092355847358704\n","Epoch 48: finishing mini batch 389, training error = 0.046875, loss = 0.18356819450855255\n","Epoch 48: finishing mini batch 390, training error = 0.046875, loss = 0.09688475728034973\n","Epoch 48: finishing mini batch 391, training error = 0.046875, loss = 0.12353844940662384\n","Epoch 48: finishing mini batch 392, training error = 0.03125, loss = 0.1102323979139328\n","Epoch 48: finishing mini batch 393, training error = 0.046875, loss = 0.11428438872098923\n","Epoch 48: finishing mini batch 394, training error = 0.0625, loss = 0.12787947058677673\n","Epoch 48: finishing mini batch 395, training error = 0.046875, loss = 0.10681401938199997\n","Epoch 48: finishing mini batch 396, training error = 0.0625, loss = 0.13541369140148163\n","Epoch 48: finishing mini batch 397, training error = 0.015625, loss = 0.053363632410764694\n","Epoch 48: finishing mini batch 398, training error = 0.03125, loss = 0.11143545806407928\n","Epoch 48: finishing mini batch 399, training error = 0.046875, loss = 0.14498746395111084\n","Epoch 48: finishing mini batch 400, training error = 0.046875, loss = 0.12145239859819412\n","Epoch 48: finishing mini batch 401, training error = 0.078125, loss = 0.22147436439990997\n","Epoch 48: finishing mini batch 402, training error = 0.078125, loss = 0.17711597681045532\n","Epoch 48: finishing mini batch 403, training error = 0.03125, loss = 0.10376282781362534\n","Epoch 48: finishing mini batch 404, training error = 0.03125, loss = 0.07283995300531387\n","Epoch 48: finishing mini batch 405, training error = 0.0, loss = 0.06435322761535645\n","Epoch 48: finishing mini batch 406, training error = 0.046875, loss = 0.15333034098148346\n","Epoch 48: finishing mini batch 407, training error = 0.046875, loss = 0.17558029294013977\n","Epoch 48: finishing mini batch 408, training error = 0.046875, loss = 0.18289369344711304\n","Epoch 48: finishing mini batch 409, training error = 0.078125, loss = 0.11282294243574142\n","Epoch 48: finishing mini batch 410, training error = 0.03125, loss = 0.059978190809488297\n","Epoch 48: finishing mini batch 411, training error = 0.0625, loss = 0.186393141746521\n","Epoch 48: finishing mini batch 412, training error = 0.015625, loss = 0.05689548701047897\n","Epoch 48: finishing mini batch 413, training error = 0.03125, loss = 0.119049571454525\n","Epoch 48: finishing mini batch 414, training error = 0.09375, loss = 0.24183973670005798\n","Epoch 48: finishing mini batch 415, training error = 0.0, loss = 0.04225097969174385\n","Epoch 48: finishing mini batch 416, training error = 0.078125, loss = 0.15322907269001007\n","Epoch 48: finishing mini batch 417, training error = 0.0625, loss = 0.18362431228160858\n","Epoch 48: finishing mini batch 418, training error = 0.046875, loss = 0.11139292269945145\n","Epoch 48: finishing mini batch 419, training error = 0.0625, loss = 0.1743222177028656\n","Epoch 48: finishing mini batch 420, training error = 0.125, loss = 0.23924674093723297\n","Epoch 48: finishing mini batch 421, training error = 0.0625, loss = 0.16924579441547394\n","Epoch 48: finishing mini batch 422, training error = 0.046875, loss = 0.08611001074314117\n","Epoch 48: finishing mini batch 423, training error = 0.0, loss = 0.022660616785287857\n","Epoch 48: finishing mini batch 424, training error = 0.109375, loss = 0.23081427812576294\n","Epoch 48: finishing mini batch 425, training error = 0.03125, loss = 0.08403360843658447\n","Epoch 48: finishing mini batch 426, training error = 0.0, loss = 0.03617691993713379\n","Epoch 48: finishing mini batch 427, training error = 0.03125, loss = 0.0890711322426796\n","Epoch 48: finishing mini batch 428, training error = 0.03125, loss = 0.11108927428722382\n","Epoch 48: finishing mini batch 429, training error = 0.0625, loss = 0.15767377614974976\n","Epoch 48: finishing mini batch 430, training error = 0.046875, loss = 0.10623297840356827\n","Epoch 48: finishing mini batch 431, training error = 0.15625, loss = 0.5014966130256653\n","Epoch 48: finishing mini batch 432, training error = 0.09375, loss = 0.3115818202495575\n","Epoch 48: finishing mini batch 433, training error = 0.0, loss = 0.05371479690074921\n","Epoch 48: finishing mini batch 434, training error = 0.078125, loss = 0.24398468434810638\n","Epoch 48: finishing mini batch 435, training error = 0.03125, loss = 0.0828210785984993\n","Epoch 48: finishing mini batch 436, training error = 0.0625, loss = 0.21304646134376526\n","Epoch 48: finishing mini batch 437, training error = 0.03125, loss = 0.11977237462997437\n","Epoch 48: finishing mini batch 438, training error = 0.046875, loss = 0.1105399876832962\n","Epoch 48: finishing mini batch 439, training error = 0.015625, loss = 0.05244491994380951\n","Epoch 48: finishing mini batch 440, training error = 0.046875, loss = 0.16712534427642822\n","Epoch 48: finishing mini batch 441, training error = 0.0625, loss = 0.14937154948711395\n","Epoch 48: finishing mini batch 442, training error = 0.078125, loss = 0.1842939406633377\n","Epoch 48: finishing mini batch 443, training error = 0.046875, loss = 0.08166410773992538\n","Epoch 48: finishing mini batch 444, training error = 0.046875, loss = 0.09530367702245712\n","Epoch 48: finishing mini batch 445, training error = 0.015625, loss = 0.07667496055364609\n","Epoch 48: finishing mini batch 446, training error = 0.0625, loss = 0.2605321705341339\n","Epoch 48: finishing mini batch 447, training error = 0.015625, loss = 0.09364798665046692\n","Epoch 48: finishing mini batch 448, training error = 0.078125, loss = 0.2723868489265442\n","Epoch 48: finishing mini batch 449, training error = 0.125, loss = 0.31146240234375\n","Epoch 48: finishing mini batch 450, training error = 0.078125, loss = 0.16103433072566986\n","Epoch 48: finishing mini batch 451, training error = 0.078125, loss = 0.16193275153636932\n","Epoch 48: finishing mini batch 452, training error = 0.015625, loss = 0.057209696620702744\n","Epoch 48: finishing mini batch 453, training error = 0.0625, loss = 0.17324472963809967\n","Epoch 48: finishing mini batch 454, training error = 0.0625, loss = 0.14504486322402954\n","Epoch 48: finishing mini batch 455, training error = 0.03125, loss = 0.09618855267763138\n","Epoch 48: finishing mini batch 456, training error = 0.0625, loss = 0.3292108476161957\n","Epoch 48: finishing mini batch 457, training error = 0.03125, loss = 0.18879839777946472\n","Epoch 48: finishing mini batch 458, training error = 0.015625, loss = 0.060638658702373505\n","Epoch 48: finishing mini batch 459, training error = 0.0625, loss = 0.18250159919261932\n","Epoch 48: finishing mini batch 460, training error = 0.0625, loss = 0.2231833040714264\n","Epoch 48: finishing mini batch 461, training error = 0.0625, loss = 0.11928729712963104\n","Epoch 48: finishing mini batch 462, training error = 0.03125, loss = 0.12127332389354706\n","Epoch 48: finishing mini batch 463, training error = 0.046875, loss = 0.14049766957759857\n","Epoch 48: finishing mini batch 464, training error = 0.078125, loss = 0.18537816405296326\n","Epoch 48: finishing mini batch 465, training error = 0.015625, loss = 0.07639936357736588\n","Epoch 48: finishing mini batch 466, training error = 0.0625, loss = 0.1496165245771408\n","Epoch 48: finishing mini batch 467, training error = 0.046875, loss = 0.09900636225938797\n","Epoch 48: finishing mini batch 468, training error = 0.0625, loss = 0.12819625437259674\n","Epoch 48: finishing mini batch 469, training error = 0.09375, loss = 0.35998621582984924\n","Epoch 48: finishing mini batch 470, training error = 0.03125, loss = 0.1121358573436737\n","Epoch 48: finishing mini batch 471, training error = 0.046875, loss = 0.15060259401798248\n","Epoch 48: finishing mini batch 472, training error = 0.0, loss = 0.035466112196445465\n","Epoch 48: finishing mini batch 473, training error = 0.046875, loss = 0.1356438845396042\n","Epoch 48: finishing mini batch 474, training error = 0.015625, loss = 0.06675726920366287\n","Epoch 48: finishing mini batch 475, training error = 0.03125, loss = 0.07057473063468933\n","Epoch 48: finishing mini batch 476, training error = 0.078125, loss = 0.16454988718032837\n","Epoch 48: finishing mini batch 477, training error = 0.03125, loss = 0.07817236334085464\n","Epoch 48: finishing mini batch 478, training error = 0.046875, loss = 0.22625280916690826\n","Epoch 48: finishing mini batch 479, training error = 0.046875, loss = 0.12750178575515747\n","Epoch 48: finishing mini batch 480, training error = 0.03125, loss = 0.08983270078897476\n","Epoch 48: finishing mini batch 481, training error = 0.015625, loss = 0.07006341218948364\n","Epoch 48: finishing mini batch 482, training error = 0.046875, loss = 0.14446164667606354\n","Epoch 48: finishing mini batch 483, training error = 0.03125, loss = 0.08439089357852936\n","Epoch 48: finishing mini batch 484, training error = 0.125, loss = 0.3728199899196625\n","Epoch 48: finishing mini batch 485, training error = 0.0, loss = 0.031032195314764977\n","Epoch 48: finishing mini batch 486, training error = 0.046875, loss = 0.14828461408615112\n","Epoch 48: finishing mini batch 487, training error = 0.015625, loss = 0.07871463894844055\n","Epoch 48: finishing mini batch 488, training error = 0.03125, loss = 0.07717602699995041\n","Epoch 48: finishing mini batch 489, training error = 0.0, loss = 0.04253733903169632\n","Epoch 48: finishing mini batch 490, training error = 0.03125, loss = 0.09360280632972717\n","Epoch 48: finishing mini batch 491, training error = 0.046875, loss = 0.14941099286079407\n","Epoch 48: finishing mini batch 492, training error = 0.046875, loss = 0.10260473191738129\n","Epoch 48: finishing mini batch 493, training error = 0.046875, loss = 0.11078377068042755\n","Epoch 48: finishing mini batch 494, training error = 0.046875, loss = 0.09857383370399475\n","Epoch 48: finishing mini batch 495, training error = 0.046875, loss = 0.10007969290018082\n","Epoch 48: finishing mini batch 496, training error = 0.0625, loss = 0.1733885407447815\n","Epoch 48: finishing mini batch 497, training error = 0.0, loss = 0.06591042876243591\n","Epoch 48: finishing mini batch 498, training error = 0.03125, loss = 0.11795974522829056\n","Epoch 48: finishing mini batch 499, training error = 0.03125, loss = 0.14053843915462494\n","Epoch 48: finishing mini batch 500, training error = 0.046875, loss = 0.1165740117430687\n","Epoch 48: finishing mini batch 501, training error = 0.0625, loss = 0.1134512722492218\n","Epoch 48: finishing mini batch 502, training error = 0.078125, loss = 0.19574467837810516\n","Epoch 48: finishing mini batch 503, training error = 0.046875, loss = 0.09359002113342285\n","Epoch 48: finishing mini batch 504, training error = 0.0, loss = 0.02921655960381031\n","Epoch 48: finishing mini batch 505, training error = 0.015625, loss = 0.049339815974235535\n","Epoch 48: finishing mini batch 506, training error = 0.03125, loss = 0.07786009460687637\n","Epoch 48: finishing mini batch 507, training error = 0.0, loss = 0.030188795179128647\n","Epoch 48: finishing mini batch 508, training error = 0.078125, loss = 0.14655061066150665\n","Epoch 48: finishing mini batch 509, training error = 0.015625, loss = 0.08050421625375748\n","Epoch 48: finishing mini batch 510, training error = 0.015625, loss = 0.04801153764128685\n","Epoch 48: finishing mini batch 511, training error = 0.03125, loss = 0.10827171802520752\n","Epoch 48: finishing mini batch 512, training error = 0.03125, loss = 0.1213577538728714\n","Epoch 48: finishing mini batch 513, training error = 0.03125, loss = 0.16056621074676514\n","Epoch 48: finishing mini batch 514, training error = 0.0625, loss = 0.17169801890850067\n","Epoch 48: finishing mini batch 515, training error = 0.03125, loss = 0.056834954768419266\n","Epoch 48: finishing mini batch 516, training error = 0.03125, loss = 0.0928092896938324\n","Epoch 48: finishing mini batch 517, training error = 0.046875, loss = 0.207227423787117\n","Epoch 48: finishing mini batch 518, training error = 0.046875, loss = 0.21327202022075653\n","Epoch 48: finishing mini batch 519, training error = 0.046875, loss = 0.17084895074367523\n","Epoch 48: finishing mini batch 520, training error = 0.015625, loss = 0.06295669078826904\n","Epoch 48: finishing mini batch 521, training error = 0.0, loss = 0.040079470723867416\n","Epoch 48: finishing mini batch 522, training error = 0.078125, loss = 0.18080894649028778\n","Epoch 48: finishing mini batch 523, training error = 0.078125, loss = 0.18398568034172058\n","Epoch 48: finishing mini batch 524, training error = 0.046875, loss = 0.1756875216960907\n","Epoch 48: finishing mini batch 525, training error = 0.078125, loss = 0.2353031039237976\n","Epoch 48: finishing mini batch 526, training error = 0.078125, loss = 0.20605437457561493\n","Epoch 48: finishing mini batch 527, training error = 0.03125, loss = 0.08686940371990204\n","Epoch 48: finishing mini batch 528, training error = 0.03125, loss = 0.08996931463479996\n","Epoch 48: finishing mini batch 529, training error = 0.0625, loss = 0.1490834504365921\n","Epoch 48: finishing mini batch 530, training error = 0.015625, loss = 0.05690019205212593\n","Epoch 48: finishing mini batch 531, training error = 0.015625, loss = 0.04922856390476227\n","Epoch 48: finishing mini batch 532, training error = 0.0625, loss = 0.19265680015087128\n","Epoch 48: finishing mini batch 533, training error = 0.0625, loss = 0.13209764659404755\n","Epoch 48: finishing mini batch 534, training error = 0.0, loss = 0.03743567317724228\n","Epoch 48: finishing mini batch 535, training error = 0.046875, loss = 0.09326701611280441\n","Epoch 48: finishing mini batch 536, training error = 0.015625, loss = 0.03927388787269592\n","Epoch 48: finishing mini batch 537, training error = 0.0625, loss = 0.15675093233585358\n","Epoch 48: finishing mini batch 538, training error = 0.015625, loss = 0.061896998435258865\n","Epoch 48: finishing mini batch 539, training error = 0.09375, loss = 0.20588676631450653\n","Epoch 48: finishing mini batch 540, training error = 0.078125, loss = 0.15005134046077728\n","Epoch 48: finishing mini batch 541, training error = 0.0, loss = 0.03983659669756889\n","Epoch 48: finishing mini batch 542, training error = 0.015625, loss = 0.10666689276695251\n","Epoch 48: finishing mini batch 543, training error = 0.03125, loss = 0.06597428023815155\n","Epoch 48: finishing mini batch 544, training error = 0.046875, loss = 0.0805915892124176\n","Epoch 48: finishing mini batch 545, training error = 0.015625, loss = 0.06278574466705322\n","Epoch 48: finishing mini batch 546, training error = 0.03125, loss = 0.08546681702136993\n","Epoch 48: finishing mini batch 547, training error = 0.015625, loss = 0.02596360445022583\n","Epoch 48: finishing mini batch 548, training error = 0.09375, loss = 0.189032182097435\n","Epoch 48: finishing mini batch 549, training error = 0.015625, loss = 0.0621943436563015\n","Epoch 48: finishing mini batch 550, training error = 0.0, loss = 0.03446654975414276\n","Epoch 48: finishing mini batch 551, training error = 0.03125, loss = 0.17476770281791687\n","Epoch 48: finishing mini batch 552, training error = 0.0625, loss = 0.2640800476074219\n","Epoch 48: finishing mini batch 553, training error = 0.0, loss = 0.021815406158566475\n","Epoch 48: finishing mini batch 554, training error = 0.046875, loss = 0.1124456599354744\n","Epoch 48: finishing mini batch 555, training error = 0.03125, loss = 0.06496863812208176\n","Epoch 48: finishing mini batch 556, training error = 0.0, loss = 0.03509872406721115\n","Epoch 48: finishing mini batch 557, training error = 0.078125, loss = 0.1510436087846756\n","Epoch 48: finishing mini batch 558, training error = 0.046875, loss = 0.14519532024860382\n","Epoch 48: finishing mini batch 559, training error = 0.0625, loss = 0.13240455090999603\n","Epoch 48: finishing mini batch 560, training error = 0.015625, loss = 0.04237978160381317\n","Epoch 48: finishing mini batch 561, training error = 0.015625, loss = 0.0662766546010971\n","Epoch 48: finishing mini batch 562, training error = 0.015625, loss = 0.05606815591454506\n","Epoch 48: finishing mini batch 563, training error = 0.09375, loss = 0.16236044466495514\n","Epoch 48: finishing mini batch 564, training error = 0.046875, loss = 0.10951953381299973\n","Epoch 48: finishing mini batch 565, training error = 0.03125, loss = 0.08229143917560577\n","Epoch 48: finishing mini batch 566, training error = 0.03125, loss = 0.05428613722324371\n","Epoch 48: finishing mini batch 567, training error = 0.0, loss = 0.03405949845910072\n","Epoch 48: finishing mini batch 568, training error = 0.0, loss = 0.03416074439883232\n","Epoch 48: finishing mini batch 569, training error = 0.046875, loss = 0.1214413046836853\n","Epoch 48: finishing mini batch 570, training error = 0.03125, loss = 0.12562529742717743\n","Epoch 48: finishing mini batch 571, training error = 0.015625, loss = 0.07063037157058716\n","Epoch 48: finishing mini batch 572, training error = 0.0, loss = 0.05262940376996994\n","Epoch 48: finishing mini batch 573, training error = 0.0625, loss = 0.17809320986270905\n","Epoch 48: finishing mini batch 574, training error = 0.03125, loss = 0.1426112800836563\n","Epoch 48: finishing mini batch 575, training error = 0.03125, loss = 0.072053462266922\n","Epoch 48: finishing mini batch 576, training error = 0.046875, loss = 0.09014783799648285\n","Epoch 48: finishing mini batch 577, training error = 0.03125, loss = 0.05585457384586334\n","Epoch 48: finishing mini batch 578, training error = 0.046875, loss = 0.11773374676704407\n","Epoch 48: finishing mini batch 579, training error = 0.015625, loss = 0.05234528332948685\n","Epoch 48: finishing mini batch 580, training error = 0.09375, loss = 0.31373053789138794\n","Epoch 48: finishing mini batch 581, training error = 0.03125, loss = 0.11275694519281387\n","Epoch 48: finishing mini batch 582, training error = 0.015625, loss = 0.11256708204746246\n","Epoch 48: finishing mini batch 583, training error = 0.0, loss = 0.041665542870759964\n","Epoch 48: finishing mini batch 584, training error = 0.0, loss = 0.047236498445272446\n","Epoch 48: finishing mini batch 585, training error = 0.109375, loss = 0.17486563324928284\n","Epoch 48: finishing mini batch 586, training error = 0.046875, loss = 0.15911851823329926\n","Epoch 48: finishing mini batch 587, training error = 0.0, loss = 0.018375804647803307\n","Epoch 48: finishing mini batch 588, training error = 0.0, loss = 0.034284234046936035\n","Epoch 48: finishing mini batch 589, training error = 0.046875, loss = 0.14475420117378235\n","Epoch 48: finishing mini batch 590, training error = 0.03125, loss = 0.06453974545001984\n","Epoch 48: finishing mini batch 591, training error = 0.015625, loss = 0.055088985711336136\n","Epoch 48: finishing mini batch 592, training error = 0.078125, loss = 0.16234150528907776\n","Epoch 48: finishing mini batch 593, training error = 0.0625, loss = 0.19115926325321198\n","Epoch 48: finishing mini batch 594, training error = 0.0, loss = 0.019566550850868225\n","Epoch 48: finishing mini batch 595, training error = 0.0625, loss = 0.14732477068901062\n","Epoch 48: finishing mini batch 596, training error = 0.046875, loss = 0.1183861717581749\n","Epoch 48: finishing mini batch 597, training error = 0.046875, loss = 0.14143215119838715\n","Epoch 48: finishing mini batch 598, training error = 0.09375, loss = 0.18177767097949982\n","Epoch 48: finishing mini batch 599, training error = 0.0625, loss = 0.1474819779396057\n","Epoch 48: finishing mini batch 600, training error = 0.015625, loss = 0.0715431272983551\n","Epoch 48: finishing mini batch 601, training error = 0.03125, loss = 0.1614699512720108\n","Epoch 48: finishing mini batch 602, training error = 0.015625, loss = 0.048264678567647934\n","Epoch 48: finishing mini batch 603, training error = 0.0, loss = 0.03564132750034332\n","Epoch 48: finishing mini batch 604, training error = 0.03125, loss = 0.0568389818072319\n","Epoch 48: finishing mini batch 605, training error = 0.0625, loss = 0.18429771065711975\n","Epoch 48: finishing mini batch 606, training error = 0.015625, loss = 0.044866934418678284\n","Epoch 48: finishing mini batch 607, training error = 0.078125, loss = 0.1564522683620453\n","Epoch 48: finishing mini batch 608, training error = 0.0625, loss = 0.16666418313980103\n","Epoch 48: finishing mini batch 609, training error = 0.03125, loss = 0.10793719440698624\n","Epoch 48: finishing mini batch 610, training error = 0.015625, loss = 0.049741230905056\n","Epoch 48: finishing mini batch 611, training error = 0.046875, loss = 0.07901021838188171\n","Epoch 48: finishing mini batch 612, training error = 0.03125, loss = 0.08822549879550934\n","Epoch 48: finishing mini batch 613, training error = 0.09375, loss = 0.22614973783493042\n","Epoch 48: finishing mini batch 614, training error = 0.03125, loss = 0.12980042397975922\n","Epoch 48: finishing mini batch 615, training error = 0.0, loss = 0.037174612283706665\n","Epoch 48: finishing mini batch 616, training error = 0.015625, loss = 0.07358086109161377\n","Epoch 48: finishing mini batch 617, training error = 0.078125, loss = 0.17791923880577087\n","Epoch 48: finishing mini batch 618, training error = 0.015625, loss = 0.10550382733345032\n","Epoch 48: finishing mini batch 619, training error = 0.0625, loss = 0.14855724573135376\n","Epoch 48: finishing mini batch 620, training error = 0.046875, loss = 0.139045849442482\n","Epoch 48: finishing mini batch 621, training error = 0.03125, loss = 0.05987025424838066\n","Epoch 48: finishing mini batch 622, training error = 0.015625, loss = 0.038466908037662506\n","Epoch 48: finishing mini batch 623, training error = 0.09375, loss = 0.143243670463562\n","Epoch 48: finishing mini batch 624, training error = 0.03125, loss = 0.06802584230899811\n","Epoch 48: finishing mini batch 625, training error = 0.046875, loss = 0.10322047024965286\n","Epoch 48: finishing mini batch 626, training error = 0.03125, loss = 0.1262473613023758\n","Epoch 48: finishing mini batch 627, training error = 0.03125, loss = 0.06536749005317688\n","Epoch 48: finishing mini batch 628, training error = 0.0625, loss = 0.14440102875232697\n","Epoch 48: finishing mini batch 629, training error = 0.09375, loss = 0.17555660009384155\n","Epoch 48: finishing mini batch 630, training error = 0.046875, loss = 0.08592547476291656\n","Epoch 48: finishing mini batch 631, training error = 0.03125, loss = 0.07120990753173828\n","Epoch 48: finishing mini batch 632, training error = 0.046875, loss = 0.11417872458696365\n","Epoch 48: finishing mini batch 633, training error = 0.046875, loss = 0.10803158581256866\n","Epoch 48: finishing mini batch 634, training error = 0.046875, loss = 0.07132909446954727\n","Epoch 48: finishing mini batch 635, training error = 0.0, loss = 0.035589609295129776\n","Epoch 48: finishing mini batch 636, training error = 0.0, loss = 0.027960147708654404\n","Epoch 48: finishing mini batch 637, training error = 0.078125, loss = 0.12399189174175262\n","Epoch 48: finishing mini batch 638, training error = 0.03125, loss = 0.06355178356170654\n","Epoch 48: finishing mini batch 639, training error = 0.046875, loss = 0.18148458003997803\n","Epoch 48: finishing mini batch 640, training error = 0.046875, loss = 0.17651468515396118\n","Epoch 48: finishing mini batch 641, training error = 0.046875, loss = 0.07313313335180283\n","Epoch 48: finishing mini batch 642, training error = 0.0, loss = 0.04342621564865112\n","Epoch 48: finishing mini batch 643, training error = 0.046875, loss = 0.12704257667064667\n","Epoch 48: finishing mini batch 644, training error = 0.015625, loss = 0.04717418551445007\n","Epoch 48: finishing mini batch 645, training error = 0.046875, loss = 0.07722364366054535\n","Epoch 48: finishing mini batch 646, training error = 0.046875, loss = 0.16009870171546936\n","Epoch 48: finishing mini batch 647, training error = 0.0, loss = 0.029421713203191757\n","Epoch 48: finishing mini batch 648, training error = 0.0625, loss = 0.10832025110721588\n","Epoch 48: finishing mini batch 649, training error = 0.046875, loss = 0.09721050411462784\n","Epoch 48: finishing mini batch 650, training error = 0.046875, loss = 0.12071239948272705\n","Epoch 48: finishing mini batch 651, training error = 0.0625, loss = 0.20729056000709534\n","Epoch 48: finishing mini batch 652, training error = 0.03125, loss = 0.10311708599328995\n","Epoch 48: finishing mini batch 653, training error = 0.03125, loss = 0.1175425797700882\n","Epoch 48: finishing mini batch 654, training error = 0.03125, loss = 0.12803198397159576\n","Epoch 48: finishing mini batch 655, training error = 0.03125, loss = 0.060198407620191574\n","Epoch 48: finishing mini batch 656, training error = 0.015625, loss = 0.03550966456532478\n","Epoch 48: finishing mini batch 657, training error = 0.046875, loss = 0.11414118856191635\n","Epoch 48: finishing mini batch 658, training error = 0.046875, loss = 0.11773614585399628\n","Epoch 48: finishing mini batch 659, training error = 0.0625, loss = 0.13527409732341766\n","Epoch 48: finishing mini batch 660, training error = 0.046875, loss = 0.1433955878019333\n","Epoch 48: finishing mini batch 661, training error = 0.078125, loss = 0.15895290672779083\n","Epoch 48: finishing mini batch 662, training error = 0.015625, loss = 0.11523566395044327\n","Epoch 48: finishing mini batch 663, training error = 0.046875, loss = 0.1266370564699173\n","Epoch 48: finishing mini batch 664, training error = 0.03125, loss = 0.08196509629487991\n","Epoch 48: finishing mini batch 665, training error = 0.03125, loss = 0.11425373703241348\n","Epoch 48: finishing mini batch 666, training error = 0.078125, loss = 0.14559803903102875\n","Epoch 48: finishing mini batch 667, training error = 0.0625, loss = 0.12646496295928955\n","Epoch 48: finishing mini batch 668, training error = 0.03125, loss = 0.10737722367048264\n","Epoch 48: finishing mini batch 669, training error = 0.078125, loss = 0.2934544086456299\n","Epoch 48: finishing mini batch 670, training error = 0.0625, loss = 0.19413752853870392\n","Epoch 48: finishing mini batch 671, training error = 0.03125, loss = 0.11233389377593994\n","Epoch 48: finishing mini batch 672, training error = 0.0625, loss = 0.22121009230613708\n","Epoch 48: finishing mini batch 673, training error = 0.03125, loss = 0.1393011063337326\n","Epoch 48: finishing mini batch 674, training error = 0.09375, loss = 0.1363273561000824\n","Epoch 48: finishing mini batch 675, training error = 0.046875, loss = 0.1071687787771225\n","Epoch 48: finishing mini batch 676, training error = 0.046875, loss = 0.107642263174057\n","Epoch 48: finishing mini batch 677, training error = 0.09375, loss = 0.25291121006011963\n","Epoch 48: finishing mini batch 678, training error = 0.046875, loss = 0.26424452662467957\n","Epoch 48: finishing mini batch 679, training error = 0.078125, loss = 0.22395335137844086\n","Epoch 48: finishing mini batch 680, training error = 0.0625, loss = 0.2269381880760193\n","Epoch 48: finishing mini batch 681, training error = 0.015625, loss = 0.057527750730514526\n","Epoch 48: finishing mini batch 682, training error = 0.0, loss = 0.032296620309352875\n","Epoch 48: finishing mini batch 683, training error = 0.03125, loss = 0.09595052897930145\n","Epoch 48: finishing mini batch 684, training error = 0.03125, loss = 0.08995670080184937\n","Epoch 48: finishing mini batch 685, training error = 0.015625, loss = 0.05018847435712814\n","Epoch 48: finishing mini batch 686, training error = 0.015625, loss = 0.066825270652771\n","Epoch 48: finishing mini batch 687, training error = 0.125, loss = 0.2643163800239563\n","Epoch 48: finishing mini batch 688, training error = 0.09375, loss = 0.1584480106830597\n","Epoch 48: finishing mini batch 689, training error = 0.015625, loss = 0.060314442962408066\n","Epoch 48: finishing mini batch 690, training error = 0.015625, loss = 0.04946994036436081\n","Epoch 48: finishing mini batch 691, training error = 0.09375, loss = 0.18472573161125183\n","Epoch 48: finishing mini batch 692, training error = 0.078125, loss = 0.19263935089111328\n","Epoch 48: finishing mini batch 693, training error = 0.03125, loss = 0.10523205995559692\n","Epoch 48: finishing mini batch 694, training error = 0.015625, loss = 0.05653312802314758\n","Epoch 48: finishing mini batch 695, training error = 0.0625, loss = 0.1800324022769928\n","Epoch 48: finishing mini batch 696, training error = 0.125, loss = 0.2809029519557953\n","Epoch 48: finishing mini batch 697, training error = 0.046875, loss = 0.12040719389915466\n","Epoch 48: finishing mini batch 698, training error = 0.015625, loss = 0.028683338314294815\n","Epoch 48: finishing mini batch 699, training error = 0.03125, loss = 0.08985558897256851\n","Epoch 48: finishing mini batch 700, training error = 0.078125, loss = 0.3178071081638336\n","Epoch 48: finishing mini batch 701, training error = 0.078125, loss = 0.2622987926006317\n","Epoch 48: finishing mini batch 702, training error = 0.046875, loss = 0.1026453748345375\n","Epoch 48: finishing mini batch 703, training error = 0.078125, loss = 0.1193729043006897\n","Epoch 48: finishing mini batch 704, training error = 0.0625, loss = 0.193900927901268\n","Epoch 48: finishing mini batch 705, training error = 0.109375, loss = 0.30046072602272034\n","Epoch 48: finishing mini batch 706, training error = 0.125, loss = 0.24702319502830505\n","Epoch 48: finishing mini batch 707, training error = 0.0625, loss = 0.12002181261777878\n","Epoch 48: finishing mini batch 708, training error = 0.0625, loss = 0.19377921521663666\n","Epoch 48: finishing mini batch 709, training error = 0.046875, loss = 0.12982968986034393\n","Epoch 48: finishing mini batch 710, training error = 0.03125, loss = 0.09491993486881256\n","Epoch 48: finishing mini batch 711, training error = 0.03125, loss = 0.06084020435810089\n","Epoch 48: finishing mini batch 712, training error = 0.078125, loss = 0.1834729015827179\n","Epoch 48: finishing mini batch 713, training error = 0.046875, loss = 0.1000942662358284\n","Epoch 48: finishing mini batch 714, training error = 0.0625, loss = 0.16644889116287231\n","Epoch 48: finishing mini batch 715, training error = 0.046875, loss = 0.13051101565361023\n","Epoch 48: finishing mini batch 716, training error = 0.09375, loss = 0.18398162722587585\n","Epoch 48: finishing mini batch 717, training error = 0.0625, loss = 0.16209086775779724\n","Epoch 48: finishing mini batch 718, training error = 0.015625, loss = 0.04563450068235397\n","Epoch 48: finishing mini batch 719, training error = 0.0625, loss = 0.17556488513946533\n","Epoch 48: finishing mini batch 720, training error = 0.125, loss = 0.22839857637882233\n","Epoch 48: finishing mini batch 721, training error = 0.078125, loss = 0.17247532308101654\n","Epoch 48: finishing mini batch 722, training error = 0.09375, loss = 0.19811902940273285\n","Epoch 48: finishing mini batch 723, training error = 0.0625, loss = 0.22079236805438995\n","Epoch 48: finishing mini batch 724, training error = 0.046875, loss = 0.23055195808410645\n","Epoch 48: finishing mini batch 725, training error = 0.0625, loss = 0.23717175424098969\n","Epoch 48: finishing mini batch 726, training error = 0.0625, loss = 0.13141515851020813\n","Epoch 48: finishing mini batch 727, training error = 0.015625, loss = 0.07339822500944138\n","Epoch 48: finishing mini batch 728, training error = 0.046875, loss = 0.15753962099552155\n","Epoch 48: finishing mini batch 729, training error = 0.046875, loss = 0.1503097265958786\n","Epoch 48: finishing mini batch 730, training error = 0.078125, loss = 0.19485893845558167\n","Epoch 48: finishing mini batch 731, training error = 0.03125, loss = 0.18800880014896393\n","Epoch 48: finishing mini batch 732, training error = 0.0625, loss = 0.2059726119041443\n","Epoch 48: finishing mini batch 733, training error = 0.046875, loss = 0.11016818135976791\n","Epoch 48: finishing mini batch 734, training error = 0.046875, loss = 0.11922585964202881\n","Epoch 48: finishing mini batch 735, training error = 0.078125, loss = 0.14845213294029236\n","Epoch 48: finishing mini batch 736, training error = 0.015625, loss = 0.1062750294804573\n","Epoch 48: finishing mini batch 737, training error = 0.0625, loss = 0.12361688911914825\n","Epoch 48: finishing mini batch 738, training error = 0.0625, loss = 0.13077586889266968\n","Epoch 48: finishing mini batch 739, training error = 0.046875, loss = 0.1636819988489151\n","Epoch 48: finishing mini batch 740, training error = 0.09375, loss = 0.18709562718868256\n","Epoch 48: finishing mini batch 741, training error = 0.03125, loss = 0.09107398241758347\n","Epoch 48: finishing mini batch 742, training error = 0.015625, loss = 0.0675201565027237\n","Epoch 48: finishing mini batch 743, training error = 0.03125, loss = 0.07836241275072098\n","Epoch 48: finishing mini batch 744, training error = 0.046875, loss = 0.1498607099056244\n","Epoch 48: finishing mini batch 745, training error = 0.015625, loss = 0.048181742429733276\n","Epoch 48: finishing mini batch 746, training error = 0.03125, loss = 0.06519166380167007\n","Epoch 48: finishing mini batch 747, training error = 0.0, loss = 0.057653963565826416\n","Epoch 48: finishing mini batch 748, training error = 0.03125, loss = 0.10389009118080139\n","Epoch 48: finishing mini batch 749, training error = 0.03125, loss = 0.13318350911140442\n","Epoch 48: finishing mini batch 750, training error = 0.046875, loss = 0.1549907773733139\n","Epoch 48: finishing mini batch 751, training error = 0.046875, loss = 0.17508533596992493\n","Epoch 48: finishing mini batch 752, training error = 0.078125, loss = 0.2095227688550949\n","Epoch 48: finishing mini batch 753, training error = 0.0625, loss = 0.16699999570846558\n","Epoch 48: finishing mini batch 754, training error = 0.03125, loss = 0.10475233942270279\n","Epoch 48: finishing mini batch 755, training error = 0.0625, loss = 0.14766201376914978\n","Epoch 48: finishing mini batch 756, training error = 0.078125, loss = 0.18542207777500153\n","Epoch 48: finishing mini batch 757, training error = 0.03125, loss = 0.13769026100635529\n","Epoch 48: finishing mini batch 758, training error = 0.0625, loss = 0.17392179369926453\n","Epoch 48: finishing mini batch 759, training error = 0.046875, loss = 0.12669329345226288\n","Epoch 48: finishing mini batch 760, training error = 0.0625, loss = 0.17688193917274475\n","Epoch 48: finishing mini batch 761, training error = 0.0625, loss = 0.1472741812467575\n","Epoch 48: finishing mini batch 762, training error = 0.109375, loss = 0.20863249897956848\n","Epoch 48: finishing mini batch 763, training error = 0.078125, loss = 0.200282484292984\n","Epoch 48: finishing mini batch 764, training error = 0.03125, loss = 0.08700580894947052\n","Epoch 48: finishing mini batch 765, training error = 0.046875, loss = 0.10015422850847244\n","Epoch 48: finishing mini batch 766, training error = 0.03125, loss = 0.09360428154468536\n","Epoch 48: finishing mini batch 767, training error = 0.03125, loss = 0.0654301568865776\n","Epoch 48: finishing mini batch 768, training error = 0.0, loss = 0.05446809157729149\n","Epoch 48: finishing mini batch 769, training error = 0.03125, loss = 0.061107147485017776\n","Epoch 48: finishing mini batch 770, training error = 0.015625, loss = 0.11502400785684586\n","Epoch 48: finishing mini batch 771, training error = 0.015625, loss = 0.04759058356285095\n","Epoch 48: finishing mini batch 772, training error = 0.109375, loss = 0.1958523392677307\n","Epoch 48: finishing mini batch 773, training error = 0.015625, loss = 0.06624361127614975\n","Epoch 48: finishing mini batch 774, training error = 0.046875, loss = 0.13352122902870178\n","Epoch 48: finishing mini batch 775, training error = 0.09375, loss = 0.19831609725952148\n","Epoch 48: finishing mini batch 776, training error = 0.0625, loss = 0.19287961721420288\n","Epoch 48: finishing mini batch 777, training error = 0.03125, loss = 0.100450798869133\n","Epoch 48: finishing mini batch 778, training error = 0.0625, loss = 0.10679848492145538\n","Epoch 48: finishing mini batch 779, training error = 0.046875, loss = 0.14755137264728546\n","Epoch 48: finishing mini batch 780, training error = 0.03125, loss = 0.07332098484039307\n","Epoch 48: finishing mini batch 781, training error = 0.015625, loss = 0.08386272937059402\n","Epoch 48: finishing mini batch 782, training error = 0.0, loss = 0.01576298102736473\n","Epoch 48 completed, acc_loss = 95.23492535762489\n","Starting epoch 49...\n","Epoch 49: finishing mini batch 1, training error = 0.015625, loss = 0.1275307685136795\n","Epoch 49: finishing mini batch 2, training error = 0.09375, loss = 0.2212037444114685\n","Epoch 49: finishing mini batch 3, training error = 0.03125, loss = 0.12911437451839447\n","Epoch 49: finishing mini batch 4, training error = 0.046875, loss = 0.08673594892024994\n","Epoch 49: finishing mini batch 5, training error = 0.078125, loss = 0.3003676235675812\n","Epoch 49: finishing mini batch 6, training error = 0.078125, loss = 0.1667560487985611\n","Epoch 49: finishing mini batch 7, training error = 0.078125, loss = 0.22270238399505615\n","Epoch 49: finishing mini batch 8, training error = 0.015625, loss = 0.044504933059215546\n","Epoch 49: finishing mini batch 9, training error = 0.0625, loss = 0.10209628194570541\n","Epoch 49: finishing mini batch 10, training error = 0.046875, loss = 0.11712733656167984\n","Epoch 49: finishing mini batch 11, training error = 0.078125, loss = 0.16249537467956543\n","Epoch 49: finishing mini batch 12, training error = 0.09375, loss = 0.18800903856754303\n","Epoch 49: finishing mini batch 13, training error = 0.03125, loss = 0.06599285453557968\n","Epoch 49: finishing mini batch 14, training error = 0.046875, loss = 0.1136704534292221\n","Epoch 49: finishing mini batch 15, training error = 0.046875, loss = 0.10662329941987991\n","Epoch 49: finishing mini batch 16, training error = 0.03125, loss = 0.08120220899581909\n","Epoch 49: finishing mini batch 17, training error = 0.046875, loss = 0.07180064916610718\n","Epoch 49: finishing mini batch 18, training error = 0.0625, loss = 0.12861648201942444\n","Epoch 49: finishing mini batch 19, training error = 0.078125, loss = 0.1814326047897339\n","Epoch 49: finishing mini batch 20, training error = 0.046875, loss = 0.10579721629619598\n","Epoch 49: finishing mini batch 21, training error = 0.03125, loss = 0.07163427770137787\n","Epoch 49: finishing mini batch 22, training error = 0.046875, loss = 0.11187735199928284\n","Epoch 49: finishing mini batch 23, training error = 0.015625, loss = 0.07421717792749405\n","Epoch 49: finishing mini batch 24, training error = 0.015625, loss = 0.07116344571113586\n","Epoch 49: finishing mini batch 25, training error = 0.046875, loss = 0.10490285605192184\n","Epoch 49: finishing mini batch 26, training error = 0.03125, loss = 0.09096498787403107\n","Epoch 49: finishing mini batch 27, training error = 0.015625, loss = 0.0638476014137268\n","Epoch 49: finishing mini batch 28, training error = 0.03125, loss = 0.05486023426055908\n","Epoch 49: finishing mini batch 29, training error = 0.03125, loss = 0.10554655641317368\n","Epoch 49: finishing mini batch 30, training error = 0.015625, loss = 0.07601422816514969\n","Epoch 49: finishing mini batch 31, training error = 0.03125, loss = 0.09118557721376419\n","Epoch 49: finishing mini batch 32, training error = 0.046875, loss = 0.09437137842178345\n","Epoch 49: finishing mini batch 33, training error = 0.015625, loss = 0.06742262095212936\n","Epoch 49: finishing mini batch 34, training error = 0.03125, loss = 0.09333837032318115\n","Epoch 49: finishing mini batch 35, training error = 0.015625, loss = 0.051860686391592026\n","Epoch 49: finishing mini batch 36, training error = 0.0625, loss = 0.12844304740428925\n","Epoch 49: finishing mini batch 37, training error = 0.03125, loss = 0.06459009647369385\n","Epoch 49: finishing mini batch 38, training error = 0.03125, loss = 0.11473091691732407\n","Epoch 49: finishing mini batch 39, training error = 0.015625, loss = 0.07160253822803497\n","Epoch 49: finishing mini batch 40, training error = 0.125, loss = 0.2293136864900589\n","Epoch 49: finishing mini batch 41, training error = 0.03125, loss = 0.09938003867864609\n","Epoch 49: finishing mini batch 42, training error = 0.015625, loss = 0.05478844419121742\n","Epoch 49: finishing mini batch 43, training error = 0.0625, loss = 0.13086530566215515\n","Epoch 49: finishing mini batch 44, training error = 0.0, loss = 0.04432512819766998\n","Epoch 49: finishing mini batch 45, training error = 0.03125, loss = 0.08014293015003204\n","Epoch 49: finishing mini batch 46, training error = 0.015625, loss = 0.045669443905353546\n","Epoch 49: finishing mini batch 47, training error = 0.03125, loss = 0.09301523119211197\n","Epoch 49: finishing mini batch 48, training error = 0.0, loss = 0.023852413520216942\n","Epoch 49: finishing mini batch 49, training error = 0.03125, loss = 0.09375042468309402\n","Epoch 49: finishing mini batch 50, training error = 0.015625, loss = 0.09238560497760773\n","Epoch 49: finishing mini batch 51, training error = 0.03125, loss = 0.10936487466096878\n","Epoch 49: finishing mini batch 52, training error = 0.015625, loss = 0.08331210911273956\n","Epoch 49: finishing mini batch 53, training error = 0.0625, loss = 0.0969230979681015\n","Epoch 49: finishing mini batch 54, training error = 0.015625, loss = 0.05728878825902939\n","Epoch 49: finishing mini batch 55, training error = 0.015625, loss = 0.054460909217596054\n","Epoch 49: finishing mini batch 56, training error = 0.0, loss = 0.05080072581768036\n","Epoch 49: finishing mini batch 57, training error = 0.0625, loss = 0.1485668271780014\n","Epoch 49: finishing mini batch 58, training error = 0.03125, loss = 0.11064812541007996\n","Epoch 49: finishing mini batch 59, training error = 0.015625, loss = 0.08723674714565277\n","Epoch 49: finishing mini batch 60, training error = 0.03125, loss = 0.0554690957069397\n","Epoch 49: finishing mini batch 61, training error = 0.0, loss = 0.030023545026779175\n","Epoch 49: finishing mini batch 62, training error = 0.046875, loss = 0.07638059556484222\n","Epoch 49: finishing mini batch 63, training error = 0.0625, loss = 0.1369328796863556\n","Epoch 49: finishing mini batch 64, training error = 0.0, loss = 0.030880140140652657\n","Epoch 49: finishing mini batch 65, training error = 0.0, loss = 0.016986431553959846\n","Epoch 49: finishing mini batch 66, training error = 0.03125, loss = 0.0578128919005394\n","Epoch 49: finishing mini batch 67, training error = 0.015625, loss = 0.033505555242300034\n","Epoch 49: finishing mini batch 68, training error = 0.015625, loss = 0.07632558792829514\n","Epoch 49: finishing mini batch 69, training error = 0.0, loss = 0.02353813126683235\n","Epoch 49: finishing mini batch 70, training error = 0.015625, loss = 0.0503503754734993\n","Epoch 49: finishing mini batch 71, training error = 0.046875, loss = 0.08978214859962463\n","Epoch 49: finishing mini batch 72, training error = 0.03125, loss = 0.11635517328977585\n","Epoch 49: finishing mini batch 73, training error = 0.0625, loss = 0.15240386128425598\n","Epoch 49: finishing mini batch 74, training error = 0.03125, loss = 0.10415950417518616\n","Epoch 49: finishing mini batch 75, training error = 0.03125, loss = 0.05462145805358887\n","Epoch 49: finishing mini batch 76, training error = 0.03125, loss = 0.07278213649988174\n","Epoch 49: finishing mini batch 77, training error = 0.046875, loss = 0.14924007654190063\n","Epoch 49: finishing mini batch 78, training error = 0.046875, loss = 0.1018047109246254\n","Epoch 49: finishing mini batch 79, training error = 0.0625, loss = 0.09850476682186127\n","Epoch 49: finishing mini batch 80, training error = 0.015625, loss = 0.03013642504811287\n","Epoch 49: finishing mini batch 81, training error = 0.015625, loss = 0.04139798879623413\n","Epoch 49: finishing mini batch 82, training error = 0.03125, loss = 0.10651879757642746\n","Epoch 49: finishing mini batch 83, training error = 0.046875, loss = 0.0674196258187294\n","Epoch 49: finishing mini batch 84, training error = 0.046875, loss = 0.07155835628509521\n","Epoch 49: finishing mini batch 85, training error = 0.0, loss = 0.029431177303195\n","Epoch 49: finishing mini batch 86, training error = 0.015625, loss = 0.05620116367936134\n","Epoch 49: finishing mini batch 87, training error = 0.015625, loss = 0.04748459532856941\n","Epoch 49: finishing mini batch 88, training error = 0.0, loss = 0.03542979061603546\n","Epoch 49: finishing mini batch 89, training error = 0.0, loss = 0.026900434866547585\n","Epoch 49: finishing mini batch 90, training error = 0.03125, loss = 0.06369513273239136\n","Epoch 49: finishing mini batch 91, training error = 0.03125, loss = 0.1422676146030426\n","Epoch 49: finishing mini batch 92, training error = 0.03125, loss = 0.09314202517271042\n","Epoch 49: finishing mini batch 93, training error = 0.015625, loss = 0.0651763305068016\n","Epoch 49: finishing mini batch 94, training error = 0.015625, loss = 0.051819078624248505\n","Epoch 49: finishing mini batch 95, training error = 0.015625, loss = 0.06139805540442467\n","Epoch 49: finishing mini batch 96, training error = 0.03125, loss = 0.05412307381629944\n","Epoch 49: finishing mini batch 97, training error = 0.03125, loss = 0.12529762089252472\n","Epoch 49: finishing mini batch 98, training error = 0.03125, loss = 0.04880187660455704\n","Epoch 49: finishing mini batch 99, training error = 0.0, loss = 0.027463259175419807\n","Epoch 49: finishing mini batch 100, training error = 0.015625, loss = 0.07366666942834854\n","Epoch 49: finishing mini batch 101, training error = 0.015625, loss = 0.06658248603343964\n","Epoch 49: finishing mini batch 102, training error = 0.046875, loss = 0.12809182703495026\n","Epoch 49: finishing mini batch 103, training error = 0.015625, loss = 0.04221096262335777\n","Epoch 49: finishing mini batch 104, training error = 0.0, loss = 0.01893605850636959\n","Epoch 49: finishing mini batch 105, training error = 0.0, loss = 0.02554059959948063\n","Epoch 49: finishing mini batch 106, training error = 0.0625, loss = 0.142013281583786\n","Epoch 49: finishing mini batch 107, training error = 0.046875, loss = 0.22360670566558838\n","Epoch 49: finishing mini batch 108, training error = 0.015625, loss = 0.04885198548436165\n","Epoch 49: finishing mini batch 109, training error = 0.0, loss = 0.019285768270492554\n","Epoch 49: finishing mini batch 110, training error = 0.015625, loss = 0.061570264399051666\n","Epoch 49: finishing mini batch 111, training error = 0.03125, loss = 0.08296066522598267\n","Epoch 49: finishing mini batch 112, training error = 0.046875, loss = 0.1526481956243515\n","Epoch 49: finishing mini batch 113, training error = 0.03125, loss = 0.11977855861186981\n","Epoch 49: finishing mini batch 114, training error = 0.015625, loss = 0.04862135648727417\n","Epoch 49: finishing mini batch 115, training error = 0.015625, loss = 0.06662283092737198\n","Epoch 49: finishing mini batch 116, training error = 0.0625, loss = 0.16484703123569489\n","Epoch 49: finishing mini batch 117, training error = 0.03125, loss = 0.048566412180662155\n","Epoch 49: finishing mini batch 118, training error = 0.046875, loss = 0.1342313289642334\n","Epoch 49: finishing mini batch 119, training error = 0.046875, loss = 0.119664765894413\n","Epoch 49: finishing mini batch 120, training error = 0.046875, loss = 0.07153166830539703\n","Epoch 49: finishing mini batch 121, training error = 0.03125, loss = 0.06937908381223679\n","Epoch 49: finishing mini batch 122, training error = 0.015625, loss = 0.09171292930841446\n","Epoch 49: finishing mini batch 123, training error = 0.015625, loss = 0.046905867755413055\n","Epoch 49: finishing mini batch 124, training error = 0.0, loss = 0.01023910753428936\n","Epoch 49: finishing mini batch 125, training error = 0.015625, loss = 0.0402669794857502\n","Epoch 49: finishing mini batch 126, training error = 0.078125, loss = 0.17012040317058563\n","Epoch 49: finishing mini batch 127, training error = 0.015625, loss = 0.03830287605524063\n","Epoch 49: finishing mini batch 128, training error = 0.015625, loss = 0.05875203758478165\n","Epoch 49: finishing mini batch 129, training error = 0.0, loss = 0.022085269913077354\n","Epoch 49: finishing mini batch 130, training error = 0.03125, loss = 0.08784830570220947\n","Epoch 49: finishing mini batch 131, training error = 0.03125, loss = 0.05642964318394661\n","Epoch 49: finishing mini batch 132, training error = 0.015625, loss = 0.0388789027929306\n","Epoch 49: finishing mini batch 133, training error = 0.0625, loss = 0.13302479684352875\n","Epoch 49: finishing mini batch 134, training error = 0.046875, loss = 0.12182357907295227\n","Epoch 49: finishing mini batch 135, training error = 0.015625, loss = 0.03870195895433426\n","Epoch 49: finishing mini batch 136, training error = 0.046875, loss = 0.16084766387939453\n","Epoch 49: finishing mini batch 137, training error = 0.015625, loss = 0.05617998167872429\n","Epoch 49: finishing mini batch 138, training error = 0.0, loss = 0.018452391028404236\n","Epoch 49: finishing mini batch 139, training error = 0.03125, loss = 0.08796368539333344\n","Epoch 49: finishing mini batch 140, training error = 0.0, loss = 0.03511922061443329\n","Epoch 49: finishing mini batch 141, training error = 0.015625, loss = 0.10369008779525757\n","Epoch 49: finishing mini batch 142, training error = 0.015625, loss = 0.052897389978170395\n","Epoch 49: finishing mini batch 143, training error = 0.0, loss = 0.032915983349084854\n","Epoch 49: finishing mini batch 144, training error = 0.0625, loss = 0.13751398026943207\n","Epoch 49: finishing mini batch 145, training error = 0.015625, loss = 0.08648078143596649\n","Epoch 49: finishing mini batch 146, training error = 0.046875, loss = 0.11548619717359543\n","Epoch 49: finishing mini batch 147, training error = 0.046875, loss = 0.08700518310070038\n","Epoch 49: finishing mini batch 148, training error = 0.03125, loss = 0.0771370530128479\n","Epoch 49: finishing mini batch 149, training error = 0.015625, loss = 0.0851065143942833\n","Epoch 49: finishing mini batch 150, training error = 0.0, loss = 0.0207991786301136\n","Epoch 49: finishing mini batch 151, training error = 0.015625, loss = 0.055155396461486816\n","Epoch 49: finishing mini batch 152, training error = 0.03125, loss = 0.06754953414201736\n","Epoch 49: finishing mini batch 153, training error = 0.03125, loss = 0.14212124049663544\n","Epoch 49: finishing mini batch 154, training error = 0.0, loss = 0.016345074400305748\n","Epoch 49: finishing mini batch 155, training error = 0.09375, loss = 0.18243451416492462\n","Epoch 49: finishing mini batch 156, training error = 0.015625, loss = 0.0436871312558651\n","Epoch 49: finishing mini batch 157, training error = 0.015625, loss = 0.037589795887470245\n","Epoch 49: finishing mini batch 158, training error = 0.015625, loss = 0.0473921000957489\n","Epoch 49: finishing mini batch 159, training error = 0.0, loss = 0.026641959324479103\n","Epoch 49: finishing mini batch 160, training error = 0.015625, loss = 0.06061554327607155\n","Epoch 49: finishing mini batch 161, training error = 0.03125, loss = 0.0597180612385273\n","Epoch 49: finishing mini batch 162, training error = 0.0625, loss = 0.1178753450512886\n","Epoch 49: finishing mini batch 163, training error = 0.015625, loss = 0.05412999168038368\n","Epoch 49: finishing mini batch 164, training error = 0.0, loss = 0.039639733731746674\n","Epoch 49: finishing mini batch 165, training error = 0.015625, loss = 0.04097668081521988\n","Epoch 49: finishing mini batch 166, training error = 0.046875, loss = 0.143915593624115\n","Epoch 49: finishing mini batch 167, training error = 0.0625, loss = 0.11466633528470993\n","Epoch 49: finishing mini batch 168, training error = 0.015625, loss = 0.07007576525211334\n","Epoch 49: finishing mini batch 169, training error = 0.015625, loss = 0.04059182107448578\n","Epoch 49: finishing mini batch 170, training error = 0.046875, loss = 0.07778605818748474\n","Epoch 49: finishing mini batch 171, training error = 0.015625, loss = 0.05839034169912338\n","Epoch 49: finishing mini batch 172, training error = 0.0625, loss = 0.10812337696552277\n","Epoch 49: finishing mini batch 173, training error = 0.0625, loss = 0.07533665001392365\n","Epoch 49: finishing mini batch 174, training error = 0.0625, loss = 0.13411389291286469\n","Epoch 49: finishing mini batch 175, training error = 0.046875, loss = 0.08232405036687851\n","Epoch 49: finishing mini batch 176, training error = 0.03125, loss = 0.06415959447622299\n","Epoch 49: finishing mini batch 177, training error = 0.046875, loss = 0.12044741958379745\n","Epoch 49: finishing mini batch 178, training error = 0.0, loss = 0.041230276226997375\n","Epoch 49: finishing mini batch 179, training error = 0.015625, loss = 0.06264816224575043\n","Epoch 49: finishing mini batch 180, training error = 0.015625, loss = 0.04038640484213829\n","Epoch 49: finishing mini batch 181, training error = 0.03125, loss = 0.059711720794439316\n","Epoch 49: finishing mini batch 182, training error = 0.015625, loss = 0.04863548278808594\n","Epoch 49: finishing mini batch 183, training error = 0.015625, loss = 0.07981094717979431\n","Epoch 49: finishing mini batch 184, training error = 0.0, loss = 0.021626101806759834\n","Epoch 49: finishing mini batch 185, training error = 0.046875, loss = 0.10517656058073044\n","Epoch 49: finishing mini batch 186, training error = 0.078125, loss = 0.15850546956062317\n","Epoch 49: finishing mini batch 187, training error = 0.0, loss = 0.023894326761364937\n","Epoch 49: finishing mini batch 188, training error = 0.0, loss = 0.028990667313337326\n","Epoch 49: finishing mini batch 189, training error = 0.0, loss = 0.0447782427072525\n","Epoch 49: finishing mini batch 190, training error = 0.03125, loss = 0.061832327395677567\n","Epoch 49: finishing mini batch 191, training error = 0.0, loss = 0.037502091377973557\n","Epoch 49: finishing mini batch 192, training error = 0.015625, loss = 0.05177408084273338\n","Epoch 49: finishing mini batch 193, training error = 0.046875, loss = 0.07105553150177002\n","Epoch 49: finishing mini batch 194, training error = 0.0625, loss = 0.11445897817611694\n","Epoch 49: finishing mini batch 195, training error = 0.0, loss = 0.007458133157342672\n","Epoch 49: finishing mini batch 196, training error = 0.03125, loss = 0.07948843389749527\n","Epoch 49: finishing mini batch 197, training error = 0.015625, loss = 0.04953399673104286\n","Epoch 49: finishing mini batch 198, training error = 0.046875, loss = 0.15907084941864014\n","Epoch 49: finishing mini batch 199, training error = 0.0, loss = 0.03371487185359001\n","Epoch 49: finishing mini batch 200, training error = 0.015625, loss = 0.029369622468948364\n","Epoch 49: finishing mini batch 201, training error = 0.03125, loss = 0.07958313822746277\n","Epoch 49: finishing mini batch 202, training error = 0.0, loss = 0.04422825947403908\n","Epoch 49: finishing mini batch 203, training error = 0.0, loss = 0.05849562957882881\n","Epoch 49: finishing mini batch 204, training error = 0.046875, loss = 0.1596726030111313\n","Epoch 49: finishing mini batch 205, training error = 0.0625, loss = 0.11055710166692734\n","Epoch 49: finishing mini batch 206, training error = 0.03125, loss = 0.08433589339256287\n","Epoch 49: finishing mini batch 207, training error = 0.0625, loss = 0.13338106870651245\n","Epoch 49: finishing mini batch 208, training error = 0.0, loss = 0.031084271147847176\n","Epoch 49: finishing mini batch 209, training error = 0.015625, loss = 0.06516461819410324\n","Epoch 49: finishing mini batch 210, training error = 0.03125, loss = 0.06878393143415451\n","Epoch 49: finishing mini batch 211, training error = 0.03125, loss = 0.06531533598899841\n","Epoch 49: finishing mini batch 212, training error = 0.078125, loss = 0.2383122444152832\n","Epoch 49: finishing mini batch 213, training error = 0.0, loss = 0.03199409320950508\n","Epoch 49: finishing mini batch 214, training error = 0.015625, loss = 0.048079077154397964\n","Epoch 49: finishing mini batch 215, training error = 0.0, loss = 0.026920964941382408\n","Epoch 49: finishing mini batch 216, training error = 0.03125, loss = 0.07515649497509003\n","Epoch 49: finishing mini batch 217, training error = 0.015625, loss = 0.04360407963395119\n","Epoch 49: finishing mini batch 218, training error = 0.0, loss = 0.0481221042573452\n","Epoch 49: finishing mini batch 219, training error = 0.0, loss = 0.014833171851933002\n","Epoch 49: finishing mini batch 220, training error = 0.015625, loss = 0.04588015750050545\n","Epoch 49: finishing mini batch 221, training error = 0.015625, loss = 0.030403701588511467\n","Epoch 49: finishing mini batch 222, training error = 0.03125, loss = 0.11163391917943954\n","Epoch 49: finishing mini batch 223, training error = 0.03125, loss = 0.0506756491959095\n","Epoch 49: finishing mini batch 224, training error = 0.015625, loss = 0.036634836345911026\n","Epoch 49: finishing mini batch 225, training error = 0.046875, loss = 0.15407587587833405\n","Epoch 49: finishing mini batch 226, training error = 0.015625, loss = 0.05160248279571533\n","Epoch 49: finishing mini batch 227, training error = 0.046875, loss = 0.08975302428007126\n","Epoch 49: finishing mini batch 228, training error = 0.015625, loss = 0.054879143834114075\n","Epoch 49: finishing mini batch 229, training error = 0.03125, loss = 0.07070007175207138\n","Epoch 49: finishing mini batch 230, training error = 0.03125, loss = 0.115636445581913\n","Epoch 49: finishing mini batch 231, training error = 0.03125, loss = 0.12588171660900116\n","Epoch 49: finishing mini batch 232, training error = 0.0, loss = 0.007931822910904884\n","Epoch 49: finishing mini batch 233, training error = 0.015625, loss = 0.05896873027086258\n","Epoch 49: finishing mini batch 234, training error = 0.046875, loss = 0.08981507271528244\n","Epoch 49: finishing mini batch 235, training error = 0.0, loss = 0.028086872771382332\n","Epoch 49: finishing mini batch 236, training error = 0.046875, loss = 0.07595672458410263\n","Epoch 49: finishing mini batch 237, training error = 0.03125, loss = 0.053474437445402145\n","Epoch 49: finishing mini batch 238, training error = 0.046875, loss = 0.08986588567495346\n","Epoch 49: finishing mini batch 239, training error = 0.03125, loss = 0.0628935918211937\n","Epoch 49: finishing mini batch 240, training error = 0.015625, loss = 0.031101860105991364\n","Epoch 49: finishing mini batch 241, training error = 0.015625, loss = 0.03854963183403015\n","Epoch 49: finishing mini batch 242, training error = 0.015625, loss = 0.049909017980098724\n","Epoch 49: finishing mini batch 243, training error = 0.046875, loss = 0.07889623194932938\n","Epoch 49: finishing mini batch 244, training error = 0.046875, loss = 0.09958896040916443\n","Epoch 49: finishing mini batch 245, training error = 0.0, loss = 0.02546665444970131\n","Epoch 49: finishing mini batch 246, training error = 0.015625, loss = 0.06074037775397301\n","Epoch 49: finishing mini batch 247, training error = 0.03125, loss = 0.059739891439676285\n","Epoch 49: finishing mini batch 248, training error = 0.0, loss = 0.01912631280720234\n","Epoch 49: finishing mini batch 249, training error = 0.0, loss = 0.022149311378598213\n","Epoch 49: finishing mini batch 250, training error = 0.0, loss = 0.024239029735326767\n","Epoch 49: finishing mini batch 251, training error = 0.015625, loss = 0.027127517387270927\n","Epoch 49: finishing mini batch 252, training error = 0.03125, loss = 0.08712150156497955\n","Epoch 49: finishing mini batch 253, training error = 0.03125, loss = 0.0717519074678421\n","Epoch 49: finishing mini batch 254, training error = 0.046875, loss = 0.1016165092587471\n","Epoch 49: finishing mini batch 255, training error = 0.0625, loss = 0.13281123340129852\n","Epoch 49: finishing mini batch 256, training error = 0.046875, loss = 0.11326106637716293\n","Epoch 49: finishing mini batch 257, training error = 0.015625, loss = 0.05865452438592911\n","Epoch 49: finishing mini batch 258, training error = 0.046875, loss = 0.1685757040977478\n","Epoch 49: finishing mini batch 259, training error = 0.015625, loss = 0.05436551198363304\n","Epoch 49: finishing mini batch 260, training error = 0.015625, loss = 0.03492734208703041\n","Epoch 49: finishing mini batch 261, training error = 0.0, loss = 0.014617878943681717\n","Epoch 49: finishing mini batch 262, training error = 0.015625, loss = 0.03557128086686134\n","Epoch 49: finishing mini batch 263, training error = 0.015625, loss = 0.05331096425652504\n","Epoch 49: finishing mini batch 264, training error = 0.03125, loss = 0.12404009699821472\n","Epoch 49: finishing mini batch 265, training error = 0.0, loss = 0.013031392358243465\n","Epoch 49: finishing mini batch 266, training error = 0.046875, loss = 0.07277040183544159\n","Epoch 49: finishing mini batch 267, training error = 0.0625, loss = 0.16249914467334747\n","Epoch 49: finishing mini batch 268, training error = 0.015625, loss = 0.10320787876844406\n","Epoch 49: finishing mini batch 269, training error = 0.0, loss = 0.024244748055934906\n","Epoch 49: finishing mini batch 270, training error = 0.0, loss = 0.0292447991669178\n","Epoch 49: finishing mini batch 271, training error = 0.0625, loss = 0.11603555083274841\n","Epoch 49: finishing mini batch 272, training error = 0.03125, loss = 0.051118332892656326\n","Epoch 49: finishing mini batch 273, training error = 0.03125, loss = 0.05126043036580086\n","Epoch 49: finishing mini batch 274, training error = 0.015625, loss = 0.08587173372507095\n","Epoch 49: finishing mini batch 275, training error = 0.03125, loss = 0.09762457013130188\n","Epoch 49: finishing mini batch 276, training error = 0.03125, loss = 0.057667531073093414\n","Epoch 49: finishing mini batch 277, training error = 0.015625, loss = 0.037825725972652435\n","Epoch 49: finishing mini batch 278, training error = 0.0625, loss = 0.1895570307970047\n","Epoch 49: finishing mini batch 279, training error = 0.0, loss = 0.023312386125326157\n","Epoch 49: finishing mini batch 280, training error = 0.0, loss = 0.023503419011831284\n","Epoch 49: finishing mini batch 281, training error = 0.03125, loss = 0.06420627236366272\n","Epoch 49: finishing mini batch 282, training error = 0.03125, loss = 0.0645068883895874\n","Epoch 49: finishing mini batch 283, training error = 0.015625, loss = 0.05801674351096153\n","Epoch 49: finishing mini batch 284, training error = 0.015625, loss = 0.073366679251194\n","Epoch 49: finishing mini batch 285, training error = 0.0625, loss = 0.16231238842010498\n","Epoch 49: finishing mini batch 286, training error = 0.0625, loss = 0.21363306045532227\n","Epoch 49: finishing mini batch 287, training error = 0.03125, loss = 0.05239182710647583\n","Epoch 49: finishing mini batch 288, training error = 0.015625, loss = 0.026884756982326508\n","Epoch 49: finishing mini batch 289, training error = 0.015625, loss = 0.04924454912543297\n","Epoch 49: finishing mini batch 290, training error = 0.03125, loss = 0.06945261359214783\n","Epoch 49: finishing mini batch 291, training error = 0.0, loss = 0.03155963867902756\n","Epoch 49: finishing mini batch 292, training error = 0.0625, loss = 0.1186310276389122\n","Epoch 49: finishing mini batch 293, training error = 0.03125, loss = 0.07696132361888885\n","Epoch 49: finishing mini batch 294, training error = 0.03125, loss = 0.04507942125201225\n","Epoch 49: finishing mini batch 295, training error = 0.015625, loss = 0.06981860846281052\n","Epoch 49: finishing mini batch 296, training error = 0.03125, loss = 0.10989999771118164\n","Epoch 49: finishing mini batch 297, training error = 0.03125, loss = 0.06182388216257095\n","Epoch 49: finishing mini batch 298, training error = 0.046875, loss = 0.1266125738620758\n","Epoch 49: finishing mini batch 299, training error = 0.046875, loss = 0.07134426385164261\n","Epoch 49: finishing mini batch 300, training error = 0.015625, loss = 0.058453723788261414\n","Epoch 49: finishing mini batch 301, training error = 0.015625, loss = 0.032254211604595184\n","Epoch 49: finishing mini batch 302, training error = 0.015625, loss = 0.06590232253074646\n","Epoch 49: finishing mini batch 303, training error = 0.046875, loss = 0.07910047471523285\n","Epoch 49: finishing mini batch 304, training error = 0.015625, loss = 0.05626953765749931\n","Epoch 49: finishing mini batch 305, training error = 0.0, loss = 0.03072533942759037\n","Epoch 49: finishing mini batch 306, training error = 0.0625, loss = 0.09550963342189789\n","Epoch 49: finishing mini batch 307, training error = 0.03125, loss = 0.09903788566589355\n","Epoch 49: finishing mini batch 308, training error = 0.015625, loss = 0.052637070417404175\n","Epoch 49: finishing mini batch 309, training error = 0.015625, loss = 0.05128070339560509\n","Epoch 49: finishing mini batch 310, training error = 0.046875, loss = 0.1078161895275116\n","Epoch 49: finishing mini batch 311, training error = 0.0, loss = 0.04338261857628822\n","Epoch 49: finishing mini batch 312, training error = 0.0, loss = 0.03169368579983711\n","Epoch 49: finishing mini batch 313, training error = 0.0, loss = 0.02114020101726055\n","Epoch 49: finishing mini batch 314, training error = 0.03125, loss = 0.029147375375032425\n","Epoch 49: finishing mini batch 315, training error = 0.015625, loss = 0.05332885682582855\n","Epoch 49: finishing mini batch 316, training error = 0.015625, loss = 0.054269418120384216\n","Epoch 49: finishing mini batch 317, training error = 0.015625, loss = 0.052916839718818665\n","Epoch 49: finishing mini batch 318, training error = 0.015625, loss = 0.05021488294005394\n","Epoch 49: finishing mini batch 319, training error = 0.015625, loss = 0.058537594974040985\n","Epoch 49: finishing mini batch 320, training error = 0.046875, loss = 0.11079463362693787\n","Epoch 49: finishing mini batch 321, training error = 0.078125, loss = 0.13319487869739532\n","Epoch 49: finishing mini batch 322, training error = 0.046875, loss = 0.09365808963775635\n","Epoch 49: finishing mini batch 323, training error = 0.03125, loss = 0.10608983784914017\n","Epoch 49: finishing mini batch 324, training error = 0.03125, loss = 0.07207087427377701\n","Epoch 49: finishing mini batch 325, training error = 0.015625, loss = 0.055007077753543854\n","Epoch 49: finishing mini batch 326, training error = 0.046875, loss = 0.11170220375061035\n","Epoch 49: finishing mini batch 327, training error = 0.015625, loss = 0.08008193224668503\n","Epoch 49: finishing mini batch 328, training error = 0.015625, loss = 0.06630846858024597\n","Epoch 49: finishing mini batch 329, training error = 0.015625, loss = 0.031722553074359894\n","Epoch 49: finishing mini batch 330, training error = 0.03125, loss = 0.09542325884103775\n","Epoch 49: finishing mini batch 331, training error = 0.0625, loss = 0.16482645273208618\n","Epoch 49: finishing mini batch 332, training error = 0.015625, loss = 0.08017248660326004\n","Epoch 49: finishing mini batch 333, training error = 0.03125, loss = 0.12566809356212616\n","Epoch 49: finishing mini batch 334, training error = 0.015625, loss = 0.048434577882289886\n","Epoch 49: finishing mini batch 335, training error = 0.046875, loss = 0.11743886768817902\n","Epoch 49: finishing mini batch 336, training error = 0.046875, loss = 0.16164913773536682\n","Epoch 49: finishing mini batch 337, training error = 0.046875, loss = 0.08975357562303543\n","Epoch 49: finishing mini batch 338, training error = 0.03125, loss = 0.09676168859004974\n","Epoch 49: finishing mini batch 339, training error = 0.0, loss = 0.024914834648370743\n","Epoch 49: finishing mini batch 340, training error = 0.015625, loss = 0.03437787666916847\n","Epoch 49: finishing mini batch 341, training error = 0.0, loss = 0.06380873918533325\n","Epoch 49: finishing mini batch 342, training error = 0.03125, loss = 0.05402747914195061\n","Epoch 49: finishing mini batch 343, training error = 0.03125, loss = 0.08402001112699509\n","Epoch 49: finishing mini batch 344, training error = 0.046875, loss = 0.1313098669052124\n","Epoch 49: finishing mini batch 345, training error = 0.03125, loss = 0.10803905129432678\n","Epoch 49: finishing mini batch 346, training error = 0.046875, loss = 0.07670054584741592\n","Epoch 49: finishing mini batch 347, training error = 0.015625, loss = 0.062129437923431396\n","Epoch 49: finishing mini batch 348, training error = 0.0625, loss = 0.14570800960063934\n","Epoch 49: finishing mini batch 349, training error = 0.0, loss = 0.03878670930862427\n","Epoch 49: finishing mini batch 350, training error = 0.015625, loss = 0.055700451135635376\n","Epoch 49: finishing mini batch 351, training error = 0.0625, loss = 0.1674756109714508\n","Epoch 49: finishing mini batch 352, training error = 0.0, loss = 0.02228274755179882\n","Epoch 49: finishing mini batch 353, training error = 0.03125, loss = 0.07264232635498047\n","Epoch 49: finishing mini batch 354, training error = 0.046875, loss = 0.1648779660463333\n","Epoch 49: finishing mini batch 355, training error = 0.046875, loss = 0.10205531120300293\n","Epoch 49: finishing mini batch 356, training error = 0.0, loss = 0.03177735581994057\n","Epoch 49: finishing mini batch 357, training error = 0.046875, loss = 0.09017717838287354\n","Epoch 49: finishing mini batch 358, training error = 0.03125, loss = 0.04750357195734978\n","Epoch 49: finishing mini batch 359, training error = 0.015625, loss = 0.04341493174433708\n","Epoch 49: finishing mini batch 360, training error = 0.0625, loss = 0.15799565613269806\n","Epoch 49: finishing mini batch 361, training error = 0.03125, loss = 0.070999376475811\n","Epoch 49: finishing mini batch 362, training error = 0.046875, loss = 0.1186467856168747\n","Epoch 49: finishing mini batch 363, training error = 0.078125, loss = 0.14970023930072784\n","Epoch 49: finishing mini batch 364, training error = 0.03125, loss = 0.0896090418100357\n","Epoch 49: finishing mini batch 365, training error = 0.0, loss = 0.030800987035036087\n","Epoch 49: finishing mini batch 366, training error = 0.046875, loss = 0.16202697157859802\n","Epoch 49: finishing mini batch 367, training error = 0.0625, loss = 0.1273116022348404\n","Epoch 49: finishing mini batch 368, training error = 0.03125, loss = 0.06800306588411331\n","Epoch 49: finishing mini batch 369, training error = 0.0625, loss = 0.09125279635190964\n","Epoch 49: finishing mini batch 370, training error = 0.03125, loss = 0.05999566242098808\n","Epoch 49: finishing mini batch 371, training error = 0.0, loss = 0.02597110904753208\n","Epoch 49: finishing mini batch 372, training error = 0.03125, loss = 0.05296991020441055\n","Epoch 49: finishing mini batch 373, training error = 0.03125, loss = 0.06279511004686356\n","Epoch 49: finishing mini batch 374, training error = 0.046875, loss = 0.11179646849632263\n","Epoch 49: finishing mini batch 375, training error = 0.03125, loss = 0.06579498946666718\n","Epoch 49: finishing mini batch 376, training error = 0.0625, loss = 0.17600923776626587\n","Epoch 49: finishing mini batch 377, training error = 0.046875, loss = 0.12273851037025452\n","Epoch 49: finishing mini batch 378, training error = 0.03125, loss = 0.08417671918869019\n","Epoch 49: finishing mini batch 379, training error = 0.03125, loss = 0.10886640101671219\n","Epoch 49: finishing mini batch 380, training error = 0.015625, loss = 0.05485948547720909\n","Epoch 49: finishing mini batch 381, training error = 0.03125, loss = 0.07733401656150818\n","Epoch 49: finishing mini batch 382, training error = 0.0, loss = 0.039315879344940186\n","Epoch 49: finishing mini batch 383, training error = 0.046875, loss = 0.10898250341415405\n","Epoch 49: finishing mini batch 384, training error = 0.015625, loss = 0.039070989936590195\n","Epoch 49: finishing mini batch 385, training error = 0.046875, loss = 0.11278041452169418\n","Epoch 49: finishing mini batch 386, training error = 0.03125, loss = 0.12167360633611679\n","Epoch 49: finishing mini batch 387, training error = 0.078125, loss = 0.10218313336372375\n","Epoch 49: finishing mini batch 388, training error = 0.0, loss = 0.04337966814637184\n","Epoch 49: finishing mini batch 389, training error = 0.03125, loss = 0.10383789241313934\n","Epoch 49: finishing mini batch 390, training error = 0.03125, loss = 0.08701043576002121\n","Epoch 49: finishing mini batch 391, training error = 0.046875, loss = 0.16343934834003448\n","Epoch 49: finishing mini batch 392, training error = 0.03125, loss = 0.10167625546455383\n","Epoch 49: finishing mini batch 393, training error = 0.03125, loss = 0.09390095621347427\n","Epoch 49: finishing mini batch 394, training error = 0.03125, loss = 0.08037062734365463\n","Epoch 49: finishing mini batch 395, training error = 0.03125, loss = 0.0780177190899849\n","Epoch 49: finishing mini batch 396, training error = 0.046875, loss = 0.09258580952882767\n","Epoch 49: finishing mini batch 397, training error = 0.046875, loss = 0.14478637278079987\n","Epoch 49: finishing mini batch 398, training error = 0.03125, loss = 0.1044696494936943\n","Epoch 49: finishing mini batch 399, training error = 0.078125, loss = 0.2109224498271942\n","Epoch 49: finishing mini batch 400, training error = 0.046875, loss = 0.10226600617170334\n","Epoch 49: finishing mini batch 401, training error = 0.015625, loss = 0.04250616207718849\n","Epoch 49: finishing mini batch 402, training error = 0.0, loss = 0.03207787498831749\n","Epoch 49: finishing mini batch 403, training error = 0.03125, loss = 0.06753098219633102\n","Epoch 49: finishing mini batch 404, training error = 0.015625, loss = 0.0653238371014595\n","Epoch 49: finishing mini batch 405, training error = 0.046875, loss = 0.11981062591075897\n","Epoch 49: finishing mini batch 406, training error = 0.03125, loss = 0.203987717628479\n","Epoch 49: finishing mini batch 407, training error = 0.0625, loss = 0.23141276836395264\n","Epoch 49: finishing mini batch 408, training error = 0.078125, loss = 0.13806577026844025\n","Epoch 49: finishing mini batch 409, training error = 0.015625, loss = 0.047970451414585114\n","Epoch 49: finishing mini batch 410, training error = 0.0625, loss = 0.17003223299980164\n","Epoch 49: finishing mini batch 411, training error = 0.03125, loss = 0.17130562663078308\n","Epoch 49: finishing mini batch 412, training error = 0.0625, loss = 0.12891314923763275\n","Epoch 49: finishing mini batch 413, training error = 0.109375, loss = 0.1739271581172943\n","Epoch 49: finishing mini batch 414, training error = 0.03125, loss = 0.09607432782649994\n","Epoch 49: finishing mini batch 415, training error = 0.0, loss = 0.028394583612680435\n","Epoch 49: finishing mini batch 416, training error = 0.046875, loss = 0.09113126993179321\n","Epoch 49: finishing mini batch 417, training error = 0.046875, loss = 0.07749065011739731\n","Epoch 49: finishing mini batch 418, training error = 0.03125, loss = 0.14240936934947968\n","Epoch 49: finishing mini batch 419, training error = 0.015625, loss = 0.07426001131534576\n","Epoch 49: finishing mini batch 420, training error = 0.078125, loss = 0.28146377205848694\n","Epoch 49: finishing mini batch 421, training error = 0.0625, loss = 0.25904580950737\n","Epoch 49: finishing mini batch 422, training error = 0.09375, loss = 0.21747441589832306\n","Epoch 49: finishing mini batch 423, training error = 0.0625, loss = 0.20809756219387054\n","Epoch 49: finishing mini batch 424, training error = 0.015625, loss = 0.06307800114154816\n","Epoch 49: finishing mini batch 425, training error = 0.046875, loss = 0.1357346773147583\n","Epoch 49: finishing mini batch 426, training error = 0.078125, loss = 0.24728809297084808\n","Epoch 49: finishing mini batch 427, training error = 0.015625, loss = 0.07365339249372482\n","Epoch 49: finishing mini batch 428, training error = 0.046875, loss = 0.16895636916160583\n","Epoch 49: finishing mini batch 429, training error = 0.015625, loss = 0.13651828467845917\n","Epoch 49: finishing mini batch 430, training error = 0.046875, loss = 0.10813965648412704\n","Epoch 49: finishing mini batch 431, training error = 0.09375, loss = 0.19759173691272736\n","Epoch 49: finishing mini batch 432, training error = 0.0625, loss = 0.16058719158172607\n","Epoch 49: finishing mini batch 433, training error = 0.078125, loss = 0.2034589797258377\n","Epoch 49: finishing mini batch 434, training error = 0.078125, loss = 0.1775968074798584\n","Epoch 49: finishing mini batch 435, training error = 0.015625, loss = 0.05977701395750046\n","Epoch 49: finishing mini batch 436, training error = 0.046875, loss = 0.09961148351430893\n","Epoch 49: finishing mini batch 437, training error = 0.046875, loss = 0.15418066084384918\n","Epoch 49: finishing mini batch 438, training error = 0.0625, loss = 0.10701602697372437\n","Epoch 49: finishing mini batch 439, training error = 0.03125, loss = 0.07344024628400803\n","Epoch 49: finishing mini batch 440, training error = 0.046875, loss = 0.14981579780578613\n","Epoch 49: finishing mini batch 441, training error = 0.046875, loss = 0.1155710443854332\n","Epoch 49: finishing mini batch 442, training error = 0.109375, loss = 0.20264855027198792\n","Epoch 49: finishing mini batch 443, training error = 0.03125, loss = 0.1052924171090126\n","Epoch 49: finishing mini batch 444, training error = 0.03125, loss = 0.09835909307003021\n","Epoch 49: finishing mini batch 445, training error = 0.0625, loss = 0.15039168298244476\n","Epoch 49: finishing mini batch 446, training error = 0.078125, loss = 0.20319995284080505\n","Epoch 49: finishing mini batch 447, training error = 0.046875, loss = 0.08784987777471542\n","Epoch 49: finishing mini batch 448, training error = 0.078125, loss = 0.1611746847629547\n","Epoch 49: finishing mini batch 449, training error = 0.03125, loss = 0.10424765944480896\n","Epoch 49: finishing mini batch 450, training error = 0.0625, loss = 0.23366285860538483\n","Epoch 49: finishing mini batch 451, training error = 0.046875, loss = 0.12435369938611984\n","Epoch 49: finishing mini batch 452, training error = 0.0, loss = 0.045261360704898834\n","Epoch 49: finishing mini batch 453, training error = 0.015625, loss = 0.08337907493114471\n","Epoch 49: finishing mini batch 454, training error = 0.0625, loss = 0.18276432156562805\n","Epoch 49: finishing mini batch 455, training error = 0.0, loss = 0.03463507816195488\n","Epoch 49: finishing mini batch 456, training error = 0.0625, loss = 0.1971718817949295\n","Epoch 49: finishing mini batch 457, training error = 0.015625, loss = 0.06688053160905838\n","Epoch 49: finishing mini batch 458, training error = 0.046875, loss = 0.07720340043306351\n","Epoch 49: finishing mini batch 459, training error = 0.0, loss = 0.03197538107633591\n","Epoch 49: finishing mini batch 460, training error = 0.0625, loss = 0.1874561607837677\n","Epoch 49: finishing mini batch 461, training error = 0.078125, loss = 0.24365727603435516\n","Epoch 49: finishing mini batch 462, training error = 0.0625, loss = 0.18703317642211914\n","Epoch 49: finishing mini batch 463, training error = 0.015625, loss = 0.03414086997509003\n","Epoch 49: finishing mini batch 464, training error = 0.078125, loss = 0.18166393041610718\n","Epoch 49: finishing mini batch 465, training error = 0.078125, loss = 0.22675721347332\n","Epoch 49: finishing mini batch 466, training error = 0.03125, loss = 0.06603127717971802\n","Epoch 49: finishing mini batch 467, training error = 0.046875, loss = 0.12301009148359299\n","Epoch 49: finishing mini batch 468, training error = 0.03125, loss = 0.1340012550354004\n","Epoch 49: finishing mini batch 469, training error = 0.03125, loss = 0.11364306509494781\n","Epoch 49: finishing mini batch 470, training error = 0.03125, loss = 0.06746798753738403\n","Epoch 49: finishing mini batch 471, training error = 0.0625, loss = 0.15451660752296448\n","Epoch 49: finishing mini batch 472, training error = 0.078125, loss = 0.27845704555511475\n","Epoch 49: finishing mini batch 473, training error = 0.078125, loss = 0.2138049304485321\n","Epoch 49: finishing mini batch 474, training error = 0.015625, loss = 0.05891590192914009\n","Epoch 49: finishing mini batch 475, training error = 0.015625, loss = 0.08865644782781601\n","Epoch 49: finishing mini batch 476, training error = 0.015625, loss = 0.0822402611374855\n","Epoch 49: finishing mini batch 477, training error = 0.015625, loss = 0.05735355615615845\n","Epoch 49: finishing mini batch 478, training error = 0.0625, loss = 0.1513766199350357\n","Epoch 49: finishing mini batch 479, training error = 0.046875, loss = 0.14318346977233887\n","Epoch 49: finishing mini batch 480, training error = 0.078125, loss = 0.1826658993959427\n","Epoch 49: finishing mini batch 481, training error = 0.0625, loss = 0.14000840485095978\n","Epoch 49: finishing mini batch 482, training error = 0.015625, loss = 0.11009387671947479\n","Epoch 49: finishing mini batch 483, training error = 0.046875, loss = 0.0911792665719986\n","Epoch 49: finishing mini batch 484, training error = 0.015625, loss = 0.05645516514778137\n","Epoch 49: finishing mini batch 485, training error = 0.046875, loss = 0.13750334084033966\n","Epoch 49: finishing mini batch 486, training error = 0.0625, loss = 0.12915250658988953\n","Epoch 49: finishing mini batch 487, training error = 0.03125, loss = 0.09748821705579758\n","Epoch 49: finishing mini batch 488, training error = 0.015625, loss = 0.10030673444271088\n","Epoch 49: finishing mini batch 489, training error = 0.03125, loss = 0.0946924164891243\n","Epoch 49: finishing mini batch 490, training error = 0.078125, loss = 0.21611525118350983\n","Epoch 49: finishing mini batch 491, training error = 0.03125, loss = 0.0969182625412941\n","Epoch 49: finishing mini batch 492, training error = 0.015625, loss = 0.04484282433986664\n","Epoch 49: finishing mini batch 493, training error = 0.078125, loss = 0.15127040445804596\n","Epoch 49: finishing mini batch 494, training error = 0.03125, loss = 0.0896475613117218\n","Epoch 49: finishing mini batch 495, training error = 0.09375, loss = 0.16328255832195282\n","Epoch 49: finishing mini batch 496, training error = 0.0625, loss = 0.21718882024288177\n","Epoch 49: finishing mini batch 497, training error = 0.0, loss = 0.06280217319726944\n","Epoch 49: finishing mini batch 498, training error = 0.0625, loss = 0.13254648447036743\n","Epoch 49: finishing mini batch 499, training error = 0.09375, loss = 0.25387606024742126\n","Epoch 49: finishing mini batch 500, training error = 0.0625, loss = 0.13469752669334412\n","Epoch 49: finishing mini batch 501, training error = 0.046875, loss = 0.14327991008758545\n","Epoch 49: finishing mini batch 502, training error = 0.046875, loss = 0.12161587178707123\n","Epoch 49: finishing mini batch 503, training error = 0.03125, loss = 0.08803573250770569\n","Epoch 49: finishing mini batch 504, training error = 0.046875, loss = 0.11834177374839783\n","Epoch 49: finishing mini batch 505, training error = 0.0625, loss = 0.14120762050151825\n","Epoch 49: finishing mini batch 506, training error = 0.03125, loss = 0.0865074023604393\n","Epoch 49: finishing mini batch 507, training error = 0.0625, loss = 0.20200766623020172\n","Epoch 49: finishing mini batch 508, training error = 0.0625, loss = 0.22792194783687592\n","Epoch 49: finishing mini batch 509, training error = 0.03125, loss = 0.21702434122562408\n","Epoch 49: finishing mini batch 510, training error = 0.03125, loss = 0.06175052747130394\n","Epoch 49: finishing mini batch 511, training error = 0.046875, loss = 0.13817229866981506\n","Epoch 49: finishing mini batch 512, training error = 0.078125, loss = 0.15063543617725372\n","Epoch 49: finishing mini batch 513, training error = 0.09375, loss = 0.17541369795799255\n","Epoch 49: finishing mini batch 514, training error = 0.03125, loss = 0.14792294800281525\n","Epoch 49: finishing mini batch 515, training error = 0.046875, loss = 0.14779497683048248\n","Epoch 49: finishing mini batch 516, training error = 0.0625, loss = 0.1184849664568901\n","Epoch 49: finishing mini batch 517, training error = 0.0, loss = 0.03843887522816658\n","Epoch 49: finishing mini batch 518, training error = 0.046875, loss = 0.11737660318613052\n","Epoch 49: finishing mini batch 519, training error = 0.046875, loss = 0.10031968355178833\n","Epoch 49: finishing mini batch 520, training error = 0.0625, loss = 0.11196044832468033\n","Epoch 49: finishing mini batch 521, training error = 0.03125, loss = 0.08665608614683151\n","Epoch 49: finishing mini batch 522, training error = 0.0, loss = 0.026394929736852646\n","Epoch 49: finishing mini batch 523, training error = 0.046875, loss = 0.17647024989128113\n","Epoch 49: finishing mini batch 524, training error = 0.046875, loss = 0.11078917980194092\n","Epoch 49: finishing mini batch 525, training error = 0.0625, loss = 0.12502674758434296\n","Epoch 49: finishing mini batch 526, training error = 0.0625, loss = 0.14909039437770844\n","Epoch 49: finishing mini batch 527, training error = 0.109375, loss = 0.2305808663368225\n","Epoch 49: finishing mini batch 528, training error = 0.0625, loss = 0.09962411224842072\n","Epoch 49: finishing mini batch 529, training error = 0.0625, loss = 0.14536423981189728\n","Epoch 49: finishing mini batch 530, training error = 0.0625, loss = 0.24422043561935425\n","Epoch 49: finishing mini batch 531, training error = 0.0625, loss = 0.19674530625343323\n","Epoch 49: finishing mini batch 532, training error = 0.125, loss = 0.3531769812107086\n","Epoch 49: finishing mini batch 533, training error = 0.09375, loss = 0.20510876178741455\n","Epoch 49: finishing mini batch 534, training error = 0.03125, loss = 0.07466687262058258\n","Epoch 49: finishing mini batch 535, training error = 0.015625, loss = 0.06680174916982651\n","Epoch 49: finishing mini batch 536, training error = 0.078125, loss = 0.2486264854669571\n","Epoch 49: finishing mini batch 537, training error = 0.0625, loss = 0.1516522765159607\n","Epoch 49: finishing mini batch 538, training error = 0.0625, loss = 0.22937753796577454\n","Epoch 49: finishing mini batch 539, training error = 0.09375, loss = 0.1735769510269165\n","Epoch 49: finishing mini batch 540, training error = 0.0625, loss = 0.17914332449436188\n","Epoch 49: finishing mini batch 541, training error = 0.09375, loss = 0.1707776039838791\n","Epoch 49: finishing mini batch 542, training error = 0.046875, loss = 0.15902288258075714\n","Epoch 49: finishing mini batch 543, training error = 0.078125, loss = 0.3308295011520386\n","Epoch 49: finishing mini batch 544, training error = 0.0625, loss = 0.30034685134887695\n","Epoch 49: finishing mini batch 545, training error = 0.0625, loss = 0.13389408588409424\n","Epoch 49: finishing mini batch 546, training error = 0.078125, loss = 0.30748823285102844\n","Epoch 49: finishing mini batch 547, training error = 0.03125, loss = 0.1502896100282669\n","Epoch 49: finishing mini batch 548, training error = 0.09375, loss = 0.24662305414676666\n","Epoch 49: finishing mini batch 549, training error = 0.078125, loss = 0.26166221499443054\n","Epoch 49: finishing mini batch 550, training error = 0.03125, loss = 0.14146073162555695\n","Epoch 49: finishing mini batch 551, training error = 0.046875, loss = 0.11504597216844559\n","Epoch 49: finishing mini batch 552, training error = 0.015625, loss = 0.0606958344578743\n","Epoch 49: finishing mini batch 553, training error = 0.03125, loss = 0.1385359764099121\n","Epoch 49: finishing mini batch 554, training error = 0.03125, loss = 0.08378531783819199\n","Epoch 49: finishing mini batch 555, training error = 0.046875, loss = 0.12350116670131683\n","Epoch 49: finishing mini batch 556, training error = 0.046875, loss = 0.11166040599346161\n","Epoch 49: finishing mini batch 557, training error = 0.046875, loss = 0.23020072281360626\n","Epoch 49: finishing mini batch 558, training error = 0.125, loss = 0.2352195382118225\n","Epoch 49: finishing mini batch 559, training error = 0.09375, loss = 0.18425793945789337\n","Epoch 49: finishing mini batch 560, training error = 0.078125, loss = 0.15813687443733215\n","Epoch 49: finishing mini batch 561, training error = 0.015625, loss = 0.0564136765897274\n","Epoch 49: finishing mini batch 562, training error = 0.0625, loss = 0.18037037551403046\n","Epoch 49: finishing mini batch 563, training error = 0.0625, loss = 0.14557218551635742\n","Epoch 49: finishing mini batch 564, training error = 0.0625, loss = 0.17919239401817322\n","Epoch 49: finishing mini batch 565, training error = 0.0625, loss = 0.1826140582561493\n","Epoch 49: finishing mini batch 566, training error = 0.015625, loss = 0.11636237800121307\n","Epoch 49: finishing mini batch 567, training error = 0.09375, loss = 0.19026850163936615\n","Epoch 49: finishing mini batch 568, training error = 0.0625, loss = 0.19999517500400543\n","Epoch 49: finishing mini batch 569, training error = 0.078125, loss = 0.20601503551006317\n","Epoch 49: finishing mini batch 570, training error = 0.046875, loss = 0.15626539289951324\n","Epoch 49: finishing mini batch 571, training error = 0.03125, loss = 0.06913907080888748\n","Epoch 49: finishing mini batch 572, training error = 0.140625, loss = 0.25273245573043823\n","Epoch 49: finishing mini batch 573, training error = 0.046875, loss = 0.15810586512088776\n","Epoch 49: finishing mini batch 574, training error = 0.0625, loss = 0.12344547361135483\n","Epoch 49: finishing mini batch 575, training error = 0.03125, loss = 0.09339699149131775\n","Epoch 49: finishing mini batch 576, training error = 0.140625, loss = 0.34656015038490295\n","Epoch 49: finishing mini batch 577, training error = 0.078125, loss = 0.1571468859910965\n","Epoch 49: finishing mini batch 578, training error = 0.015625, loss = 0.05781067907810211\n","Epoch 49: finishing mini batch 579, training error = 0.046875, loss = 0.13606925308704376\n","Epoch 49: finishing mini batch 580, training error = 0.0625, loss = 0.12124331295490265\n","Epoch 49: finishing mini batch 581, training error = 0.046875, loss = 0.09121433645486832\n","Epoch 49: finishing mini batch 582, training error = 0.078125, loss = 0.20087853074073792\n","Epoch 49: finishing mini batch 583, training error = 0.046875, loss = 0.16501407325267792\n","Epoch 49: finishing mini batch 584, training error = 0.046875, loss = 0.206907257437706\n","Epoch 49: finishing mini batch 585, training error = 0.03125, loss = 0.05851465463638306\n","Epoch 49: finishing mini batch 586, training error = 0.09375, loss = 0.15239834785461426\n","Epoch 49: finishing mini batch 587, training error = 0.015625, loss = 0.07155442237854004\n","Epoch 49: finishing mini batch 588, training error = 0.03125, loss = 0.11182383447885513\n","Epoch 49: finishing mini batch 589, training error = 0.09375, loss = 0.187219500541687\n","Epoch 49: finishing mini batch 590, training error = 0.046875, loss = 0.11359914392232895\n","Epoch 49: finishing mini batch 591, training error = 0.015625, loss = 0.08150327205657959\n","Epoch 49: finishing mini batch 592, training error = 0.046875, loss = 0.1268920600414276\n","Epoch 49: finishing mini batch 593, training error = 0.046875, loss = 0.1492355912923813\n","Epoch 49: finishing mini batch 594, training error = 0.109375, loss = 0.18330928683280945\n","Epoch 49: finishing mini batch 595, training error = 0.046875, loss = 0.08785808086395264\n","Epoch 49: finishing mini batch 596, training error = 0.078125, loss = 0.34464630484580994\n","Epoch 49: finishing mini batch 597, training error = 0.046875, loss = 0.17330516874790192\n","Epoch 49: finishing mini batch 598, training error = 0.046875, loss = 0.06528972089290619\n","Epoch 49: finishing mini batch 599, training error = 0.078125, loss = 0.18179644644260406\n","Epoch 49: finishing mini batch 600, training error = 0.046875, loss = 0.11441534757614136\n","Epoch 49: finishing mini batch 601, training error = 0.03125, loss = 0.1376170665025711\n","Epoch 49: finishing mini batch 602, training error = 0.03125, loss = 0.07457248866558075\n","Epoch 49: finishing mini batch 603, training error = 0.0625, loss = 0.14263132214546204\n","Epoch 49: finishing mini batch 604, training error = 0.046875, loss = 0.14690729975700378\n","Epoch 49: finishing mini batch 605, training error = 0.046875, loss = 0.14959825575351715\n","Epoch 49: finishing mini batch 606, training error = 0.046875, loss = 0.11244669556617737\n","Epoch 49: finishing mini batch 607, training error = 0.0625, loss = 0.16000227630138397\n","Epoch 49: finishing mini batch 608, training error = 0.03125, loss = 0.13782238960266113\n","Epoch 49: finishing mini batch 609, training error = 0.015625, loss = 0.07182352244853973\n","Epoch 49: finishing mini batch 610, training error = 0.0, loss = 0.03964178264141083\n","Epoch 49: finishing mini batch 611, training error = 0.078125, loss = 0.19316206872463226\n","Epoch 49: finishing mini batch 612, training error = 0.0625, loss = 0.12945401668548584\n","Epoch 49: finishing mini batch 613, training error = 0.109375, loss = 0.3849526643753052\n","Epoch 49: finishing mini batch 614, training error = 0.046875, loss = 0.12061729282140732\n","Epoch 49: finishing mini batch 615, training error = 0.0, loss = 0.01742331124842167\n","Epoch 49: finishing mini batch 616, training error = 0.046875, loss = 0.11319119483232498\n","Epoch 49: finishing mini batch 617, training error = 0.03125, loss = 0.12868168950080872\n","Epoch 49: finishing mini batch 618, training error = 0.09375, loss = 0.2135118544101715\n","Epoch 49: finishing mini batch 619, training error = 0.078125, loss = 0.24395936727523804\n","Epoch 49: finishing mini batch 620, training error = 0.0625, loss = 0.1269814372062683\n","Epoch 49: finishing mini batch 621, training error = 0.015625, loss = 0.06126774474978447\n","Epoch 49: finishing mini batch 622, training error = 0.078125, loss = 0.11459694057703018\n","Epoch 49: finishing mini batch 623, training error = 0.0625, loss = 0.14382734894752502\n","Epoch 49: finishing mini batch 624, training error = 0.0625, loss = 0.11241869628429413\n","Epoch 49: finishing mini batch 625, training error = 0.078125, loss = 0.19382239878177643\n","Epoch 49: finishing mini batch 626, training error = 0.046875, loss = 0.16850924491882324\n","Epoch 49: finishing mini batch 627, training error = 0.03125, loss = 0.09337371587753296\n","Epoch 49: finishing mini batch 628, training error = 0.078125, loss = 0.18255381286144257\n","Epoch 49: finishing mini batch 629, training error = 0.0625, loss = 0.3276148736476898\n","Epoch 49: finishing mini batch 630, training error = 0.03125, loss = 0.09377264976501465\n","Epoch 49: finishing mini batch 631, training error = 0.078125, loss = 0.18655405938625336\n","Epoch 49: finishing mini batch 632, training error = 0.0625, loss = 0.17363567650318146\n","Epoch 49: finishing mini batch 633, training error = 0.015625, loss = 0.0627138614654541\n","Epoch 49: finishing mini batch 634, training error = 0.09375, loss = 0.2198658287525177\n","Epoch 49: finishing mini batch 635, training error = 0.046875, loss = 0.15886536240577698\n","Epoch 49: finishing mini batch 636, training error = 0.03125, loss = 0.14489416778087616\n","Epoch 49: finishing mini batch 637, training error = 0.046875, loss = 0.13710691034793854\n","Epoch 49: finishing mini batch 638, training error = 0.09375, loss = 0.23676717281341553\n","Epoch 49: finishing mini batch 639, training error = 0.078125, loss = 0.20994186401367188\n","Epoch 49: finishing mini batch 640, training error = 0.046875, loss = 0.09585969150066376\n","Epoch 49: finishing mini batch 641, training error = 0.015625, loss = 0.1193617731332779\n","Epoch 49: finishing mini batch 642, training error = 0.0625, loss = 0.11126689612865448\n","Epoch 49: finishing mini batch 643, training error = 0.015625, loss = 0.06902267038822174\n","Epoch 49: finishing mini batch 644, training error = 0.078125, loss = 0.23251721262931824\n","Epoch 49: finishing mini batch 645, training error = 0.046875, loss = 0.21025709807872772\n","Epoch 49: finishing mini batch 646, training error = 0.03125, loss = 0.08582639694213867\n","Epoch 49: finishing mini batch 647, training error = 0.046875, loss = 0.14927254617214203\n","Epoch 49: finishing mini batch 648, training error = 0.046875, loss = 0.17683644592761993\n","Epoch 49: finishing mini batch 649, training error = 0.015625, loss = 0.06567835807800293\n","Epoch 49: finishing mini batch 650, training error = 0.109375, loss = 0.21150614321231842\n","Epoch 49: finishing mini batch 651, training error = 0.046875, loss = 0.17653389275074005\n","Epoch 49: finishing mini batch 652, training error = 0.03125, loss = 0.10426870733499527\n","Epoch 49: finishing mini batch 653, training error = 0.0625, loss = 0.21062646806240082\n","Epoch 49: finishing mini batch 654, training error = 0.046875, loss = 0.2006654441356659\n","Epoch 49: finishing mini batch 655, training error = 0.109375, loss = 0.35707879066467285\n","Epoch 49: finishing mini batch 656, training error = 0.015625, loss = 0.054220303893089294\n","Epoch 49: finishing mini batch 657, training error = 0.015625, loss = 0.030219607055187225\n","Epoch 49: finishing mini batch 658, training error = 0.046875, loss = 0.13583998382091522\n","Epoch 49: finishing mini batch 659, training error = 0.0, loss = 0.029607929289340973\n","Epoch 49: finishing mini batch 660, training error = 0.015625, loss = 0.07308609038591385\n","Epoch 49: finishing mini batch 661, training error = 0.046875, loss = 0.13968299329280853\n","Epoch 49: finishing mini batch 662, training error = 0.046875, loss = 0.15393513441085815\n","Epoch 49: finishing mini batch 663, training error = 0.0625, loss = 0.25219589471817017\n","Epoch 49: finishing mini batch 664, training error = 0.09375, loss = 0.18744951486587524\n","Epoch 49: finishing mini batch 665, training error = 0.046875, loss = 0.1019817665219307\n","Epoch 49: finishing mini batch 666, training error = 0.09375, loss = 0.20007137954235077\n","Epoch 49: finishing mini batch 667, training error = 0.046875, loss = 0.21504567563533783\n","Epoch 49: finishing mini batch 668, training error = 0.0625, loss = 0.19333814084529877\n","Epoch 49: finishing mini batch 669, training error = 0.03125, loss = 0.09820118546485901\n","Epoch 49: finishing mini batch 670, training error = 0.015625, loss = 0.05152985081076622\n","Epoch 49: finishing mini batch 671, training error = 0.03125, loss = 0.059025976806879044\n","Epoch 49: finishing mini batch 672, training error = 0.09375, loss = 0.16510462760925293\n","Epoch 49: finishing mini batch 673, training error = 0.03125, loss = 0.060177866369485855\n","Epoch 49: finishing mini batch 674, training error = 0.09375, loss = 0.25059229135513306\n","Epoch 49: finishing mini batch 675, training error = 0.078125, loss = 0.2578546404838562\n","Epoch 49: finishing mini batch 676, training error = 0.09375, loss = 0.16754907369613647\n","Epoch 49: finishing mini batch 677, training error = 0.09375, loss = 0.2686995565891266\n","Epoch 49: finishing mini batch 678, training error = 0.046875, loss = 0.16061246395111084\n","Epoch 49: finishing mini batch 679, training error = 0.015625, loss = 0.05608794838190079\n","Epoch 49: finishing mini batch 680, training error = 0.03125, loss = 0.09515601396560669\n","Epoch 49: finishing mini batch 681, training error = 0.046875, loss = 0.08627152442932129\n","Epoch 49: finishing mini batch 682, training error = 0.046875, loss = 0.08035101741552353\n","Epoch 49: finishing mini batch 683, training error = 0.078125, loss = 0.1334218829870224\n","Epoch 49: finishing mini batch 684, training error = 0.09375, loss = 0.3425542712211609\n","Epoch 49: finishing mini batch 685, training error = 0.03125, loss = 0.13774649798870087\n","Epoch 49: finishing mini batch 686, training error = 0.046875, loss = 0.10722453147172928\n","Epoch 49: finishing mini batch 687, training error = 0.046875, loss = 0.09484588354825974\n","Epoch 49: finishing mini batch 688, training error = 0.046875, loss = 0.1704826056957245\n","Epoch 49: finishing mini batch 689, training error = 0.03125, loss = 0.06956947594881058\n","Epoch 49: finishing mini batch 690, training error = 0.0625, loss = 0.13748793303966522\n","Epoch 49: finishing mini batch 691, training error = 0.046875, loss = 0.10651449859142303\n","Epoch 49: finishing mini batch 692, training error = 0.03125, loss = 0.08735116571187973\n","Epoch 49: finishing mini batch 693, training error = 0.015625, loss = 0.07579810917377472\n","Epoch 49: finishing mini batch 694, training error = 0.015625, loss = 0.07521142065525055\n","Epoch 49: finishing mini batch 695, training error = 0.109375, loss = 0.3053840398788452\n","Epoch 49: finishing mini batch 696, training error = 0.046875, loss = 0.19709743559360504\n","Epoch 49: finishing mini batch 697, training error = 0.078125, loss = 0.15517765283584595\n","Epoch 49: finishing mini batch 698, training error = 0.09375, loss = 0.2393757700920105\n","Epoch 49: finishing mini batch 699, training error = 0.03125, loss = 0.06765392422676086\n","Epoch 49: finishing mini batch 700, training error = 0.09375, loss = 0.3311031460762024\n","Epoch 49: finishing mini batch 701, training error = 0.03125, loss = 0.07796762138605118\n","Epoch 49: finishing mini batch 702, training error = 0.078125, loss = 0.15075276792049408\n","Epoch 49: finishing mini batch 703, training error = 0.046875, loss = 0.17186182737350464\n","Epoch 49: finishing mini batch 704, training error = 0.0625, loss = 0.20074144005775452\n","Epoch 49: finishing mini batch 705, training error = 0.0625, loss = 0.17219007015228271\n","Epoch 49: finishing mini batch 706, training error = 0.046875, loss = 0.13920849561691284\n","Epoch 49: finishing mini batch 707, training error = 0.0625, loss = 0.19778646528720856\n","Epoch 49: finishing mini batch 708, training error = 0.109375, loss = 0.23189979791641235\n","Epoch 49: finishing mini batch 709, training error = 0.03125, loss = 0.05812928453087807\n","Epoch 49: finishing mini batch 710, training error = 0.078125, loss = 0.18262073397636414\n","Epoch 49: finishing mini batch 711, training error = 0.0625, loss = 0.13564279675483704\n","Epoch 49: finishing mini batch 712, training error = 0.0625, loss = 0.14045816659927368\n","Epoch 49: finishing mini batch 713, training error = 0.109375, loss = 0.34636953473091125\n","Epoch 49: finishing mini batch 714, training error = 0.125, loss = 0.5036186575889587\n","Epoch 49: finishing mini batch 715, training error = 0.03125, loss = 0.11575683951377869\n","Epoch 49: finishing mini batch 716, training error = 0.03125, loss = 0.10581611841917038\n","Epoch 49: finishing mini batch 717, training error = 0.0625, loss = 0.12427586317062378\n","Epoch 49: finishing mini batch 718, training error = 0.078125, loss = 0.23493707180023193\n","Epoch 49: finishing mini batch 719, training error = 0.09375, loss = 0.22874508798122406\n","Epoch 49: finishing mini batch 720, training error = 0.078125, loss = 0.1686086803674698\n","Epoch 49: finishing mini batch 721, training error = 0.109375, loss = 0.16401493549346924\n","Epoch 49: finishing mini batch 722, training error = 0.046875, loss = 0.0790025144815445\n","Epoch 49: finishing mini batch 723, training error = 0.0625, loss = 0.15419408679008484\n","Epoch 49: finishing mini batch 724, training error = 0.046875, loss = 0.18969036638736725\n","Epoch 49: finishing mini batch 725, training error = 0.0625, loss = 0.08795929700136185\n","Epoch 49: finishing mini batch 726, training error = 0.140625, loss = 0.4617812931537628\n","Epoch 49: finishing mini batch 727, training error = 0.0625, loss = 0.15163390338420868\n","Epoch 49: finishing mini batch 728, training error = 0.0625, loss = 0.21549014747142792\n","Epoch 49: finishing mini batch 729, training error = 0.09375, loss = 0.20721711218357086\n","Epoch 49: finishing mini batch 730, training error = 0.015625, loss = 0.06721566617488861\n","Epoch 49: finishing mini batch 731, training error = 0.078125, loss = 0.17246662080287933\n","Epoch 49: finishing mini batch 732, training error = 0.0625, loss = 0.1423274427652359\n","Epoch 49: finishing mini batch 733, training error = 0.046875, loss = 0.16378483176231384\n","Epoch 49: finishing mini batch 734, training error = 0.03125, loss = 0.08257703483104706\n","Epoch 49: finishing mini batch 735, training error = 0.078125, loss = 0.19631746411323547\n","Epoch 49: finishing mini batch 736, training error = 0.046875, loss = 0.13887959718704224\n","Epoch 49: finishing mini batch 737, training error = 0.0625, loss = 0.18690259754657745\n","Epoch 49: finishing mini batch 738, training error = 0.09375, loss = 0.19973456859588623\n","Epoch 49: finishing mini batch 739, training error = 0.078125, loss = 0.17679676413536072\n","Epoch 49: finishing mini batch 740, training error = 0.03125, loss = 0.09147753566503525\n","Epoch 49: finishing mini batch 741, training error = 0.09375, loss = 0.208097442984581\n","Epoch 49: finishing mini batch 742, training error = 0.046875, loss = 0.1407354325056076\n","Epoch 49: finishing mini batch 743, training error = 0.0625, loss = 0.2973628640174866\n","Epoch 49: finishing mini batch 744, training error = 0.03125, loss = 0.09586850553750992\n","Epoch 49: finishing mini batch 745, training error = 0.046875, loss = 0.13306142389774323\n","Epoch 49: finishing mini batch 746, training error = 0.09375, loss = 0.27823105454444885\n","Epoch 49: finishing mini batch 747, training error = 0.09375, loss = 0.3347822427749634\n","Epoch 49: finishing mini batch 748, training error = 0.046875, loss = 0.13559411466121674\n","Epoch 49: finishing mini batch 749, training error = 0.0625, loss = 0.18361738324165344\n","Epoch 49: finishing mini batch 750, training error = 0.09375, loss = 0.31394097208976746\n","Epoch 49: finishing mini batch 751, training error = 0.0625, loss = 0.15779165923595428\n","Epoch 49: finishing mini batch 752, training error = 0.03125, loss = 0.07086579501628876\n","Epoch 49: finishing mini batch 753, training error = 0.046875, loss = 0.15538212656974792\n","Epoch 49: finishing mini batch 754, training error = 0.03125, loss = 0.17529651522636414\n","Epoch 49: finishing mini batch 755, training error = 0.046875, loss = 0.14008577167987823\n","Epoch 49: finishing mini batch 756, training error = 0.09375, loss = 0.19950616359710693\n","Epoch 49: finishing mini batch 757, training error = 0.109375, loss = 0.29791393876075745\n","Epoch 49: finishing mini batch 758, training error = 0.0625, loss = 0.17512908577919006\n","Epoch 49: finishing mini batch 759, training error = 0.0625, loss = 0.1415437012910843\n","Epoch 49: finishing mini batch 760, training error = 0.078125, loss = 0.1628658026456833\n","Epoch 49: finishing mini batch 761, training error = 0.0625, loss = 0.222344309091568\n","Epoch 49: finishing mini batch 762, training error = 0.078125, loss = 0.1527969092130661\n","Epoch 49: finishing mini batch 763, training error = 0.0625, loss = 0.18626849353313446\n","Epoch 49: finishing mini batch 764, training error = 0.046875, loss = 0.10405939072370529\n","Epoch 49: finishing mini batch 765, training error = 0.046875, loss = 0.12883369624614716\n","Epoch 49: finishing mini batch 766, training error = 0.078125, loss = 0.1544037163257599\n","Epoch 49: finishing mini batch 767, training error = 0.078125, loss = 0.30538395047187805\n","Epoch 49: finishing mini batch 768, training error = 0.078125, loss = 0.3315786123275757\n","Epoch 49: finishing mini batch 769, training error = 0.078125, loss = 0.222623810172081\n","Epoch 49: finishing mini batch 770, training error = 0.078125, loss = 0.189070925116539\n","Epoch 49: finishing mini batch 771, training error = 0.078125, loss = 0.2568533420562744\n","Epoch 49: finishing mini batch 772, training error = 0.03125, loss = 0.1004054918885231\n","Epoch 49: finishing mini batch 773, training error = 0.046875, loss = 0.08072087913751602\n","Epoch 49: finishing mini batch 774, training error = 0.03125, loss = 0.07988123595714569\n","Epoch 49: finishing mini batch 775, training error = 0.046875, loss = 0.13452109694480896\n","Epoch 49: finishing mini batch 776, training error = 0.0625, loss = 0.15883898735046387\n","Epoch 49: finishing mini batch 777, training error = 0.078125, loss = 0.30285346508026123\n","Epoch 49: finishing mini batch 778, training error = 0.078125, loss = 0.2217661440372467\n","Epoch 49: finishing mini batch 779, training error = 0.078125, loss = 0.18726831674575806\n","Epoch 49: finishing mini batch 780, training error = 0.0625, loss = 0.2007347196340561\n","Epoch 49: finishing mini batch 781, training error = 0.0625, loss = 0.2723275423049927\n","Epoch 49: finishing mini batch 782, training error = 0.0625, loss = 0.15045543015003204\n","Epoch 49 completed, acc_loss = 90.7250964823179\n"]}]},{"cell_type":"code","source":["nb_test_errors, nb_test_samples = 0, 0\n","\n","model.eval()\n","\n","mini_batch = 0\n","for input, targets in iter(test_loader):\n","    input, targets = input.to(device), targets.to(device)\n","\n","    output = model(input)\n","    preds = torch.argmax(output.data, 1)\n","    diff_count = torch.count_nonzero(preds - targets)\n","    batch_size = targets.size(0)\n","    test_error = float(diff_count) / batch_size\n","\n","    mini_batch += 1\n","    print(f'Mini batch {mini_batch}: test error = {test_error}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HWm4YBzsrIbz","executionInfo":{"status":"ok","timestamp":1672532228786,"user_tz":480,"elapsed":3265,"user":{"displayName":"sillybierba","userId":"07761949595544066685"}},"outputId":"23af6661-b602-48b8-e0f2-6456d4e43334"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Mini batch 1: test error = 0.3125\n","Mini batch 2: test error = 0.296875\n","Mini batch 3: test error = 0.28125\n","Mini batch 4: test error = 0.25\n","Mini batch 5: test error = 0.3125\n","Mini batch 6: test error = 0.28125\n","Mini batch 7: test error = 0.328125\n","Mini batch 8: test error = 0.140625\n","Mini batch 9: test error = 0.203125\n","Mini batch 10: test error = 0.125\n","Mini batch 11: test error = 0.25\n","Mini batch 12: test error = 0.296875\n","Mini batch 13: test error = 0.234375\n","Mini batch 14: test error = 0.203125\n","Mini batch 15: test error = 0.25\n","Mini batch 16: test error = 0.203125\n","Mini batch 17: test error = 0.265625\n","Mini batch 18: test error = 0.359375\n","Mini batch 19: test error = 0.140625\n","Mini batch 20: test error = 0.3125\n","Mini batch 21: test error = 0.234375\n","Mini batch 22: test error = 0.28125\n","Mini batch 23: test error = 0.1875\n","Mini batch 24: test error = 0.28125\n","Mini batch 25: test error = 0.28125\n","Mini batch 26: test error = 0.171875\n","Mini batch 27: test error = 0.265625\n","Mini batch 28: test error = 0.328125\n","Mini batch 29: test error = 0.328125\n","Mini batch 30: test error = 0.21875\n","Mini batch 31: test error = 0.3125\n","Mini batch 32: test error = 0.265625\n","Mini batch 33: test error = 0.203125\n","Mini batch 34: test error = 0.375\n","Mini batch 35: test error = 0.1875\n","Mini batch 36: test error = 0.375\n","Mini batch 37: test error = 0.3125\n","Mini batch 38: test error = 0.265625\n","Mini batch 39: test error = 0.25\n","Mini batch 40: test error = 0.28125\n","Mini batch 41: test error = 0.28125\n","Mini batch 42: test error = 0.3125\n","Mini batch 43: test error = 0.28125\n","Mini batch 44: test error = 0.234375\n","Mini batch 45: test error = 0.28125\n","Mini batch 46: test error = 0.21875\n","Mini batch 47: test error = 0.28125\n","Mini batch 48: test error = 0.328125\n","Mini batch 49: test error = 0.25\n","Mini batch 50: test error = 0.359375\n","Mini batch 51: test error = 0.25\n","Mini batch 52: test error = 0.234375\n","Mini batch 53: test error = 0.34375\n","Mini batch 54: test error = 0.3125\n","Mini batch 55: test error = 0.265625\n","Mini batch 56: test error = 0.21875\n","Mini batch 57: test error = 0.28125\n","Mini batch 58: test error = 0.171875\n","Mini batch 59: test error = 0.25\n","Mini batch 60: test error = 0.265625\n","Mini batch 61: test error = 0.28125\n","Mini batch 62: test error = 0.25\n","Mini batch 63: test error = 0.328125\n","Mini batch 64: test error = 0.1875\n","Mini batch 65: test error = 0.21875\n","Mini batch 66: test error = 0.28125\n","Mini batch 67: test error = 0.25\n","Mini batch 68: test error = 0.265625\n","Mini batch 69: test error = 0.234375\n","Mini batch 70: test error = 0.25\n","Mini batch 71: test error = 0.1875\n","Mini batch 72: test error = 0.265625\n","Mini batch 73: test error = 0.375\n","Mini batch 74: test error = 0.1875\n","Mini batch 75: test error = 0.296875\n","Mini batch 76: test error = 0.21875\n","Mini batch 77: test error = 0.265625\n","Mini batch 78: test error = 0.203125\n","Mini batch 79: test error = 0.296875\n","Mini batch 80: test error = 0.3125\n","Mini batch 81: test error = 0.28125\n","Mini batch 82: test error = 0.328125\n","Mini batch 83: test error = 0.265625\n","Mini batch 84: test error = 0.265625\n","Mini batch 85: test error = 0.25\n","Mini batch 86: test error = 0.234375\n","Mini batch 87: test error = 0.296875\n","Mini batch 88: test error = 0.25\n","Mini batch 89: test error = 0.34375\n","Mini batch 90: test error = 0.21875\n","Mini batch 91: test error = 0.15625\n","Mini batch 92: test error = 0.34375\n","Mini batch 93: test error = 0.359375\n","Mini batch 94: test error = 0.203125\n","Mini batch 95: test error = 0.328125\n","Mini batch 96: test error = 0.265625\n","Mini batch 97: test error = 0.28125\n","Mini batch 98: test error = 0.21875\n","Mini batch 99: test error = 0.25\n","Mini batch 100: test error = 0.25\n","Mini batch 101: test error = 0.265625\n","Mini batch 102: test error = 0.328125\n","Mini batch 103: test error = 0.25\n","Mini batch 104: test error = 0.28125\n","Mini batch 105: test error = 0.234375\n","Mini batch 106: test error = 0.296875\n","Mini batch 107: test error = 0.234375\n","Mini batch 108: test error = 0.28125\n","Mini batch 109: test error = 0.21875\n","Mini batch 110: test error = 0.265625\n","Mini batch 111: test error = 0.28125\n","Mini batch 112: test error = 0.203125\n","Mini batch 113: test error = 0.328125\n","Mini batch 114: test error = 0.21875\n","Mini batch 115: test error = 0.203125\n","Mini batch 116: test error = 0.390625\n","Mini batch 117: test error = 0.234375\n","Mini batch 118: test error = 0.171875\n","Mini batch 119: test error = 0.34375\n","Mini batch 120: test error = 0.25\n","Mini batch 121: test error = 0.1875\n","Mini batch 122: test error = 0.34375\n","Mini batch 123: test error = 0.25\n","Mini batch 124: test error = 0.28125\n","Mini batch 125: test error = 0.21875\n","Mini batch 126: test error = 0.203125\n","Mini batch 127: test error = 0.21875\n","Mini batch 128: test error = 0.28125\n","Mini batch 129: test error = 0.234375\n","Mini batch 130: test error = 0.328125\n","Mini batch 131: test error = 0.28125\n","Mini batch 132: test error = 0.28125\n","Mini batch 133: test error = 0.390625\n","Mini batch 134: test error = 0.34375\n","Mini batch 135: test error = 0.3125\n","Mini batch 136: test error = 0.25\n","Mini batch 137: test error = 0.296875\n","Mini batch 138: test error = 0.328125\n","Mini batch 139: test error = 0.21875\n","Mini batch 140: test error = 0.28125\n","Mini batch 141: test error = 0.25\n","Mini batch 142: test error = 0.296875\n","Mini batch 143: test error = 0.40625\n","Mini batch 144: test error = 0.1875\n","Mini batch 145: test error = 0.3125\n","Mini batch 146: test error = 0.21875\n","Mini batch 147: test error = 0.21875\n","Mini batch 148: test error = 0.390625\n","Mini batch 149: test error = 0.203125\n","Mini batch 150: test error = 0.171875\n","Mini batch 151: test error = 0.265625\n","Mini batch 152: test error = 0.21875\n","Mini batch 153: test error = 0.296875\n","Mini batch 154: test error = 0.375\n","Mini batch 155: test error = 0.25\n","Mini batch 156: test error = 0.34375\n","Mini batch 157: test error = 0.1875\n"]}]}]}